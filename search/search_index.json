{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Willkommen im Skript zur Fortgeschrittenenschulung Python.</p> <ul> <li> <p> Python Dash</p> </li> <li> <p> Pydantic</p> </li> <li> <p> Effizienter Code &amp; Arbeitsspeicherressourcen</p> </li> <li> <p> Polars</p> </li> <li> <p> Pytest</p> </li> <li> <p> Dekoratoren &amp; Klassen</p> </li> <li> <p> GIT</p> </li> <li> <p> OOP &amp; Design Patterns/ Strukturierte Projekte</p> </li> </ul>"},{"location":"dekoratoren_und_klassen/","title":"Dekoratoren und Klassen","text":""},{"location":"dekoratoren_und_klassen/#klassen-in-python-eine-wiederholung","title":"Klassen in Python \u2013 Eine Wiederholung","text":"<p>Klassen bieten uns eine strukturierte Methode, um Daten und Funktionen zu organisieren und zu kapseln, was insbesondere bei gr\u00f6\u00dferen Projekten von Vorteil ist.</p>"},{"location":"dekoratoren_und_klassen/#anwendung-von-klassen-im-projektrahmen","title":"Anwendung von Klassen im Projektrahmen","text":"<p>Klassen erm\u00f6glichen es uns, verschiedene Aspekte eines Projekts logisch zu strukturieren. Nehmen wir als Beispiel einen Discounter: Hier k\u00f6nnen Klassen genutzt werden, um Kundenprofile, Produktinformationen oder Verkaufsdaten systematisch zu organisieren. Das sorgt f\u00fcr einen \u00fcbersichtlichen und wiederverwendbaren Code.</p> <p>Beispiele:</p> <ol> <li>Kunde-Klasse zur Verwaltung von Kundendaten:</li> </ol> <pre><code>class Kunde:\n    def __init__(self, kunden_id, name, einkaufsverhalten):\n        self.kunden_id = kunden_id\n        self.name = name\n        self.einkaufsverhalten = einkaufsverhalten\n\n    def berechne_gesamtumsatz(self):\n        return sum(self.einkaufsverhalten)\n\nkunde1 = Kunde(101, \"Max Mustermann\", [23.50, 15.75, 9.99])\nprint(kunde1.berechne_gesamtumsatz())\n</code></pre> <p>Diese Klasse verwaltet Kundendaten und berechnet den Gesamtumsatz eines Kunden. Dies hilft, Kundenprofile effizient zu analysieren.</p> <ol> <li>Produkt-Klasse zur Verwaltung von Produktinformationen:</li> </ol> <pre><code>class Produkt:\n    def __init__(self, produkt_id, name, preis, lagerbestand):\n        self.produkt_id = produkt_id\n        self.name = name\n        self.preis = preis\n        self.lagerbestand = lagerbestand\n\n    def aktualisiere_lagerbestand(self, verkaufte_menge):\n        self.lagerbestand -= verkaufte_menge\n</code></pre> <p>Mit dieser Klasse k\u00f6nnen wir Informationen \u00fcber Produkte verwalten und den Lagerbestand nach Verk\u00e4ufen aktualisieren.</p> <ol> <li>Verkauf-Klasse f\u00fcr Transaktionsmanagement:</li> </ol> <pre><code>class Verkauf:\n    def __init__(self):\n        self.transaktionen = []\n\n    def fuege_transaktion_hinzu(self, produkt, menge, preis):\n        self.transaktionen.append({'produkt': produkt, 'menge': menge, 'preis': preis})\n\n    def berechne_gesamtumsatz(self):\n        return sum(t['menge'] * t['preis'] for t in self.transaktionen)\n</code></pre> <p>Diese Klasse speichert Verkaufsdaten und berechnet den Gesamtumsatz aller Transaktionen, was f\u00fcr die Zusammenstellung von Verkaufsberichten n\u00fctzlich ist.</p>"},{"location":"dekoratoren_und_klassen/#aufgaben-zum-vertiefen-des-verstandnisses","title":"Aufgaben zum Vertiefen des Verst\u00e4ndnisses","text":"<ol> <li> <p>Erweitern der Produktklasse:    Erg\u00e4nzen wir die <code>Produkt</code>-Klasse um eine Methode, die den Lagerbestand nach einer R\u00fcckgabe aktualisiert.</p> </li> <li> <p>Analyse des Einkaufsverhaltens:    Modifizieren wir die <code>Kunde</code>-Klasse, um eine Methode zu implementieren, die eine Liste der am h\u00e4ufigsten gekauften Produkte ausgibt.</p> </li> <li> <p>Entwicklung eines Rabatt-Systems:    Erstellen wir eine neue Klasse <code>Rabatt</code>, die verschiedene Rabattstrategien f\u00fcr Produkte implementiert und auf den Gesamtumsatz angewendet werden kann.</p> </li> </ol>"},{"location":"dekoratoren_und_klassen/dekoratoren/","title":"Dekoratoren in Python","text":"<p>Mithilfe von Dekoratoren k\u00f6nnen wir Funktionen oder Klassen flexibel erweitern, ohne deren urspr\u00fcnglichen Code zu ver\u00e4ndern. Sie erlauben es uns, zus\u00e4tzliche Funktionalit\u00e4ten hinzuzuf\u00fcgen, was besonders hilfreich ist, um den Quellcode sauberer und modularer zu gestalten.</p>"},{"location":"dekoratoren_und_klassen/dekoratoren/#grundlagen-der-dekoratoren","title":"Grundlagen der Dekoratoren","text":"<p>Ein Dekorator ist im Wesentlichen eine Funktion, die eine andere Funktion als Argument akzeptiert und eine neue Funktion zur\u00fcckgibt. Diese neue Funktion kann den urspr\u00fcnglichen Funktionsaufruf erweitern oder modifizieren. Dekoratoren werden h\u00e4ufig f\u00fcr Logging, Zugriffskontrolle oder zur Verifikation von Eingabedaten verwendet.</p> <p>Beispiel:</p> <pre><code>def log_decorator(funktion):\n    def wrapper(*args, **kwargs):\n        print(f\"Ausf\u00fchren von: {funktion.__name__}\")\n        ergebnis = funktion(*args, **kwargs)\n        print(f\"Beendet: {funktion.__name__}\")\n        return ergebnis\n    return wrapper\n\n@log_decorator\ndef berechne_rabatt(preis, rabatt):\n    return preis * (1 - rabatt)\n\nprint(berechne_rabatt(100, 0.1))\n</code></pre> <p>In diesem Beispiel verwenden wir den <code>log_decorator</code>, um die Ausf\u00fchrung der Funktion <code>berechne_rabatt</code> zu protokollieren.</p>"},{"location":"dekoratoren_und_klassen/dekoratoren/#praktische-anwendungen","title":"Praktische Anwendungen","text":"<p>Dekoratoren k\u00f6nnen wir verwenden, um beispielsweise Berechnungen zu \u00fcberwachen, indem wir Protokollierungs- oder Sicherheitsmechanismen einf\u00fchren.</p> <p>Beispiel:</p> <pre><code>def zugriffs_kontrolle(funktion):\n    def wrapper(*args, **kwargs):\n        benutzer = kwargs.get('benutzer', None)\n        if benutzer == 'admin':\n            return funktion(*args, **kwargs)\n        else:\n            print(\"Zugriff verweigert.\")\n    return wrapper\n\n@zugriffs_kontrolle\ndef aktualisiere_preise(produkt_id, neuer_preis, benutzer=None):\n    # Logik zur Preisaktualisierung\n    print(f\"Preis f\u00fcr Produkt {produkt_id} aktualisiert auf {neuer_preis}\")\n\n# Beispielaufrufe\naktualisiere_preise(101, 2.99, benutzer='admin')\naktualisiere_preise(101, 2.99, benutzer='kunde')\n</code></pre> <p>Hier sorgt der Dekorator <code>zugriffs_kontrolle</code> daf\u00fcr, dass nur bestimmte Nutzergruppen Preise aktualisieren k\u00f6nnen.</p>"},{"location":"dekoratoren_und_klassen/dekoratoren/#aufgaben-zum-verstandnis","title":"Aufgaben zum Verst\u00e4ndnis","text":"<ol> <li> <p>Dekorator f\u00fcr Zeitmessung:    Entwickeln wir einen Dekorator, der die Ausf\u00fchrungszeit einer Funktion misst und die Ergebnisse protokolliert.</p> </li> <li> <p>Validierungs-Dekorator:    Erstellen wir einen Dekorator, der sicherstellt, dass alle Eingabewerte der Funktion <code>berechne_rabatt</code> g\u00fcltig sind (z.B. positive Zahlen).</p> </li> <li> <p>Benachrichtigungs-Dekorator:    Implementieren wir einen Dekorator, der nach der Aktualisierung von Lagerbest\u00e4nden automatisch eine Benachrichtigung sendet.</p> </li> </ol>"},{"location":"dekoratoren_und_klassen/erweiterte_klassen/","title":"Klassen","text":""},{"location":"dekoratoren_und_klassen/erweiterte_klassen/#erweiterte-konzepte-in-python-klassen","title":"Erweiterte Konzepte in Python-Klassen","text":"<p>Nachdem wir die Grundlagen von Klassen besprochen haben, wenden wir uns nun einigen fortgeschrittenen Themen zu. Diese Konzepte erm\u00f6glichen eine noch effektivere Strukturierung und Wiederverwendbarkeit unseres Codes.</p>"},{"location":"dekoratoren_und_klassen/erweiterte_klassen/#classmethods","title":"Classmethods","text":"<p>Classmethods bieten uns die M\u00f6glichkeit, Methoden zu erstellen, die auf die Klasse selbst anstatt auf eine Instanz angewendet werden. Dies ist n\u00fctzlich, wenn wir Konstruktoren oder alternative Initialisierungsmethoden ben\u00f6tigen.</p> <p>Beispiele:</p> <ol> <li>Produkt aus String erstellen:</li> </ol> <pre><code>class Produkt:\n    produktzaehler = 0\n\n    def __init__(self, name, preis):\n        self.name = name\n        self.preis = preis\n        Produkt.produktzaehler += 1\n\n    @classmethod\n    def erstelle_aus_string(cls, produkt_string):\n        name, preis = produkt_string.split(',')\n        return cls(name, float(preis))\n\nneues_produkt = Produkt.erstelle_aus_string(\"Kaffee,3.99\")\n</code></pre> <p>Hier verwenden wir eine Classmethod, um ein <code>Produkt</code> aus einer kommagetrennten Zeichenkette zu erstellen.</p> <ol> <li>Z\u00e4hler f\u00fcr erstellte Instanzen:</li> </ol> <pre><code>class Produkt:\n    instanz_zaehler = 0\n\n    def __init__(self, name, preis):\n        self.name = name\n        self.preis = preis\n        Produkt.instanz_zaehler += 1\n\n    @classmethod\n    def gib_anzahl_erstellt(cls):\n        return cls.instanz_zaehler\n\nprodukt1 = Produkt(\"Brot\", 1.50)\nprodukt2 = Produkt(\"Milch\", 0.99)\nprint(Produkt.gib_anzahl_erstellt())\n</code></pre> <p>Diese Methode z\u00e4hlt die Anzahl der erstellten Instanzen der Klasse.</p>"},{"location":"dekoratoren_und_klassen/erweiterte_klassen/#abstrakte-klassen","title":"Abstrakte Klassen","text":"<p>Abstrakte Klassen dienen als Blaupause f\u00fcr andere Klassen. Sie enthalten abstrakte Methoden, die in abgeleiteten Klassen implementiert werden m\u00fcssen.</p> <p>Beispiele:</p> <ol> <li>Rabattstrategie Implementierung:</li> </ol> <pre><code>from abc import ABC, abstractmethod\n\nclass RabattStrategie(ABC):\n\n    @abstractmethod\n    def berechne_rabatt(self, betrag):\n        pass\n\nclass ProzentualerRabatt(RabattStrategie):\n    def berechne_rabatt(self, betrag):\n        return betrag * 0.90  # 10% Rabatt\n</code></pre> <p>Hier definieren wir eine abstrakte Klasse <code>RabattStrategie</code> und implementieren eine prozentuale Rabattstrategie.</p> <ol> <li>Zahlungsmethoden-Plattform:</li> </ol> <pre><code>class Zahlungsplattform(ABC):\n\n    @abstractmethod\n    def verarbeite_zahlung(self, betrag):\n        pass\n\nclass Kreditkarte(Zahlungsplattform):\n    def verarbeite_zahlung(self, betrag):\n        print(f\"Zahlung von {betrag} per Kreditkarte verarbeitet.\")\n</code></pre> <p>Diese abstrakte Klasse definiert eine <code>Zahlungsplattform</code>, die von spezifischen Zahlungsarten wie <code>Kreditkarte</code> abgeleitet wird.</p>"},{"location":"dekoratoren_und_klassen/erweiterte_klassen/#mixins","title":"Mixins","text":"<p>Mixins sind Klassen, die kleine Funktionen bereitstellen, die von verschiedenen Klassen geteilt werden k\u00f6nnen. Sie sind n\u00fctzlich, um wiederverwendbaren Code zu erstellen, ohne komplexe Erbstrukturen.</p> <p>Beispiele:</p> <ol> <li>LogMixin f\u00fcr verschiedene Klassen:</li> </ol> <pre><code>class LogMixin:\n    def log(self, nachricht):\n        print(f\"Log: {nachricht}\")\n\nclass Bestandsverwaltung(LogMixin):\n    def aktualisiere_bestand(self, menge):\n        # Bestandslogik\n        self.log(f\"Bestand um {menge} Einheiten aktualisiert.\")\n</code></pre> <p><code>LogMixin</code> erm\u00f6glicht das Hinzuf\u00fcgen von Logging-Funktionen zu jeder Klasse.</p> <ol> <li>Benachrichtigungs-Mixin:</li> </ol> <pre><code>class BenachrichtigungMixin:\n    def sende_benachrichtigung(self, nachricht):\n        print(f\"Benachrichtigung: {nachricht}\")\n\nclass Bestellung(BenachrichtigungMixin):\n    def abschliessen(self):\n        # Bestellung abschlie\u00dfen\n        self.sende_benachrichtigung(\"Bestellung erfolgreich abgeschlossen.\")\n</code></pre> <p>Dieses Mixin bietet eine Benachrichtigungsfunktion, die in mehreren Klassen verwendet werden kann.</p>"},{"location":"dekoratoren_und_klassen/erweiterte_klassen/#dataclasses","title":"Dataclasses","text":"<p>Dataclasses vereinfachen die Erstellung von Klassen, die haupts\u00e4chlich der Datenhaltung dienen, indem sie automatisch Methoden wie <code>__init__</code>, <code>__repr__</code> und <code>__eq__</code> generieren.</p> <p>Beispiele:</p> <ol> <li>Einfache Produkt-Dataclass:</li> </ol> <pre><code>from dataclasses import dataclass\n\n@dataclass\nclass Produkt:\n    name: str\n    preis: float\n    lagerbestand: int\n\nprodukt1 = Produkt(\"Tee\", 2.99, 100)\n</code></pre> <p>Hier nutzen wir eine Dataclass, um schnell eine <code>Produkt</code>-Klasse zu erstellen, ohne Boilerplate-Code zu schreiben.</p> <ol> <li>Erweiterte Dataclass mit Methode:</li> </ol> <pre><code>@dataclass\nclass Kunde:\n    name: str\n    einkaufsverhalten: list\n\n    def gesamtumsatz(self) -&gt; float:\n        return sum(self.einkaufsverhalten)\n\nkunde1 = Kunde(\"Anna\", [10.99, 20.50, 5.99])\nprint(kunde1.gesamtumsatz())\n</code></pre> <p>Diese Dataclass enth\u00e4lt eine Methode zur Berechnung des Gesamtumsatzes.</p>"},{"location":"dekoratoren_und_klassen/erweiterte_klassen/#aufgaben","title":"Aufgaben","text":"<ol> <li> <p>Implementierung einer Klassmethoden-Fabrik:    Erstellen wir eine Classmethod in der <code>Produkt</code>-Klasse, die eine Liste von Produkten aus einer Liste von Strings initialisiert.</p> </li> <li> <p>Entwicklung eines Rabattsystems:    Implementieren wir eine weitere <code>RabattStrategie</code>, die einen prozentualen Rabatt gew\u00e4hrt und testen diese in einer Einkaufsumgebung.</p> </li> <li> <p>Logik mit Mixins erweitern:    F\u00fcgen wir einem bestehenden System ein Mixin hinzu, das erweiterte Protokollierungsfunktionen bietet, und verwenden es in mehreren Klassen.</p> </li> </ol>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/","title":"Effizienter Code und Arbeitsspeicherressourcen","text":"<p>In unserer t\u00e4glichen Arbeit mit Daten ist Effizienz von entscheidender Bedeutung. Egal, ob wir gro\u00dfe Datens\u00e4tze analysieren, Modelle trainieren oder interaktive Dashboards erstellen \u2013 effizienter Code und der sparsame Umgang mit Arbeitsspeicherressourcen machen den Unterschied zwischen einem reibungslosen Workflow und Performance-Problemen aus. In diesem Kapitel betrachten wir Python-Optimierungen, die uns helfen, sowohl schneller als auch ressourcenschonender zu arbeiten.</p> <p>Effizienter Code bedeutet nicht nur Geschwindigkeit, sondern auch Klarheit und Wartbarkeit. Besonders in der Datenanalyse und beim maschinellen Lernen, wo riesige Datenmengen verarbeitet werden, ist es wichtig, den Arbeitsspeicher nicht unn\u00f6tig zu belasten. Zwei Hauptfaktoren sind entscheidend: die Algorithmen, die wir verwenden, und die Datenstrukturen, die wir w\u00e4hlen. Dieses Kapitel zeigt, wie wir diese Ressourcen optimal nutzen k\u00f6nnen.</p>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/#stellschrauben-zur-erhohung-der-effizienz","title":"Stellschrauben zur Erh\u00f6hung der Effizienz","text":"<p>Um die Effizienz unserer Python-Programme zu steigern, gibt es mehrere Ansatzpunkte:</p>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/#algorithmische-effizienz","title":"Algorithmische Effizienz","text":"<p>Die Wahl des richtigen Algorithmus hat den gr\u00f6\u00dften Einfluss auf die Effizienz eines Programms.</p> <ul> <li> <p>Analyse der Zeitkomplexit\u00e4t: Wir sollten die Zeitkomplexit\u00e4t von Algorithmen \u00fcberpr\u00fcfen und solche mit niedrigerer Komplexit\u00e4t (z. B. O(n log n) statt O(n\u00b2)) bevorzugen.</p> </li> <li> <p>Geeignete Algorithmen verwenden: Oft bieten spezialisierte Bibliotheken optimierte Algorithmen an. Zum Beispiel ist die <code>sorted()</code>-Funktion in Python meist schneller als eigene Sortierfunktionen.</p> </li> </ul> <pre><code>zahlen = [5, 2, 9, 1, 5, 6]\nsortierte_zahlen = sorted(zahlen)\nprint(sortierte_zahlen)  # Ausgabe: [1, 2, 5, 5, 6, 9]\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/#effiziente-datenstrukturen","title":"Effiziente Datenstrukturen","text":"<p>Die Wahl der richtigen Datenstruktur kann die Effizienz erheblich beeinflussen.</p> <ul> <li>Listen vs. Sets vs. Dictionaries: Sets eignen sich gut, um Duplikate zu vermeiden und schnelle Mitgliedschaftstests durchzuf\u00fchren. Dictionaries bieten schnellen Zugriff auf Werte \u00fcber Schl\u00fcssel.</li> </ul> <pre><code>preise = {\"Apfel\": 1.20, \"Banane\": 0.50, \"Orange\": 0.80}\nprint(preise[\"Banane\"])  # Ausgabe: 0.50\n</code></pre> <ul> <li>Arrays f\u00fcr gro\u00dfe Datenmengen: Bei gro\u00dfen numerischen Datens\u00e4tzen sollten wir Bibliotheken wie <code>numpy</code>, <code>polars</code> oder <code>spark</code> nutzen, die f\u00fcr numerische Berechnungen optimiert sind.</li> </ul>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/#minimierung-von-kopien","title":"Minimierung von Kopien","text":"<p>Das Erstellen von Kopien gro\u00dfer Datenstrukturen kann viel Arbeitsspeicher beanspruchen. Wir sollten Kopien vermeiden und stattdessen Referenzen verwenden, wenn m\u00f6glich.</p> <pre><code>liste1 = [1, 2, 3]\nliste2 = liste1  # liste2 ist eine Referenz auf liste1\n\nliste2[0] = 99\nprint(liste1)  # Ausgabe: [99, 2, 3]\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/#profiling-und-optimierung","title":"Profiling und Optimierung","text":"<p>Profiling-Tools helfen uns, Engp\u00e4sse im Code zu identifizieren. Das <code>cProfile</code>-Modul erm\u00f6glicht es uns, die Laufzeit von Funktionen zu analysieren und zu optimieren.</p> <pre><code>import cProfile\n\ndef lange_berechnung():\n    # Simulierte lange Berechnung\n    summe = 0\n    for i in range(1000000):\n        summe += i\n    return summe\n\ncProfile.run('lange_berechnung()')\n</code></pre> <p>Die Ausgabe von <code>cProfile</code> gibt detaillierte Informationen \u00fcber die Ausf\u00fchrung von Funktionen:</p> <ul> <li><code>ncalls</code>: Anzahl der Funktionsaufrufe</li> <li><code>tottime</code>: Gesamtzeit in der Funktion (ohne Unterfunktionen)</li> <li><code>percall</code>: Zeit pro Aufruf</li> <li><code>cumtime</code>: Gesamtzeit in der Funktion und ihren Unterfunktionen</li> <li><code>filename:lineno(function)</code>: Funktion und ihre Position im Code</li> </ul>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/arbeitsspeicher/","title":"Arbeitsspeicher","text":""},{"location":"effizienter_code_und_arbeitsspeicherressourcen/arbeitsspeicher/#arbeitsspeicherverwaltung-in-python","title":"Arbeitsspeicherverwaltung in Python","text":"<p>Die automatisierte Speicherverwaltung in Python, bekannt als Garbage Collection, ist entscheidend f\u00fcr die Effizienz und Stabilit\u00e4t von Anwendungen, insbesondere bei gro\u00dfen Datens\u00e4tzen.</p>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/arbeitsspeicher/#speicherzuweisung-in-python","title":"Speicherzuweisung in Python","text":"<p>Python nutzt ein internes Speicherpool-System f\u00fcr h\u00e4ufig verwendete, kleine Objekte. Das Buddy-Allocation-System weist Speicherbl\u00f6cke von 8 bis 512 Bytes zu, um die Effizienz zu steigern und Fragmentierungen zu minimieren.</p> <p>Alle Daten in Python sind Objekte mit spezifischem Speicherbedarf. Zum Beispiel ben\u00f6tigen Integer dynamisch angepassten Speicher, Listen und Dictionaries nutzen Arrays, und Strings sind unver\u00e4nderlich, was bei \u00c4nderungen neue Speicheranforderungen erzeugt.</p> <pre><code>import sys\n\na = 42\nb = [1, 2, 3]\nc = \"Hello, World!\"\n\nprint(sys.getsizeof(a))\nprint(sys.getsizeof(b))\nprint(sys.getsizeof(c))\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/arbeitsspeicher/#referenzzahlung-und-garbage-collection","title":"Referenzz\u00e4hlung und Garbage Collection","text":"<p>Python verwendet Referenzz\u00e4hlung, um die Nutzung von Objekten zu verfolgen. Wenn der Z\u00e4hler eines Objekts auf null sinkt, wird es freigegeben. Zus\u00e4tzlich erkennt die zyklische Garbage Collection Objekte in gegenseitigen Referenzzyklen, die nicht mehr ben\u00f6tigt werden.</p> <pre><code>import sys\n\nx = [1, 2, 3]\ny = x\nz = [x, y]\n\nprint(sys.getrefcount(x))\ndel y\nprint(sys.getrefcount(x))\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/arbeitsspeicher/#optimierung-des-speicherverbrauchs-in-python","title":"Optimierung des Speicherverbrauchs in Python","text":"<ul> <li>Generatoren: Sie erstellen Sequenzen speichersparend, indem sie Werte bei Bedarf erzeugen.</li> </ul> <pre><code>def meine_generator():\n    for i in range(100):\n        yield i * 2\n\ngen = meine_generator()\nfor wert in gen:\n    print(wert)\n</code></pre> <ul> <li> <p>Objekt-Cache: Wiederholt erstellte Objekte wie kleine Ganzzahlen k\u00f6nnen gecacht werden.</p> </li> <li> <p>Speicherprofilierung: Tools wie <code>memory_profiler</code> helfen, Speicherverbrauch und Engp\u00e4sse zu \u00fcberwachen.</p> </li> </ul> <pre><code>pip install memory-profiler\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/arbeitsspeicher/#vergleich-mit-c","title":"Vergleich mit C","text":"<p>In C erfolgt die Speicherverwaltung manuell mit <code>malloc()</code> und <code>free()</code>. Diese Methode bietet mehr Kontrolle und Optimierungsm\u00f6glichkeiten, birgt aber auch Risiken wie Speicherlecks.</p>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/arbeitsspeicher/#moderne-arbeitsspeicherarchitekturen","title":"Moderne Arbeitsspeicherarchitekturen","text":"<p>Diese beeinflussen die Leistung von Anwendungen direkt. RAM ist der h\u00e4ufigste Typ:</p> <ul> <li>DRAM erfordert regelm\u00e4\u00dfiges Auffrischen.</li> <li>SRAM ist schneller, aber teurer und wird in Caches verwendet.</li> </ul> <p>Flash-Speicher, wie SSDs, bietet hohe Geschwindigkeiten und wird in modernen Speicherl\u00f6sungen eingesetzt.</p>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/arbeitsspeicher/#einfluss-der-architektur-auf-die-leistung","title":"Einfluss der Architektur auf die Leistung","text":"<ul> <li>Latenz und Bandbreite: Beeinflussen die Geschwindigkeit der Datenverarbeitung.</li> <li>Cache-Hierarchie: Optimiert Datenzugriffe und reduziert die Abh\u00e4ngigkeit vom Hauptspeicher.</li> </ul> <p>Moderne Technologien wie DDR5 und HBM erh\u00f6hen die Speicherbandbreite und Effizienz. Non-Volatile Memory bietet eine langlebige Speicheroption, die die L\u00fccke zwischen RAM und permanentem Speicher schlie\u00dft.</p>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/","title":"Effizienter Code im Umgang mit Daten","text":""},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#richtlinien-zur-erstellung-von-effizientem-code","title":"Richtlinien zur Erstellung von effizientem Code","text":"<p>Effizienter Code ist entscheidend f\u00fcr die Performance und Wartbarkeit unserer Datenanalysen. Hier sind einige Richtlinien, die wir befolgen sollten, um sowohl mit Pandas als auch mit Polars effektiv zu arbeiten.</p>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#pandas","title":"Pandas","text":""},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#vektorisierung-nutzen","title":"Vektorisierung nutzen","text":"<p>Mit Pandas k\u00f6nnen wir vektorisierte Operationen durchf\u00fchren, um ganze Spalten auf einmal zu bearbeiten und so die Leistung erheblich zu steigern.</p> <p>Beispiel:</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({'Original_Spalte': [1, 2, 3, 4, 5]})\ndf['Neue_Spalte'] = df['Original_Spalte'] * 2  # Vektorisierte Operation\nprint(df)\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#effizientes-einlesen-von-daten","title":"Effizientes Einlesen von Daten","text":"<ul> <li>CSV-Dateien: Nutzen wir die <code>dtype</code>-Option, um den Speicherbedarf zu optimieren.</li> <li>Excel-Dateien: Mit <code>usecols</code> k\u00f6nnen wir gezielt nur die ben\u00f6tigten Spalten laden.</li> <li>SQL-Datenbanken: Abfragen sollten so gestaltet sein, dass nur relevante Daten geladen werden.</li> </ul> <p>CSV-Beispiel:</p> <pre><code>df = pd.read_csv('daten.csv', dtype={'Spalte1': 'int32', 'Spalte2': 'float32'})\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#speicherverbrauch-optimieren","title":"Speicherverbrauch optimieren","text":"<p>Datentypen wie <code>category</code> helfen, Speicher zu sparen und die Performance zu verbessern.</p> <p>Beispiel:</p> <pre><code>df['Kategorische_Spalte'] = df['Kategorische_Spalte'].astype('category')\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#speicherplatz-freigeben","title":"Speicherplatz freigeben","text":"<p>Wir k\u00f6nnen den Speicher durch L\u00f6schen nicht mehr ben\u00f6tigter DataFrames freigeben.</p> <pre><code>del df\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#polars","title":"Polars","text":""},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#vektorisierung-nutzen_1","title":"Vektorisierung nutzen","text":"<p>Auch Polars bietet vektorisierte Operationen:</p> <p>Beispiel:</p> <pre><code>import polars as pl\n\ndf = pl.DataFrame({'Original_Spalte': [1, 2, 3, 4, 5]})\ndf = df.with_columns((pl.col('Original_Spalte') * 2).alias('Neue_Spalte'))\nprint(df)\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#effizientes-einlesen-von-daten_1","title":"Effizientes Einlesen von Daten","text":"<ul> <li>CSV-Dateien: Der <code>dtypes</code>-Parameter hilft, den Speicherbedarf zu kontrollieren.</li> <li>Excel-Dateien: Excel-Dateien m\u00fcssen erst mit Pandas eingelesen und dann in Polars umgewandelt werden.</li> <li>SQL-Datenbanken: SQL-Abfragen in Polars sollten ebenfalls zielgerichtet sein.</li> </ul> <p>CSV-Beispiel:</p> <pre><code>df = pl.read_csv('daten.csv', dtypes={'Spalte1': pl.Int32, 'Spalte2': pl.Float32})\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#speicherverbrauch-optimieren_1","title":"Speicherverbrauch optimieren","text":"<p>Wir sollten die <code>Categorical</code>-Klasse verwenden, um den Speicherverbrauch effizient zu gestalten.</p> <p>Beispiel:</p> <pre><code>df = df.with_columns(pl.col('Kategorische_Spalte').cast(pl.Categorical))\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#speicherplatz-freigeben_1","title":"Speicherplatz freigeben","text":"<p>Sicherstellen, dass wir den Speicher freigeben, indem wir gro\u00dfe DataFrames l\u00f6schen, wenn sie nicht mehr ben\u00f6tigt werden.</p> <pre><code>del df\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_im_umgang_mit_daten/#wichtige-erkenntnisse","title":"Wichtige Erkenntnisse","text":"<ul> <li>Vektorisierung ist unerl\u00e4sslich, um die Verarbeitungsgeschwindigkeit zu maximieren.</li> <li>Gezieltes Einlesen von Daten vermeidet unn\u00f6tige Speicherbelastung.</li> <li>Optimierte Datentypen sparen Speicherplatz und verbessern die Leistung.</li> <li>Speicherfreigabe verhindert Speicherlecks und gew\u00e4hrleistet die Effizienz von Anwendungen. </li> </ul>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/","title":"Optimierung von Python-Code","text":"<p>Die Effizienz unseres Python-Codes hat einen direkten Einfluss auf die Leistung unserer Anwendungen. Durch die Auswahl geeigneter Algorithmen und Datenstrukturen k\u00f6nnen wir nicht nur die Ausf\u00fchrungsgeschwindigkeit unserer Programme verbessern, sondern auch deren Lesbarkeit und Wartbarkeit erh\u00f6hen. Lass uns einige Beispiele f\u00fcr sowohl ineffizienten als auch effizienten Code betrachten.</p>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#verwendung-von-lru_cache","title":"Verwendung von <code>lru_cache</code>","text":"<p>Der <code>lru_cache</code>-Dekorator aus dem <code>functools</code>-Modul ist ein Tools, mit dem wir die Leistung von Funktionen zu steigern, die h\u00e4ufig mit denselben Argumenten aufgerufen werden. Er speichert die Ergebnisse von Funktionsaufrufen und gibt sie zur\u00fcck, wenn die Funktion erneut mit denselben Argumenten aufgerufen wird, wodurch unn\u00f6tige Berechnungen vermieden und die Ausf\u00fchrungszeit reduziert wird.</p>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#beispiel","title":"Beispiel","text":"<p>Unten siehst du ein Beispiel zur Berechnung von Fibonacci-Zahlen. Ohne <code>lru_cache</code> wird die Fibonacci-Sequenz rekursiv berechnet, was zu einer exponentiellen Laufzeit f\u00fchrt. Mit <code>lru_cache</code> werden die Ergebnisse zwischengespeichert, was die Berechnungen erheblich beschleunigt.</p> <pre><code>from functools import lru_cache\n\n# Fibonacci-Zahlen ohne lru_cache\ndef fibonacci(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci(n - 1) + fibonacci(n - 2)\n\nprint(fibonacci(10))  # Ausgabe: 55\n\n# Fibonacci-Zahlen mit lru_cache\n@lru_cache(maxsize=None)\ndef fibonacci_cached(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci_cached(n - 1) + fibonacci_cached(n - 2)\n\nprint(fibonacci_cached(10))  # Ausgabe: 55\n</code></pre> <p>Dieses Beispiel verdeutlicht den Unterschied zwischen der Berechnung von Fibonacci-Zahlen mit und ohne <code>lru_cache</code>. Die zwischengespeicherte Version ist aufgrund der Wiederverwendung zuvor berechneter Ergebnisse wesentlich schneller.</p>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#1-beispiele-fur-ineffizienten-und-effizienten-code","title":"1. Beispiele f\u00fcr ineffizienten und effizienten Code","text":""},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#beispiel-1-ineffiziente-schleifen","title":"Beispiel 1: Ineffiziente Schleifen","text":"<p>Ineffizienter Code:</p> <p>Hier wird eine Schleife verwendet, um die Summe aller geraden Zahlen in einer Liste mit einer Methode zu berechnen, die unn\u00f6tige \u00dcberpr\u00fcfungen durchf\u00fchrt.</p> <pre><code>def sum_even_numbers(numbers):\n    total = 0\n    for number in numbers:\n        if number % 2 == 0:\n            total += number\n    return total\n\n# Beispielaufruf\nzahlen = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nprint(sum_even_numbers(zahlen))  # Ausgabe: 30\n</code></pre> <p>Effizienter Code:</p> <p>Mit List Comprehensions k\u00f6nnen wir die Summe der geraden Zahlen effizienter und \u00fcbersichtlicher berechnen.</p> <pre><code>def sum_even_numbers(numbers):\n    return sum(number for number in numbers if number % 2 == 0)\n\n# Beispielaufruf\nzahlen = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nprint(sum_even_numbers(zahlen))  # Ausgabe: 30\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#2-beispiel-2-verwendung-von-datenstrukturen","title":"2. Beispiel 2: Verwendung von Datenstrukturen","text":"<p>Ineffizienter Code:</p> <p>Dieses Beispiel verwendet eine Liste, um doppelte Werte zu finden, was eine hohe Zeitkomplexit\u00e4t aufweist, da die Liste mehrfach durchlaufen werden muss.</p> <pre><code>def find_duplicates(values):\n    duplicates = []\n    for value in values:\n        if values.count(value) &gt; 1 and value not in duplicates:\n            duplicates.append(value)\n    return duplicates\n\n# Beispielaufruf\nwerte = [1, 2, 3, 1, 2, 4, 5]\nprint(find_duplicates(werte))  # Ausgabe: [1, 2]\n</code></pre> <p>Effizienter Code:</p> <p>Hier nutzen wir ein Set, um Duplikate effizient zu finden, da Sets schnelle Mitgliedschaftstests bieten.</p> <pre><code>def find_duplicates(values):\n    seen = set()\n    duplicates = set()\n    for value in values:\n        if value in seen:\n            duplicates.add(value)\n        else:\n            seen.add(value)\n    return list(duplicates)\n\n# Beispielaufruf\nwerte = [1, 2, 3, 1, 2, 4, 5]\nprint(find_duplicates(werte))  # Ausgabe: [1, 2]\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#3-aufgaben","title":"3. Aufgaben","text":"<p>Jetzt sind wir an der Reihe! In den folgenden Aufgaben bitten wir dich, den schlechten Code zu verbessern, um die Effizienz und Lesbarkeit zu steigern.</p>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#aufgabe-1-schleifenoptimierung","title":"Aufgabe 1: Schleifenoptimierung","text":"<p>Hier ist ein ineffizienter Code, der die Summe aller Zahlen in einer Liste berechnet. Verbessere ihn, indem du die Schleife optimierst.</p> <pre><code>def sum_numbers(numbers):\n    total = 0\n    for number in numbers:\n        total += number\n    return total\n\n# Beispielaufruf\nzahlen = [1, 2, 3, 4, 5]\nprint(sum_numbers(zahlen))  # Ausgabe: 15\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#aufgabe-2-nutzung-von-sets","title":"Aufgabe 2: Nutzung von Sets","text":"<p>In diesem Beispiel wird eine Liste verwendet, um die einzigartigen Werte aus einer anderen Liste zu extrahieren. Optimiere den Code, indem du Sets verwendest.</p> <pre><code>def unique_values(values):\n    unique = []\n    for value in values:\n        if value not in unique:\n            unique.append(value)\n    return unique\n\n# Beispielaufruf\nwerte = [1, 2, 2, 3, 4, 4, 5]\nprint(unique_values(werte))  # Ausgabe: [1, 2, 3, 4, 5]\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#ineffiziente-und-effiziente-pandas-codes","title":"Ineffiziente und effiziente Pandas-Codes","text":""},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#beispiel-1-ineffiziente-nutzung-von-schleifen","title":"Beispiel 1: Ineffiziente Nutzung von Schleifen","text":"<p>Ineffizienter Code:</p> <p>Diese Schleife berechnet die Quadratwerte einer Spalte, was ineffizient ist, da Pandas die Vektorisierung unterst\u00fctzt.</p> <pre><code>import pandas as pd\n\n# Beispiel-DataFrame erstellen\ndf = pd.DataFrame({'Zahlen': [1, 2, 3, 4, 5]})\n\n# Schleife zur Berechnung der Quadratwerte\nsquares = []\nfor i in range(len(df)):\n    squares.append(df['Zahlen'][i] ** 2)\n\ndf['Quadrate'] = squares\nprint(df)\n</code></pre> <p>Effizienter Code:</p> <p>Hier verwenden wir die Vektorisierung von Pandas, um die Quadratwerte effizient und \u00fcbersichtlich zu berechnen.</p> <pre><code># Vektorisierung zur Berechnung der Quadratwerte\ndf['Quadrate'] = df['Zahlen'] ** 2\nprint(df)\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#beispiel-2-mehrfache-berechnungen-in-einer-schleife","title":"Beispiel 2: Mehrfache Berechnungen in einer Schleife","text":"<p>Ineffizienter Code:</p> <p>Diese Schleife berechnet die durchschnittlichen Punktzahlen, was ineffizient ist, da die Berechnungen wiederholt werden.</p> <pre><code># Beispiel-DataFrame erstellen\ndf = pd.DataFrame({'Name': ['Alice', 'Bob', 'Charlie'],\n                   'Punkte1': [10, 20, 30],\n                   'Punkte2': [15, 25, 35]})\n\n# Durchschnittliche Punktzahlen berechnen\naverages = []\nfor i in range(len(df)):\n    avg = (df['Punkte1'][i] + df['Punkte2'][i]) / 2\n    averages.append(avg)\n\ndf['Durchschnitt'] = averages\nprint(df)\n</code></pre> <p>Effizienter Code:</p> <p>Wir berechnen die durchschnittlichen Punktzahlen effizient, indem wir die Vektorisierung nutzen.</p> <pre><code># Vektorisierung zur Berechnung der durchschnittlichen Punktzahlen\ndf['Durchschnitt'] = (df['Punkte1'] + df['Punkte2']) / 2\nprint(df)\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#beispiel-3-unnotige-verwendung-von-reset_index","title":"Beispiel 3: Unn\u00f6tige Verwendung von <code>reset_index()</code>","text":"<p>Ineffizienter Code:</p> <p>Hier wird <code>reset_index()</code> mehrfach unn\u00f6tig verwendet, was die Performance beeintr\u00e4chtigt.</p> <pre><code># Beispiel-DataFrame erstellen\ndf = pd.DataFrame({'Abteilung': ['A', 'B', 'A', 'B'],\n                   'Gehalt': [50000, 60000, 70000, 80000]})\n\n# Gruppierung und reset_index() mehrmals aufrufen\ngrouped = df.groupby('Abteilung')['Gehalt'].mean()\ngrouped_reset = grouped.reset_index()\nprint(grouped_reset)\n</code></pre> <p>Effizienter Code:</p> <p>Vermeiden wir das unn\u00f6tige Zur\u00fccksetzen des Index, indem wir die Aggregation direkt im DataFrame durchf\u00fchren.</p> <pre><code># Gruppierung ohne unn\u00f6tige reset_index()\ngrouped = df.groupby('Abteilung')['Gehalt'].mean().reset_index()\nprint(grouped)\n</code></pre>"},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#aufgabe","title":"Aufgabe","text":""},{"location":"effizienter_code_und_arbeitsspeicherressourcen/effizienter_code_in_python/#aufgabe-3-ineffiziente-filterung-von-dataframes","title":"Aufgabe 3: Ineffiziente Filterung von DataFrames","text":"<p>Ineffizienter Code:</p> <p>Dieser Code verwendet <code>apply()</code>, um Daten zu filtern, was ineffizient ist, da es eine Schleife \u00fcber alle Zeilen erfordert.</p> <pre><code># Beispiel-DataFrame erstellen\ndf = pd.DataFrame({'Alter': [25, 30, 35, 40, 45]})\n\n# Schleifenbasierte Filterung\nfiltered = df[df.apply(lambda row: row['Alter'] &gt; 30, axis=1)]\nprint(filtered)\n</code></pre> <p>Optimiere den Code, indem du die Vektorisierung nutzt.</p>"},{"location":"git/","title":"Git f\u00fcr Data Scientists","text":"<p>Git ist ein Versionskontrollsystem, das es uns erm\u00f6glicht, \u00c4nderungen an Code \u00fcber die Zeit zu verfolgen und mit Teams effizient zusammenzuarbeiten. In diesem Kapitel wiederholen wir kurz die Grundlagen und vertiefen uns dann in fortgeschrittene Themen wie Rebase, Cherry Picking und Commit-Konventionen.</p>"},{"location":"git/#1-grundlagen-von-git","title":"1. Grundlagen von Git","text":"<p>Bevor wir in fortgeschrittenere Themen eintauchen, wiederholen wir die wichtigsten Konzepte von Git:</p> <ul> <li>Repository (Repo): Ein Ordner, der die gesamte Historie der \u00c4nderungen eines Projekts speichert.</li> <li>Commit: Eine Momentaufnahme des aktuellen Zustands der Dateien. Jeder Commit hat eine eindeutige ID.</li> <li>Branch: Ein Zweig in der Versionsgeschichte, der es uns erlaubt, parallel an verschiedenen Features oder Fixes zu arbeiten.</li> <li>Merge: Das Zusammenf\u00fchren von zwei Branches.</li> <li>Remote: Die Online-Version eines Git-Repositories (z.B. auf GitHub oder GitLab).</li> </ul>"},{"location":"git/#wichtige-befehle","title":"Wichtige Befehle","text":"<ul> <li> <p>Initialisieren eines neuen Repos: <pre><code>git init\n</code></pre></p> </li> <li> <p>\u00c4nderungen zum Staging hinzuf\u00fcgen: <pre><code>git add &lt;datei&gt;\n</code></pre></p> </li> <li> <p>Einen Commit erstellen: <pre><code>git commit -m \"Beschreibung der \u00c4nderung\"\n</code></pre></p> </li> <li> <p>\u00c4nderungen auf einen Remote-Branch pushen: <pre><code>git push origin &lt;branch-name&gt;\n</code></pre></p> </li> </ul>"},{"location":"git/#2-fortgeschrittene-themen","title":"2. Fortgeschrittene Themen","text":""},{"location":"git/#21-git-rebase","title":"2.1 Git Rebase","text":"<p>Mit Rebase k\u00f6nnen wir eine saubere Versionsgeschichte zu erstellen, indem wir \u00c4nderungen aus einem Branch auf einem anderen neu anwenden, anstatt sie zu mergen. W\u00e4hrend ein Merge alle Commits aus beiden Branches beibeh\u00e4lt und einen \"Merge-Commit\" erstellt, ordnet Rebase die Commits neu an, sodass sie auf der Spitze des Ziel-Branches erscheinen, als ob sie von Anfang an dort gewesen w\u00e4ren.</p>"},{"location":"git/#wann-sollte-rebase-verwendet-werden","title":"Wann sollte Rebase verwendet werden?","text":"<ul> <li>Um eine saubere, lineare Historie zu erhalten.</li> <li>Wenn wir auf einem Feature-Branch gearbeitet haben und die \u00c4nderungen auf den aktuellen Stand des Haupt-Branches bringen wollen, ohne die Historie zu verkomplizieren.</li> </ul>"},{"location":"git/#beispiel-rebase-eines-feature-branches-auf-main","title":"Beispiel: Rebase eines Feature-Branches auf <code>main</code>","text":"<pre><code># Wir befinden uns auf dem Feature-Branch\ngit checkout feature-branch\n\n# Rebase den Feature-Branch auf den aktuellen Stand von main\ngit rebase main\n</code></pre>"},{"location":"git/#konflikte-wahrend-des-rebasing-losen","title":"Konflikte w\u00e4hrend des Rebasing l\u00f6sen","text":"<p>W\u00e4hrend eines Rebase-Vorgangs k\u00f6nnen Konflikte auftreten, wenn \u00c4nderungen auf den gleichen Zeilen einer Datei gemacht wurden. In diesem Fall wird Git den Rebase-Prozess anhalten, bis der Konflikt gel\u00f6st ist. Nach dem L\u00f6sen des Konflikts:</p> <pre><code># Konflikte manuell l\u00f6sen und Dateien zum Staging hinzuf\u00fcgen\ngit add &lt;datei&gt;\n\n# Rebase fortsetzen\ngit rebase --continue\n</code></pre>"},{"location":"git/#22-git-cherry-picking","title":"2.2 Git Cherry Picking","text":"<p>Cherry Picking erlaubt es uns, einen spezifischen Commit von einem Branch zu nehmen und ihn auf einen anderen Branch anzuwenden, ohne alle anderen \u00c4nderungen aus dem urspr\u00fcnglichen Branch mitzunehmen. Dies ist n\u00fctzlich, wenn wir einen bestimmten Fix oder ein Feature aus einem Branch isoliert in einen anderen einf\u00fcgen wollen.</p>"},{"location":"git/#wann-sollte-cherry-picking-verwendet-werden","title":"Wann sollte Cherry Picking verwendet werden?","text":"<ul> <li>Wenn ein Bugfix bereits in einem Feature-Branch existiert und wir ihn schnell in den Haupt-Branch \u00fcbernehmen m\u00fcssen, ohne den ganzen Branch zu mergen.</li> <li>Um spezifische Commits zwischen verschiedenen Branches zu \u00fcbertragen.</li> </ul>"},{"location":"git/#beispiel-cherry-picking-eines-commits","title":"Beispiel: Cherry Picking eines Commits","text":"<ol> <li> <p>Finde die Commit-ID, die du \u00fcbernehmen m\u00f6chtest:     <pre><code>git log\n</code></pre></p> </li> <li> <p>F\u00fchre den Cherry Pick-Vorgang durch:     <pre><code>git checkout main\ngit cherry-pick &lt;commit-id&gt;\n</code></pre></p> </li> </ol> <p>Falls Konflikte auftreten, m\u00fcssen diese manuell gel\u00f6st und der Cherry-Pick-Vorgang fortgesetzt werden:</p> <pre><code>git add &lt;datei&gt;\ngit cherry-pick --continue\n</code></pre>"},{"location":"git/#23-commit-konventionen-form","title":"2.3 Commit-Konventionen (Form)","text":"<p>Eine konsistente Commit-Message-Struktur hilft nicht nur bei der Lesbarkeit des Codes, sondern verbessert auch die Zusammenarbeit im Team und die Wartbarkeit des Projekts. Wir sollten eine klare Struktur f\u00fcr unsere Commit-Nachrichten einhalten.</p>"},{"location":"git/#eine-sinnvolle-commit-nachricht-besteht-aus","title":"Eine sinnvolle Commit-Nachricht besteht aus:","text":"<ol> <li>Header: Eine kurze, pr\u00e4gnante Zusammenfassung (max. 50 Zeichen), die beschreibt, was ge\u00e4ndert wurde.</li> <li>Body (optional): Ein detaillierterer Text, der erkl\u00e4rt, warum die \u00c4nderung vorgenommen wurde, welche Auswirkungen sie hat und ggf. wie sie implementiert wurde.</li> <li>Footer (optional): Zus\u00e4tzliche Informationen wie Referenzen zu Tickets oder Issues.</li> </ol>"},{"location":"git/#beispiel-einer-guten-commit-nachricht","title":"Beispiel einer guten Commit-Nachricht:","text":"<pre><code>fix(bug): Behebt das Problem beim Einlesen der CSV-Datei\n\nDas Problem wurde durch falsche Datentypen verursacht. Die \u00c4nderung\nstellt sicher, dass die korrekten Typen verwendet werden, wenn die Datei\neingelesen wird.\n\nFixes #123\n</code></pre>"},{"location":"git/best_practices/","title":"Best Practices","text":""},{"location":"git/best_practices/#best-practices-fur-git","title":"Best Practices f\u00fcr Git","text":""},{"location":"git/best_practices/#best-practices-fur-commit-nachrichten","title":"Best Practices f\u00fcr Commit-Nachrichten","text":"<ul> <li>Schreibe Commit-Nachrichten in der Befehlsform, z. B. \"F\u00fcgt eine neue Spalte hinzu\" anstelle von \"Neue Spalte wurde hinzugef\u00fcgt\".</li> <li>Vermeide generische Nachrichten wie \"Fix\" oder \"Update\", da sie keine sinnvolle Information \u00fcber die \u00c4nderung geben.</li> <li>Gruppiere kleine \u00c4nderungen in einem Commit, anstatt viele winzige Commits zu machen.</li> </ul>"},{"location":"git/best_practices/#best-practices-mit-branches-in-git","title":"Best Practices mit Branches in Git","text":"<p>Branching ist eine der m\u00e4chtigsten Funktionen von Git und erm\u00f6glicht es uns, parallel an verschiedenen Features, Bugfixes oder Experimenten zu arbeiten, ohne den Hauptzweig des Projekts zu beeintr\u00e4chtigen. Ein disziplinierter Umgang mit Branches sorgt f\u00fcr eine saubere Projektstruktur und erleichtert die Zusammenarbeit im Team. In diesem Abschnitt besprechen wir einige Best Practices f\u00fcr den effizienten Umgang mit Branches.</p>"},{"location":"git/best_practices/#1-verwende-eine-konsistente-branch-namenskonvention","title":"1. Verwende eine konsistente Branch-Namenskonvention","text":"<p>Eine klare und einheitliche Namenskonvention f\u00fcr Branches hilft dabei, den Zweck eines Branches sofort zu verstehen und Missverst\u00e4ndnisse im Team zu vermeiden. Hier einige g\u00e4ngige Konventionen:</p> <ul> <li>Feature-Branches: <code>feature/&lt;beschreibung&gt;</code><ul> <li>Beispiel: <code>feature/benutzer-login</code></li> </ul> </li> <li>Bugfix-Branches: <code>bugfix/&lt;beschreibung&gt;</code><ul> <li>Beispiel: <code>bugfix/csv-import-error</code></li> </ul> </li> <li>Hotfix-Branches (f\u00fcr kritische Fehler): <code>hotfix/&lt;beschreibung&gt;</code><ul> <li>Beispiel: <code>hotfix/sicherheitsl\u00fccke</code></li> </ul> </li> <li>Release-Branches: <code>release/&lt;version&gt;</code><ul> <li>Beispiel: <code>release/1.0.0</code></li> </ul> </li> </ul> <p>Eine klare Struktur und Beschreibung im Branch-Namen erleichtert es jedem im Team, den Zweck des Branches zu erkennen.</p>"},{"location":"git/best_practices/#2-isoliere-features-und-bugfixes-in-eigene-branches","title":"2. Isoliere Features und Bugfixes in eigene Branches","text":"<p>Jedem neuen Feature oder Bugfix sollte ein eigener Branch zugewiesen werden. Dies erm\u00f6glicht:</p> <ul> <li>Isolation von \u00c4nderungen: Features und Fixes k\u00f6nnen unabh\u00e4ngig voneinander entwickelt, getestet und integriert werden, ohne den Hauptbranch zu st\u00f6ren.</li> <li>Parallelit\u00e4t: Mehrere Teammitglieder k\u00f6nnen gleichzeitig an unterschiedlichen Features arbeiten, ohne in Konflikt zu geraten.</li> <li>R\u00fcckverfolgbarkeit: \u00c4nderungen sind leichter nachvollziehbar und jeder Branch repr\u00e4sentiert eine klar definierte Aufgabe.</li> </ul> <p>Beispiel:</p> <pre><code>git checkout -b feature/benutzer-authentifizierung\n</code></pre> <p>Nach dem Fertigstellen des Features oder Fixes wird der Branch in den Hauptbranch (meist <code>main</code> oder <code>develop</code>) gemerged.</p>"},{"location":"git/best_practices/#3-regelmaig-rebasen-oder-den-hauptbranch-mergen","title":"3. Regelm\u00e4\u00dfig rebasen oder den Hauptbranch mergen","text":"<p>Wenn du \u00fcber l\u00e4ngere Zeit an einem Feature-Branch arbeitest, ist es wichtig, den Branch regelm\u00e4\u00dfig mit dem Hauptbranch zu synchronisieren. Dies kann durch Merge oder Rebase geschehen:</p> <ul> <li>Merge: F\u00fchrt \u00c4nderungen des Hauptbranches in den Feature-Branch ein, beh\u00e4lt jedoch alle Historien bei.</li> </ul> <pre><code>git checkout feature/benutzer-login\ngit merge main\n</code></pre> <ul> <li>Rebase: Setzt den Feature-Branch auf den aktuellen Stand des Hauptbranches und erzeugt eine linearere Historie, da er \"so tut\", als ob die Arbeit immer auf dem neuesten Stand des Hauptbranches stattfand.</li> </ul> <pre><code>git checkout feature/benutzer-login\ngit rebase main\n</code></pre> <p>Durch regelm\u00e4\u00dfiges Rebasen oder Mergen vermeiden wir Konflikte und stellen sicher, dass unsere \u00c4nderungen mit der aktuellen Version kompatibel sind.</p>"},{"location":"git/best_practices/#4-kleine-fokussierte-branches-erstellen","title":"4. Kleine, fokussierte Branches erstellen","text":"<p>Branches sollten spezifische Aufgaben isolieren und nicht zu viele \u00c4nderungen auf einmal umfassen. Ein kleiner Branch ist einfacher zu testen, zu \u00fcberpr\u00fcfen und zu integrieren. Dies gilt besonders in Data-Science-Projekten, in denen Datenpipelines und Modelle oft schrittweise entwickelt werden. Ein paar Vorteile dieser Praxis sind:</p> <ul> <li>Schnellere Code-Reviews: Kleinere \u00c4nderungen sind schneller zu \u00fcberpr\u00fcfen.</li> <li>Weniger Konflikte: Je kleiner der Branch, desto weniger ist die Wahrscheinlichkeit, dass es zu Merge-Konflikten kommt.</li> <li>Bessere Nachvollziehbarkeit: Es ist leichter, spezifische \u00c4nderungen zu finden und r\u00fcckg\u00e4ngig zu machen.</li> </ul>"},{"location":"git/best_practices/#5-losche-branches-nach-dem-merge","title":"5. L\u00f6sche Branches nach dem Merge","text":"<p>Nach erfolgreichem Merge eines Branches in den Hauptbranch sollte der Branch gel\u00f6scht werden, um Verwirrung und \u00fcberfl\u00fcssige Branches zu vermeiden. Dies sorgt f\u00fcr eine saubere Git-Historie und vermeidet das Ansammeln von \"toten\" Branches.</p> <pre><code># Branch lokal l\u00f6schen\ngit branch -d feature/benutzer-login\n\n# Branch vom Remote l\u00f6schen\ngit push origin --delete feature/benutzer-login\n</code></pre>"},{"location":"git/best_practices/#6-trenne-entwicklungs-und-hauptbranch","title":"6. Trenne Entwicklungs- und Hauptbranch","text":"<p>Es empfiehlt sich, separate Branches f\u00fcr Entwicklung und Produktion zu haben:</p> <ul> <li> <p>Main-Branch (z.B. <code>main</code> oder <code>master</code>): Dieser Branch enth\u00e4lt die stabile und produktionsbereite Version des Projekts. Hier sollten nur gepr\u00fcfte und getestete Features gemerged werden.</p> </li> <li> <p>Entwicklungsbranch (z.B. <code>develop</code>): Der <code>develop</code>-Branch enth\u00e4lt die neusten, aber m\u00f6glicherweise noch nicht vollst\u00e4ndig stabilen Features. Neue Features und Fixes werden zuerst in <code>develop</code> gemerged, bevor sie nach umfassendem Testen in <code>main</code> \u00fcberf\u00fchrt werden.</p> </li> </ul>"},{"location":"git/best_practices/#7-nutze-pull-requests-fur-branch-merges","title":"7. Nutze Pull Requests f\u00fcr Branch-Merges","text":"<p>Ein guter Workflow ist, den Merge eines Branches \u00fcber einen Pull Request (PR) durchzuf\u00fchren. Pull Requests erm\u00f6glichen eine formale Code-\u00dcberpr\u00fcfung durch Teammitglieder, bevor der Code in den Hauptbranch integriert wird. Das sorgt f\u00fcr eine bessere Qualit\u00e4tssicherung und stellt sicher, dass alle \u00c4nderungen nachvollziehbar sind.</p>"},{"location":"git/best_practices/#umgang-mit-jupyter-notebooks-in-git-fur-data-science-projekte","title":"Umgang mit Jupyter Notebooks in Git f\u00fcr Data Science Projekte","text":"<p>Jupyter Notebooks sind in Data-Science-Projekten weit verbreitet, k\u00f6nnen jedoch in der Versionskontrolle einige Herausforderungen mit sich bringen. Da Notebooks nicht nur Code, sondern auch Metadaten und Ausgaben speichern, k\u00f6nnen sie bei mehreren \u00c4nderungen schwer lesbar und konfliktanf\u00e4llig werden. Hier sind einige Best Practices, um effizient mit Jupyter Notebooks in Git umzugehen:</p>"},{"location":"git/best_practices/#1-trenne-code-und-ausgaben","title":"1. Trenne Code und Ausgaben","text":"<p>Speichere keine Ausgaben (Plots, Tabellen, etc.) in den Notebooks, bevor du sie in Git commitest. Du kannst alle Ausgaben l\u00f6schen, indem du in Jupyter die Option \"Kernel &gt; Restart &amp; Clear Output\" w\u00e4hlst. Dadurch bleibt die Versionshistorie sauberer und reduziert Konflikte.</p> <pre><code># Beispiel: Notebook ohne Ausgaben speichern\njupyter nbconvert --clear-output --inplace &lt;notebook.ipynb&gt;\n</code></pre>"},{"location":"git/best_practices/#2-nutze-gitignore-fur-temporare-dateien","title":"2. Nutze <code>.gitignore</code> f\u00fcr tempor\u00e4re Dateien","text":"<p>Vermeide, dass unn\u00f6tige tempor\u00e4re Dateien wie Checkpoints oder Cache-Dateien ins Git-Repo gelangen, indem du sie in der <code>.gitignore</code>-Datei ausschlie\u00dft:</p> <pre><code># .gitignore\n.ipynb_checkpoints/\n</code></pre>"},{"location":"git/best_practices/#3-verwende-nbdime-fur-besseres-diffing-und-merging","title":"3. Verwende <code>nbdime</code> f\u00fcr besseres Diffing und Merging","text":"<p>Standard-Git-Diffs f\u00fcr Jupyter Notebooks sind oft schwer lesbar. Das Tool <code>nbdime</code> bietet eine spezialisierte M\u00f6glichkeit, Diffs von Notebooks klar darzustellen und Merge-Konflikte leichter zu l\u00f6sen:</p> <pre><code># Installation\npip install nbdime\n\n# Notebook-Diffs in Git einrichten\nnbdime config-git --enable\n</code></pre>"},{"location":"git/best_practices/#4-teile-code-als-python-module","title":"4. Teile Code als Python-Module","text":"<p>W\u00e4hrend der Entwicklung ist es oft sinnvoll, wiederverwendbare Funktionen und Pipelines in Python-Skripte auszulagern. Das h\u00e4lt die Notebooks leichtgewichtig und erleichtert die Wiederverwendbarkeit und Versionierung des Codes.</p> <pre><code># Beispiel: Funktionen in einem separaten Modul auslagern\nproject/\n\u2502\n\u251c\u2500\u2500 notebooks/\n\u2502   \u2514\u2500\u2500 analysis.ipynb\n\u2514\u2500\u2500 src/\n    \u2514\u2500\u2500 data_processing.py\n</code></pre>"},{"location":"git/gitignore/","title":"Umgang mit <code>.gitignore</code>","text":"<p>Die <code>.gitignore</code>-Datei ist ein essentielles Werkzeug, um unn\u00f6tige oder sensible Dateien von der Versionskontrolle auszuschlie\u00dfen. In Data Science Projekten entstehen h\u00e4ufig tempor\u00e4re Dateien, gro\u00dfe Datenbest\u00e4nde und Arbeitsprodukte wie Modelle oder Checkpoints, die nicht in Git gespeichert werden sollten. Eine saubere <code>.gitignore</code> sorgt daf\u00fcr, dass nur relevante Code- und Konfigurationsdateien versioniert werden, w\u00e4hrend Zwischenergebnisse und private Daten gesch\u00fctzt bleiben.</p>"},{"location":"git/gitignore/#typische-dateien-die-in-data-science-projekten-ignoriert-werden-sollten","title":"Typische Dateien, die in Data Science Projekten ignoriert werden sollten:","text":"<ul> <li>Daten: CSV, Excel, Parquet-Dateien und andere gro\u00dfe Datenbest\u00e4nde</li> <li>Modelle: Zwischengespeicherte Modelle und Checkpoints</li> <li>Notebooks: Checkpoints und tempor\u00e4re Dateien</li> <li>Virtuelle Umgebungen: Paketinstallationen und virtuelle Environments (z.B. <code>venv</code>, <code>conda</code>)</li> <li>Logdateien und tempor\u00e4re Ausgaben: Alles, was nur f\u00fcr tempor\u00e4re Berechnungen gebraucht wird (z.B. Logs, Cache)</li> </ul>"},{"location":"git/gitignore/#beispiel-gitignore-template-fur-data-science-projekte","title":"Beispiel <code>.gitignore</code>-Template f\u00fcr Data Science Projekte","text":"<p>Hier ist ein Beispiel f\u00fcr eine <code>.gitignore</code>-Datei, die f\u00fcr Data Science Projekte n\u00fctzlich sein kann:</p> <pre><code># Python Standard\n*.pyc\n__pycache__/\n*.pyo\n*.pyd\n.Python\n*.so\n\n# Jupyter Notebook Checkpoints\n.ipynb_checkpoints/\n\n# Virtual Environments\nenv/\nvenv/\n.venv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Conda Environments\n.conda/\n*.conda\n*.env\n*.yml\n\n# Data files\n*.csv\n*.tsv\n*.xls\n*.xlsx\n*.parquet\n*.feather\n*.h5\n*.hdf5\n*.db\n\n# Model files\n*.pkl\n*.joblib\n*.h5\n*.pb\n*.onnx\n\n# Logs und tempor\u00e4re Dateien\n*.log\n*.out\n*.tmp\n*.cache\n*.pid\n*.tar.gz\n*.zip\n\n# IDEs und Editoren\n.vscode/\n.idea/\n*.sublime-project\n*.sublime-workspace\n\n# DVC (falls verwendet)\n.dvc/\n\n# Docker und andere Umgebungen\n.dockerignore\ndocker-compose.yml\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/","title":"OOP &amp; Design Patterns / Strukturierte Projekte","text":""},{"location":"oop_design_patterns_projektstrukturen/#einfuhrung-in-oop-design-patterns-strukturierte-projekte","title":"Einf\u00fchrung in OOP &amp; Design Patterns / Strukturierte Projekte","text":"<p>In diesem Kapitel werden wir die Grundlagen der OOP in Python sowie fortgeschrittene Konzepte wie Design Patterns durch praktische Beispiele aus der Data Science Welt erarbeiten. Ein besonderer Fokus liegt dabei auf der Strukturierung von Data Science Projekten \u2013 von der Datenverarbeitung \u00fcber die Modellierung bis hin zur Ausgabe der Ergebnisse.</p>"},{"location":"oop_design_patterns_projektstrukturen/#warum-oop-in-data-science","title":"Warum OOP in Data Science?","text":"<p>Traditionell wird Data Science oft prozedural umgesetzt, indem Skripte geschrieben werden, die schrittweise Daten verarbeiten und Modelle trainieren. Diese Herangehensweise hat jedoch Grenzen, insbesondere wenn Projekte gr\u00f6\u00dfer werden oder wiederverwendbar sein sollen. Mit OOP k\u00f6nnen wir: - Komplexe Datenverarbeitungsprozesse in wiederverwendbare Klassen und Methoden kapseln. - Flexiblere Pipelines erstellen, bei denen wir Methoden oder Algorithmen leicht austauschen k\u00f6nnen. - Bessere Wartbarkeit erreichen, da der Code modularer und klar strukturiert ist.</p>"},{"location":"oop_design_patterns_projektstrukturen/abstrakte_klassen_und_schnittstellen/","title":"Abstrakte Klassen und Schnittstellen","text":"<p>In der objektorientierten Programmierung bieten abstrakte Klassen und Schnittstellen (Interfaces) ein m\u00e4chtiges Werkzeug, um wiederverwendbare und strukturierte Software-Architekturen zu gestalten. Sie erm\u00f6glichen es uns, generische Verarbeitungslogiken zu definieren, die dann von spezialisierteren Klassen erweitert und angepasst werden k\u00f6nnen. Insbesondere in Data Science Projekten, in denen oft mehrere unterschiedliche Datenquellen oder Verarbeitungsschritte zu verwalten sind, erleichtern abstrakte Klassen und Schnittstellen die Erstellung flexibler Pipelines.</p>"},{"location":"oop_design_patterns_projektstrukturen/abstrakte_klassen_und_schnittstellen/#was-ist-eine-abstrakte-klasse","title":"Was ist eine abstrakte Klasse?","text":"<p>Eine abstrakte Klasse dient als Vorlage f\u00fcr andere Klassen und kann nicht direkt instanziiert werden. Sie enth\u00e4lt in der Regel abstrakte Methoden, die von den abgeleiteten Klassen implementiert werden m\u00fcssen. Abstrakte Klassen bieten uns die M\u00f6glichkeit, allgemeine Funktionalit\u00e4ten zu definieren, die von den spezialisierten Klassen konkretisiert werden.</p> <p>Im Data Science Kontext kann man sich eine abstrakte Klasse als allgemeine Beschreibung eines Verarbeitungsschrittes oder einer Datenquelle vorstellen. Zum Beispiel k\u00f6nnten alle Datenquellen (CSV-Dateien, SQL-Datenbanken, APIs) eine gemeinsame Methode zur Datenbeschaffung haben, die in der abstrakten Klasse definiert, aber in den abgeleiteten Klassen unterschiedlich implementiert wird.</p> <p>Beispiel: Abstrakte Klasse f\u00fcr Datenquellen</p> <pre><code>from abc import ABC, abstractmethod\nimport pandas as pd\n\nclass DatenQuelle(ABC):\n    @abstractmethod\n    def lade_daten(self):\n        pass\n\nclass CSVQuelle(DatenQuelle):\n    def __init__(self, dateipfad):\n        self.dateipfad = dateipfad\n\n    def lade_daten(self):\n        return pd.read_csv(self.dateipfad)\n\nclass SQLQuelle(DatenQuelle):\n    def __init__(self, verbindungsstring, query):\n        self.verbindungsstring = verbindungsstring\n        self.query = query\n\n    def lade_daten(self):\n        # Simuliert den SQL-Datenabruf\n        return pd.DataFrame({\"Spalte1\": [1, 2], \"Spalte2\": [3, 4]})\n</code></pre> <p>In diesem Beispiel haben wir eine abstrakte Klasse <code>DatenQuelle</code> definiert, die die abstrakte Methode <code>lade_daten()</code> enth\u00e4lt. Diese Methode wird in den spezialisierten Klassen <code>CSVQuelle</code> und <code>SQLQuelle</code> implementiert, die die konkrete Logik zum Laden der Daten aus der jeweiligen Quelle bereitstellen.</p>"},{"location":"oop_design_patterns_projektstrukturen/abstrakte_klassen_und_schnittstellen/#schnittstellen-in-python","title":"Schnittstellen in Python","text":"<p>W\u00e4hrend Python keine echten \"Interfaces\" wie andere Sprachen (z.B. Java) hat, k\u00f6nnen wir durch den Einsatz abstrakter Klassen und Methoden \u00e4hnliche Strukturen schaffen. Schnittstellen definieren lediglich die Methoden, die eine Klasse implementieren muss, ohne dabei Logik vorzugeben. Sie f\u00f6rdern lose Kopplung und machen Code flexibler und einfacher erweiterbar.</p> <p>Nehmen wir ein Data Science Pipeline Szenario: Unterschiedliche Schritte wie \"Vorverarbeitung\", \"Feature Engineering\" und \"Modellierung\" k\u00f6nnen durch Schnittstellen abstrahiert werden, um sicherzustellen, dass jede Klasse die gleichen Methoden implementiert, w\u00e4hrend die Details unterschiedlich sind.</p> <p>Beispiel: Abstrakte Klasse f\u00fcr eine Pipeline</p> <pre><code>class Verarbeitungsschritt(ABC):\n    @abstractmethod\n    def verarbeite(self, daten: pd.DataFrame) -&gt; pd.DataFrame:\n        pass\n\nclass Skalierung(Verarbeitungsschritt):\n    def verarbeite(self, daten: pd.DataFrame) -&gt; pd.DataFrame:\n        return (daten - daten.mean()) / daten.std()\n\nclass KategorischeKodierung(Verarbeitungsschritt):\n    def verarbeite(self, daten: pd.DataFrame) -&gt; pd.DataFrame:\n        return pd.get_dummies(daten)\n</code></pre> <p>Hier definiert die abstrakte Klasse <code>Verarbeitungsschritt</code> die Methode <code>verarbeite()</code>, die f\u00fcr jeden Schritt der Datenverarbeitung implementiert werden muss. Die spezialisierte Klasse <code>Skalierung</code> f\u00fchrt z.B. eine Standardisierung der Daten durch, w\u00e4hrend <code>KategorischeKodierung</code> eine One-Hot-Encoding-Transformation anwendet.</p>"},{"location":"oop_design_patterns_projektstrukturen/abstrakte_klassen_und_schnittstellen/#verwendung-von-abstrakten-klassen-in-data-science-pipelines","title":"Verwendung von abstrakten Klassen in Data Science Pipelines","text":"<p>In komplexen Data Science Projekten k\u00f6nnen abstrakte Klassen dazu beitragen, einzelne Verarbeitungsschritte und Datenquellen standardisiert zu behandeln. Dadurch wird es einfacher, neue Schritte oder Datenquellen hinzuzuf\u00fcgen, ohne den bestehenden Code \u00e4ndern zu m\u00fcssen. Diese Flexibilit\u00e4t ist besonders n\u00fctzlich, wenn man mit verschiedenen Datens\u00e4tzen oder Modellen arbeitet.</p> <p>Beispiel: Flexible Pipeline mit abstrakten Klassen</p> <pre><code>class Pipeline:\n    def __init__(self):\n        self.schritte = []\n\n    def hinzufuegen_schritt(self, schritt: Verarbeitungsschritt):\n        self.schritte.append(schritt)\n\n    def ausfuehren(self, daten: pd.DataFrame) -&gt; pd.DataFrame:\n        for schritt in self.schritte:\n            daten = schritt.verarbeite(daten)\n        return daten\n\n# Pipeline erstellen\npipeline = Pipeline()\n#pipeline.hinzufuegen_schritt(Skalierung()) #Funktioniert nur bei numerischen Daten\npipeline.hinzufuegen_schritt(KategorischeKodierung())\n\n# Beispiel-Daten\ndaten = pd.DataFrame({\n    'Alter': [25, 32, 47],\n    'Geschlecht': ['m\u00e4nnlich', 'weiblich', 'm\u00e4nnlich']\n})\n\n# Pipeline ausf\u00fchren\nverarbeitete_daten = pipeline.ausfuehren(daten)\nprint(verarbeitete_daten)\n</code></pre> <p>Hier f\u00fcgen wir verschiedene Verarbeitungsschritte zur Pipeline hinzu und f\u00fchren sie auf die Daten aus. Dies zeigt die St\u00e4rke der Abstraktion: Wir k\u00f6nnen leicht neue Schritte zur Pipeline hinzuf\u00fcgen, ohne den Rest des Codes \u00e4ndern zu m\u00fcssen.</p>"},{"location":"oop_design_patterns_projektstrukturen/abstrakte_klassen_und_schnittstellen/#aufgaben","title":"Aufgaben","text":"<ol> <li> <p>Abstrakte Klassen erweitern:    Implementiere eine weitere Klasse <code>APIZugriff</code>, die von <code>DatenQuelle</code> erbt und Daten aus einer API l\u00e4dt (du kannst den API-Zugriff simulieren, indem du ein statisches DataFrame zur\u00fcckgibst).</p> </li> <li> <p>Neue Verarbeitungsschritte:    Erstelle einen neuen Verarbeitungsschritt <code>Normalisierung</code>, der eine Min-Max-Normalisierung auf numerische Daten anwendet und ihn zur bestehenden Pipeline hinzuf\u00fcgt.</p> </li> <li> <p>Verwende die Pipeline mit verschiedenen Datenquellen:    Implementiere die Pipeline so, dass sie mit Daten aus verschiedenen Quellen (<code>CSVQuelle</code>, <code>SQLQuelle</code>) flexibel arbeiten kann.</p> </li> </ol>"},{"location":"oop_design_patterns_projektstrukturen/best_practices/","title":"Best Practices f\u00fcr OOP in Data Science Projekten","text":"<p>In der Softwareentwicklung sind Best Practices von entscheidender Bedeutung, um sauberen, wartbaren und effizienten Code zu schreiben. Insbesondere in Data Science Projekten, in denen Datenverarbeitung, Modellierung und Analyse oft komplex sind, k\u00f6nnen wir durch die Anwendung bew\u00e4hrter Prinzipien die Qualit\u00e4t unseres Codes erheblich steigern. In diesem Abschnitt konzentrieren wir uns auf wichtige Prinzipien wie KISS (Keep it Simple, Stupid), DRY (Don\u2019t Repeat Yourself) und weitere Leitlinien, die uns helfen, OOP in unseren Data Science Projekten effektiv umzusetzen.</p>"},{"location":"oop_design_patterns_projektstrukturen/best_practices/#1-kiss-keep-it-simple-stupid","title":"1. KISS \u2013 Keep it Simple, Stupid","text":"<p>Das KISS-Prinzip ermutigt uns, einfach zu denken und einfache L\u00f6sungen zu bevorzugen. In Data Science Projekten ist es oft verlockend, komplexe L\u00f6sungen zu entwickeln, insbesondere wenn es um Datenverarbeitung oder Modellierung geht. Doch oft k\u00f6nnen einfache Ans\u00e4tze effektiver und leichter wartbar sein.</p> <p>Beispiel: Anstatt eine komplexe Kette von Transformationen zu erstellen, k\u00f6nnen wir kleinere, klar definierte Schritte verwenden, die sp\u00e4ter kombiniert werden.</p> <pre><code># Komplexe Transformation\nclass KomplexeDatenverarbeitung:\n    def verarbeite(self, df):\n        # ... viele Schritte ...\n        return df\n\n# Einfache, modulare Transformation\nclass EinfacheDatenverarbeitung:\n    def bereinigen(self, df):\n        return df.dropna()\n\n    def transformieren(self, df):\n        return df.apply(lambda x: x * 2)\n\n# Nutzung der einfachen Verarbeitung\ndatenverarbeitung = EinfacheDatenverarbeitung()\ndaten = datenverarbeitung.bereinigen(df)\ndaten = datenverarbeitung.transformieren(daten)\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/best_practices/#2-dry-dont-repeat-yourself","title":"2. DRY \u2013 Don\u2019t Repeat Yourself","text":"<p>Das DRY-Prinzip fordert uns auf, Redundanz im Code zu vermeiden. Wiederholungen f\u00fchren nicht nur zu unn\u00f6tiger Komplexit\u00e4t, sondern erschweren auch die Wartung, da \u00c4nderungen an mehreren Stellen vorgenommen werden m\u00fcssen. Durch die Definition von Funktionen oder Klassen f\u00fcr wiederkehrende Aufgaben k\u00f6nnen wir den Code effizienter gestalten.</p> <p>Beispiel: Anstatt die gleiche Berechnung in verschiedenen Klassen zu wiederholen, definieren wir eine gemeinsame Methode.</p> <pre><code>class Statistik:\n    @staticmethod\n    def berechne_mittelwert(df, spalte):\n        return df[spalte].mean()\n\n# Wiederverwendbare Berechnung in verschiedenen Analysen\nclass AnalyseA:\n    def analyse(self, df):\n        mittelwert = Statistik.berechne_mittelwert(df, 'sales')\n        # Weitere Analysen...\n\nclass AnalyseB:\n    def analyse(self, df):\n        mittelwert = Statistik.berechne_mittelwert(df, 'profit')\n        # Weitere Analysen...\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/best_practices/#3-single-responsibility-principle-srp","title":"3. Single Responsibility Principle (SRP)","text":"<p>Das Single Responsibility Principle besagt, dass jede Klasse nur f\u00fcr eine einzige Aufgabe zust\u00e4ndig sein sollte. In Data Science Projekten bedeutet das, dass wir Klassen und Methoden so gestalten, dass sie jeweils eine klar definierte Funktion erf\u00fcllen. Dies verbessert die Wartbarkeit und Testbarkeit des Codes.</p> <p>Beispiel: Eine Klasse f\u00fcr Datenbeschaffung und eine andere f\u00fcr Datenanalyse.</p> <pre><code>class DatenLoader:\n    def lade_csv(self, dateipfad):\n        # Lade CSV-Daten\n        pass\n\nclass DatenAnalysator:\n    def analysiere(self, df):\n        # F\u00fchre Datenanalysen durch\n        pass\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/best_practices/#4-openclosed-principle-ocp","title":"4. Open/Closed Principle (OCP)","text":"<p>Das Open/Closed Principle besagt, dass Softwareelemente offen f\u00fcr Erweiterungen, aber geschlossen f\u00fcr \u00c4nderungen sein sollten. Dies bedeutet, dass wir neue Funktionalit\u00e4ten hinzuf\u00fcgen k\u00f6nnen, ohne bestehenden Code zu \u00e4ndern. In Data Science Projekten k\u00f6nnen wir dies erreichen, indem wir abstrakte Klassen und Vererbung nutzen.</p> <p>Beispiel: Ein allgemeines Modell f\u00fcr verschiedene Algorithmen.</p> <pre><code>class Modell:\n    def trainiere(self, X, y):\n        raise NotImplementedError\n\nclass Entscheidungsbaum(Modell):\n    def trainiere(self, X, y):\n        # Training des Entscheidungsbaum-Modells\n        pass\n\nclass RandomForest(Modell):\n    def trainiere(self, X, y):\n        # Training des Random Forest-Modells\n        pass\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/best_practices/#5-verwendung-von-design-patterns","title":"5. Verwendung von Design Patterns","text":"<p>Das Verst\u00e4ndnis und die Anwendung von Design Patterns in der OOP helfen uns, bew\u00e4hrte L\u00f6sungen f\u00fcr h\u00e4ufige Probleme zu implementieren. Muster wie das Factory Pattern oder das Strategy Pattern k\u00f6nnen uns helfen, unsere Projekte robuster und flexibler zu gestalten.</p> <p>Beispiel: Verwendung des Factory Patterns zur Erstellung von Modellen.</p> <pre><code>class ModellFactory:\n    @staticmethod\n    def erstelle_modell(modell_typ):\n        if modell_typ == 'entscheidungsbaum':\n            return Entscheidungsbaum()\n        elif modell_typ == 'random_forest':\n            return RandomForest()\n\n# Erstellen eines Modells \u00fcber die Factory\nmodell = ModellFactory.erstelle_modell('random_forest')\nmodell.trainiere(X, y)\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/","title":"Design Patterns in Data Science Projekten","text":"<p>Design Patterns sind wiederkehrende L\u00f6sungsans\u00e4tze f\u00fcr h\u00e4ufig auftretende Entwurfsprobleme in der Softwareentwicklung. In Data Science Projekten, die oft komplexe und sich wiederholende Prozesse beinhalten, k\u00f6nnen Design Patterns dabei helfen, Code wartbarer, flexibler und effizienter zu gestalten. Der Einsatz von Design Patterns erm\u00f6glicht eine klare Strukturierung von Projekten, die das Verst\u00e4ndnis und die Zusammenarbeit im Team erleichtert. Im Folgenden gehen wir auf einige wichtige Design Patterns ein, die in Data Science Projekten n\u00fctzlich sein k\u00f6nnen.</p>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/#vorteile-der-nutzung-von-design-patterns-in-data-science-projekten","title":"Vorteile der Nutzung von Design Patterns in Data Science Projekten","text":"<ol> <li>Wartbarkeit: Muster sorgen f\u00fcr einen strukturierten und modularen Code, der leichter zu pflegen ist.</li> <li>Wiederverwendbarkeit: Einmal implementierte Design Patterns k\u00f6nnen in anderen Projekten oder Szenarien wiederverwendet werden.</li> <li>Erweiterbarkeit: Mit Patterns wird es einfacher, neuen Code hinzuzuf\u00fcgen, ohne den bestehenden Code zu \u00e4ndern oder zu brechen.</li> <li>Teamarbeit: Klar definierte Muster erleichtern es Teams, sich in bestehende Codebasen einzuarbeiten und an einem Projekt zu arbeiten.</li> <li>Effizienz: Durch die Verwendung optimierter L\u00f6sungen lassen sich h\u00e4ufige Probleme schneller und eleganter l\u00f6sen.</li> </ol>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/#creational-patterns","title":"Creational Patterns","text":"<p>Diese Muster befassen sich mit der Erzeugung von Objekten. Im Kontext von Data Science helfen sie, Objekte wie Datenquellen oder Datenverarbeitungsmodelle auf flexible Weise zu erzeugen.</p>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/#factory-pattern-erzeugen-von-datenverarbeitungsobjekten","title":"Factory Pattern: Erzeugen von Datenverarbeitungsobjekten","text":"<p>Das Factory Pattern wird verwendet, um Objekte zu erstellen, ohne die genauen Klassen anzugeben. In Data Science k\u00f6nnen wir es verwenden, um unterschiedliche Datenquellen (z.B. CSV, SQL, API) mit einer einheitlichen Methode zu erstellen.</p> <p>Beispiel: Factory Pattern f\u00fcr Datenquellen</p> <pre><code>class DatenQuelleFactory:\n    def erstelle_datenquelle(self, typ, **kwargs):\n        if typ == 'csv':\n            return CSVQuelle(kwargs['dateipfad'])\n        elif typ == 'sql':\n            return SQLQuelle(kwargs['verbindungsstring'], kwargs['query'])\n        elif typ == 'api':\n            return APIQuelle(kwargs['url'])\n\n# Verwendung\nfactory = DatenQuelleFactory()\ndatenquelle = factory.erstelle_datenquelle('csv', dateipfad='daten.csv')\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/#singleton-pattern-sicherstellen-dass-nur-eine-datenbankverbindung-existiert","title":"Singleton Pattern: Sicherstellen, dass nur eine Datenbankverbindung existiert","text":"<p>Das Singleton Pattern wird verwendet, um sicherzustellen, dass eine Klasse nur eine einzige Instanz hat. Bei der Verbindung zu Datenbanken ist es oft sinnvoll, nur eine Verbindung offen zu halten, um Ressourcen zu schonen.</p> <p>Beispiel: Singleton Pattern f\u00fcr Datenbankverbindung</p> <pre><code>class Datenbankverbindung:\n    _instance = None\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super(Datenbankverbindung, cls).__new__(cls)\n            # Simulierte Verbindung\n            cls._instance.verbindung = \"SQL Datenbank Verbindung\"\n        return cls._instance\n\n# Verwendung\nverbindung1 = Datenbankverbindung()\nverbindung2 = Datenbankverbindung()\n\nprint(verbindung1 is verbindung2)  # True\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/#structural-patterns","title":"Structural Patterns","text":"<p>Diese Muster befassen sich mit der Strukturierung von Klassen und Objekten und deren Zusammensetzung.</p>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/#adapter-pattern-anpassung-verschiedener-datenquellen-an-eine-einheitliche-api","title":"Adapter Pattern: Anpassung verschiedener Datenquellen an eine einheitliche API","text":"<p>Das Adapter Pattern hilft, Schnittstellen inkompatibler Klassen anzupassen, ohne die Klassen selbst zu ver\u00e4ndern. In Data Science k\u00f6nnen wir dieses Muster nutzen, um verschiedene Datenquellen (z.B. CSV, SQL, APIs) so anzupassen, dass sie alle mit derselben API angesprochen werden k\u00f6nnen.</p> <p>Beispiel: Adapter Pattern f\u00fcr Datenquellen</p> <pre><code>class CSVAdapter:\n    def __init__(self, csv_quelle):\n        self.csv_quelle = csv_quelle\n\n    def lade_daten(self):\n        return self.csv_quelle.lade_daten()\n\nclass SQLAdapter:\n    def __init__(self, sql_quelle):\n        self.sql_quelle = sql_quelle\n\n    def lade_daten(self):\n        return self.sql_quelle.lade_daten()\n\n# Jetzt k\u00f6nnen beide Quellen mit der gleichen Methode verwendet werden\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/#decorator-pattern-erweiterung-von-datenverarbeitungsfunktionen-zb-logging","title":"Decorator Pattern: Erweiterung von Datenverarbeitungsfunktionen (z.B. Logging)","text":"<p>Mit dem Decorator Pattern k\u00f6nnen wir bestehenden Funktionen zus\u00e4tzliche Funktionalit\u00e4ten hinzuf\u00fcgen, ohne sie zu ver\u00e4ndern. Beispielsweise k\u00f6nnten wir eine Datenverarbeitungsfunktion erweitern, um automatisch Log-Eintr\u00e4ge zu erstellen.</p> <p>Beispiel: Decorator f\u00fcr Logging in Pandas</p> <pre><code>def log_verarbeitung(funktion):\n    def wrapper(*args, **kwargs):\n        print(f\"Start der Verarbeitung: {funktion.__name__}\")\n        ergebnis = funktion(*args, **kwargs)\n        print(f\"Ende der Verarbeitung: {funktion.__name__}\")\n        return ergebnis\n    return wrapper\n\n@log_verarbeitung\ndef bereinige_daten(daten):\n    # Simulierte Bereinigung\n    return daten.dropna()\n\n# Verwendung\ndaten = pd.DataFrame({\"Alter\": [25, None, 47], \"Geschlecht\": ['m\u00e4nnlich', 'weiblich', None]})\nbereinige_daten(daten)\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/#behavioral-patterns","title":"Behavioral Patterns","text":"<p>Behavioral Patterns befassen sich mit der Interaktion zwischen Objekten und der Zuweisung von Verantwortlichkeiten.</p>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/#observer-pattern-ereignisgesteuerte-updates-fur-groe-datenverarbeitungen","title":"Observer Pattern: Ereignisgesteuerte Updates f\u00fcr gro\u00dfe Datenverarbeitungen","text":"<p>Das Observer Pattern erm\u00f6glicht es Objekten, auf \u00c4nderungen oder Ereignisse zu reagieren. In Data Science Projekten k\u00f6nnen wir dieses Muster verwenden, um bestimmte Aktionen automatisch auszuf\u00fchren, wenn Daten sich \u00e4ndern, z.B. bei Live-Datenverarbeitungen oder Dashboards.</p> <p>Beispiel: Observer Pattern f\u00fcr Datenverarbeitung</p> <pre><code>class Beobachter:\n    def update(self, daten):\n        pass\n\nclass LoggingBeobachter(Beobachter):\n    def update(self, daten):\n        print(f\"Neue Daten verarbeitet: {daten}\")\n\nclass DatenVerarbeiter:\n    def __init__(self):\n        self.beobachter = []\n\n    def hinzufuegen_beobachter(self, beobachter):\n        self.beobachter.append(beobachter)\n\n    def verarbeite(self, daten):\n        # Simulierte Datenverarbeitung\n        for beobachter in self.beobachter:\n            beobachter.update(daten)\n\n# Verwendung\nverarbeiter = DatenVerarbeiter()\nverarbeiter.hinzufuegen_beobachter(LoggingBeobachter())\nverarbeiter.verarbeite(pd.DataFrame({\"Alter\": [25, 32, 47]}))\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/#strategy-pattern-austauschbare-algorithmen-fur-die-datenanalyse","title":"Strategy Pattern: Austauschbare Algorithmen f\u00fcr die Datenanalyse","text":"<p>Das Strategy Pattern erm\u00f6glicht es, Algorithmen zur Laufzeit auszutauschen, ohne den restlichen Code zu \u00e4ndern. In Data Science Projekten kann dies verwendet werden, um unterschiedliche Machine Learning Modelle dynamisch zu laden und anzuwenden.</p> <p>Beispiel: Strategy Pattern f\u00fcr Machine Learning Modelle</p> <pre><code>class ModellStrategie:\n    def trainiere(self, daten):\n        pass\n\nclass LineareRegression(ModellStrategie):\n    def trainiere(self, daten):\n        print(\"Training mit Linearer Regression\")\n\nclass Entscheidungsbaum(ModellStrategie):\n    def trainiere(self, daten):\n        print(\"Training mit Entscheidungsbaum\")\n\nclass ModellTrainer:\n    def __init__(self, strategie: ModellStrategie):\n        self.strategie = strategie\n\n    def setze_strategie(self, strategie: ModellStrategie):\n        self.strategie = strategie\n\n    def trainiere(self, daten):\n        self.strategie.trainiere(daten)\n\n# Verwendung\ntrainer = ModellTrainer(LineareRegression())\ntrainer.trainiere(pd.DataFrame({\"Feature1\": [1, 2, 3], \"Ziel\": [1, 0, 1]}))\n\n# Strategie \u00e4ndern\ntrainer.setze_strategie(Entscheidungsbaum())\ntrainer.trainiere(pd.DataFrame({\"Feature1\": [1, 2, 3], \"Ziel\": [1, 0, 1]}))\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/design_patterns/#praktische-implementierung-von-design-patterns-in-python","title":"Praktische Implementierung von Design Patterns in Python","text":"<p>Python bietet durch seine dynamische Natur und flexiblen Sprachfeatures viele M\u00f6glichkeiten, Design Patterns einfach zu implementieren. Eine Herausforderung dabei ist, dass Python weniger strikte Typensysteme als andere Sprachen hat, was zu weniger offensichtlichen Fehlern f\u00fchren kann. Die konsequente Verwendung von Patterns kann hier helfen, Struktur und Sicherheit in Projekte zu bringen.</p>"},{"location":"oop_design_patterns_projektstrukturen/prinzipien_oop/","title":"Grundprinzipien der OOP","text":"<p>Die objektorientierte Programmierung (OOP) basiert auf vier zentralen Prinzipien, die den Umgang mit komplexen Datenstrukturen und Prozessen effizienter gestalten: Abstraktion, Kapselung, Vererbung und Polymorphismus. Diese Prinzipien erm\u00f6glichen es uns, sauberen, wiederverwendbaren und leicht wartbaren Code zu schreiben.</p>"},{"location":"oop_design_patterns_projektstrukturen/prinzipien_oop/#abstraktion","title":"Abstraktion","text":"<p>Abstraktion bedeutet, dass nur die wesentlichen Informationen eines Objekts dargestellt werden, w\u00e4hrend unn\u00f6tige Details verborgen bleiben. In der Praxis erm\u00f6glicht Abstraktion die Reduzierung von Komplexit\u00e4t, indem wir uns auf die wichtigen Eigenschaften und Funktionen eines Objekts konzentrieren.</p> <p>Beispiel:</p> <pre><code>from abc import ABC, abstractmethod\n\nclass ZahlungsMethode(ABC):\n    @abstractmethod\n    def zahlen(self, betrag):\n        pass\n\nclass Kreditkarte(ZahlungsMethode):\n    def zahlen(self, betrag):\n        print(f\"Bezahlung von {betrag}\u20ac mit Kreditkarte\")\n\nclass PayPal(ZahlungsMethode):\n    def zahlen(self, betrag):\n        print(f\"Bezahlung von {betrag}\u20ac mit PayPal\")\n</code></pre> <p>Hier stellt die abstrakte Klasse <code>ZahlungsMethode</code> die allgemeine Idee der Zahlung dar, ohne auf spezifische Implementierungen einzugehen. Die konkreten Zahlungsarten wie Kreditkarte und PayPal werden von ihr abgeleitet und implementieren die <code>zahlen</code>-Methode auf unterschiedliche Weise.</p> <p>Aufgabe: Erstelle eine abstrakte Klasse <code>Fahrzeug</code> mit der abstrakten Methode <code>fahren()</code>. Implementiere zwei konkrete Klassen, <code>Auto</code> und <code>Fahrrad</code>, die jeweils <code>fahren()</code> spezifisch umsetzen.</p>"},{"location":"oop_design_patterns_projektstrukturen/prinzipien_oop/#kapselung","title":"Kapselung","text":"<p>Kapselung bezieht sich auf das Verbergen von Daten und die Einschr\u00e4nkung des Zugriffs auf bestimmte Teile eines Objekts. Dies sch\u00fctzt die internen Zust\u00e4nde und verhindert unbeabsichtigte \u00c4nderungen.</p> <p>Beispiel:</p> <pre><code>class Konto:\n    def __init__(self, saldo):\n        self.__saldo = saldo  # private Variable\n\n    def einzahlen(self, betrag):\n        self.__saldo += betrag\n\n    def get_saldo(self):\n        return self.__saldo\n\nkonto = Konto(1000)\nkonto.einzahlen(500)\nprint(konto.get_saldo())  # Ausgabe: 1500\n</code></pre> <p>In diesem Beispiel ist das Attribut <code>__saldo</code> privat und kann nicht direkt von au\u00dfen ver\u00e4ndert werden. Der Zugriff erfolgt \u00fcber die Methode <code>get_saldo()</code>.</p> <p>Aufgabe: Erstelle eine Klasse <code>Benutzer</code>, die den Namen und das Passwort eines Benutzers kapselt. Das Passwort soll nur innerhalb der Klasse sichtbar sein, aber durch eine Methode ge\u00e4ndert werden k\u00f6nnen.</p>"},{"location":"oop_design_patterns_projektstrukturen/prinzipien_oop/#vererbung","title":"Vererbung","text":"<p>Vererbung erlaubt es uns, eine Klasse von einer anderen abzuleiten, sodass die abgeleitete Klasse die Eigenschaften und Methoden der Basisklasse erbt. Dies f\u00f6rdert die Wiederverwendbarkeit von Code.</p> <p>Beispiel:</p> <pre><code>class Fahrzeug:\n    def __init__(self, marke):\n        self.marke = marke\n\n    def fahren(self):\n        print(f\"{self.marke} f\u00e4hrt los\")\n\nclass Auto(Fahrzeug):\n    def hupen(self):\n        print(f\"{self.marke} hupt\")\n\nauto = Auto(\"BMW\")\nauto.fahren()  # Ausgabe: BMW f\u00e4hrt los\nauto.hupen()   # Ausgabe: BMW hupt\n</code></pre> <p>Hier erbt die Klasse <code>Auto</code> die Methode <code>fahren</code> von der Basisklasse <code>Fahrzeug</code> und erweitert sie um eine eigene Methode <code>hupen</code>.</p> <p>Aufgabe: Erstelle eine Basisklasse <code>Mitarbeiter</code> mit der Methode <code>arbeiten()</code>. Leite von dieser Klasse <code>Manager</code> und <code>Verk\u00e4ufer</code> ab, die beide die Methode <code>arbeiten()</code> spezifisch umsetzen.</p>"},{"location":"oop_design_patterns_projektstrukturen/prinzipien_oop/#polymorphismus","title":"Polymorphismus","text":"<p>Polymorphismus erm\u00f6glicht es uns, auf unterschiedliche Arten auf dieselbe Methode zuzugreifen, abh\u00e4ngig davon, welches Objekt diese Methode aufruft. Dies erlaubt uns, flexible und austauschbare Code-Strukturen zu schaffen.</p> <p>Beispiel:</p> <pre><code>class Tier:\n    def laut(self):\n        pass\n\nclass Hund(Tier):\n    def laut(self):\n        print(\"Wuff\")\n\nclass Katze(Tier):\n    def laut(self):\n        print(\"Miau\")\n\ndef tier_geraeusch(tier):\n    tier.laut()\n\nhund = Hund()\nkatze = Katze()\n\ntier_geraeusch(hund)  # Ausgabe: Wuff\ntier_geraeusch(katze)  # Ausgabe: Miau\n</code></pre> <p>In diesem Beispiel rufen sowohl <code>Hund</code> als auch <code>Katze</code> die Methode <code>laut()</code> auf, aber mit unterschiedlichen Implementierungen.</p> <p>Aufgabe: Erstelle eine Funktion <code>rechnen()</code>, die mit verschiedenen Objekten von Rechenklassen (z.B. <code>Addition</code>, <code>Subtraktion</code>) arbeitet, die jeweils eine Methode <code>berechnen()</code> besitzen. Implementiere zwei Klassen, die jeweils die Berechnung spezifisch umsetzen.</p>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/","title":"Strukturierung von Data Science Projekten mit OOP","text":"<p>Die Strukturierung von Data Science Projekten ist entscheidend f\u00fcr die Wartbarkeit, Wiederverwendbarkeit und Skalierbarkeit des Codes. Objektorientierte Programmierung (OOP) bietet eine klare M\u00f6glichkeit, die Logik eines Projekts zu organisieren, indem sie es erm\u00f6glicht, Daten und Funktionen zu kapseln und klare Schnittstellen zu schaffen. In diesem Abschnitt betrachten wir die Vorteile von OOP-Architekturen, die Modulaufteilung und Ordnerstrukturen, die Klassenstruktur f\u00fcr die Datenverarbeitung und Analyse sowie die Trennung von Gesch\u00e4ftslogik und Datenzugriff.</p>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/#vorteile-von-oop-architekturen-in-data-science","title":"Vorteile von OOP-Architekturen in Data Science","text":"<ol> <li> <p>Wiederverwendbarkeit: Durch die Erstellung generischer Klassen und Methoden k\u00f6nnen wir wiederverwendbaren Code schreiben, der in verschiedenen Projekten verwendet werden kann.</p> </li> <li> <p>Modularit\u00e4t: OOP f\u00f6rdert die Modularit\u00e4t, indem es Funktionen und Daten in separaten Klassen organisiert. Dies erleichtert das Testen und die Wartung.</p> </li> <li> <p>Klarheit und Lesbarkeit: OOP erm\u00f6glicht es, den Code in logische Einheiten zu gliedern, was die Lesbarkeit verbessert und es einfacher macht, den Code zu verstehen.</p> </li> <li> <p>Erweiterbarkeit: Neue Funktionen k\u00f6nnen durch Vererbung und Polymorphismus leicht hinzugef\u00fcgt werden, ohne bestehende Codebasen zu ver\u00e4ndern.</p> </li> <li> <p>Encapsulation: Die Kapselung von Daten und Methoden innerhalb von Klassen hilft, den Zustand der Anwendung zu sch\u00fctzen und unbefugte Zugriffe zu verhindern.</p> </li> </ol>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/#klassenstruktur-fur-datenverarbeitung-und-analyse","title":"Klassenstruktur f\u00fcr Datenverarbeitung und Analyse","text":"<p>In einer OOP-Architektur kann die Datenverarbeitung durch spezialisierte Klassen organisiert werden. Hier ist ein Beispiel f\u00fcr eine einfache Klassenstruktur, die Datenverarbeitungs- und Analyseklassen beschreibt:</p> <pre><code># src/data/data_loader.py\nimport pandas as pd\n\nclass DatenLoader:\n    def lade_csv(self, dateipfad):\n        return pd.read_csv(dateipfad)\n\n    def lade_sql(self, verbindungsstring, query):\n        # Implementierung des SQL-Ladevorgangs\n        pass\n\n# src/models/model.py\nfrom sklearn.linear_model import LinearRegression\n\nclass ModellTrainer:\n    def __init__(self):\n        self.model = LinearRegression()\n\n    def trainiere(self, X, y):\n        self.model.fit(X, y)\n\n    def vorhersage(self, X):\n        return self.model.predict(X)\n</code></pre> <p>In diesem Beispiel haben wir separate Klassen f\u00fcr das Laden von Daten und f\u00fcr das Trainieren von Modellen, was die Wartbarkeit und Wiederverwendbarkeit des Codes erh\u00f6ht.</p>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/#trennung-von-geschaftslogik-und-datenzugriff","title":"Trennung von Gesch\u00e4ftslogik und Datenzugriff","text":"<p>Eine der besten Praktiken in der Softwareentwicklung besteht darin, die Gesch\u00e4ftslogik von der Datenzugriffslogik zu trennen. Dadurch wird der Code flexibler und einfacher zu testen. In Data Science Projekten bedeutet dies, dass wir separate Klassen f\u00fcr den Zugriff auf Daten (Datenbankzugriffe, APIs, etc.) und f\u00fcr die Anwendung unserer Gesch\u00e4ftslogik (Datenanalyse, Modelltraining) erstellen.</p> <pre><code># src/data/data_accessor.py\nclass DatenAccessor:\n    def __init__(self, loader):\n        self.loader = loader\n\n    def lade_daten(self, quelle):\n        if quelle['typ'] == 'csv':\n            return self.loader.lade_csv(quelle['pfad'])\n        elif quelle['typ'] == 'sql':\n            return self.loader.lade_sql(quelle['verbindungsstring'], quelle['query'])\n\n# src/analysis/analyze.py\nclass DatenAnalysator:\n    def __init__(self, model_trainer, daten_accessor):\n        self.model_trainer = model_trainer\n        self.daten_accessor = daten_accessor\n\n    def analysiere(self, quelle):\n        daten = self.daten_accessor.lade_daten(quelle)\n        # Weitere Datenanalyse und Modelltraining\n</code></pre> <p>In diesem Beispiel wird die <code>DatenAccessor</code>-Klasse zur Handhabung des Datenzugriffs verwendet, w\u00e4hrend die <code>DatenAnalysator</code>-Klasse f\u00fcr die Gesch\u00e4ftslogik zust\u00e4ndig ist. Diese klare Trennung erleichtert nicht nur das Testen und die Wartung des Codes, sondern macht auch die Erweiterung um neue Datenquellen oder Analysemethoden einfacher.</p>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/#projektstruktur-fur-ein-data-science-projekt-in-python","title":"Projektstruktur f\u00fcr ein Data Science Projekt in Python","text":"<p>Die Organisation eines Data Science Projekts kann den Unterschied zwischen einem klar strukturierten, wartbaren Projekt und einem verworrenen Chaos ausmachen. Lassen Sie uns gemeinsam die bew\u00e4hrte Praxis einer effektiven Projektstruktur erkunden, die Ihnen hilft, den \u00dcberblick zu behalten und effizienter zu arbeiten.</p>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/#readmemd","title":"README.md","text":"<p>Beginnen wir mit der README-Datei, die als erste Anlaufstelle f\u00fcr jeden dient, der Ihr Projekt erkunden m\u00f6chte. Diese Datei sollte eine pr\u00e4gnante Erkl\u00e4rung des Projekts enthalten: Warum existiert es, wie ist es strukturiert, und welche Konventionen werden verwendet? Denken Sie daran, dass das \"Warum\" hier von entscheidender Bedeutung ist, um den Kontext zu vermitteln.</p>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/#verzeichnisstruktur","title":"Verzeichnisstruktur","text":"<p>In unserer Projektstruktur bekommt alles seinen eigenen Platz. Alle projektbezogenen Elemente sollten untergeordneten Verzeichnissen unter einem Hauptverzeichnis zugeordnet werden.</p> <p>Beispielstruktur:</p> <pre><code>/path/to/project/directory/\n|- notebooks/\n   |- 01-einleitung.ipynb\n   |- 02-analyse.ipynb\n   |- prototypen/\n      |- erster-entwurf.ipynb\n|- projectname/\n   |- projectname/\n      |- __init__.py\n      |- config.py\n      |- utils.py\n   |- setup.py\n|- data/\n   |- raw/\n   |- processed/\n   |- cleaned/\n|- scripts/\n   |- datentransformation.py\n   |- visualisierung.py\n|- environment.yml\n|- README.md\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/#notebooks","title":"notebooks/","text":"<p>In diesem Verzeichnis organisieren wir alle Jupyter-Notebooks des Projekts. Diese Notebooks sollten in logische Abschnitte unterteilt und entsprechend benannt sein, z.B. <code>01-einleitung.ipynb</code>. Dies hilft uns, eine narrative Struktur innerhalb des Projekts zu entwickeln. Prototypen oder veraltete Notebooks k\u00f6nnen in separaten Unterverzeichnissen wie <code>prototypen/</code> oder <code>archive/</code> abgelegt werden.</p>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/#projectname","title":"projectname/","text":"<p>Unter diesem Verzeichnis erstellen wir ein leichtgewichtiges Python-Paket, das alles enth\u00e4lt, was aus den Notebooks herausgekapselt wird, um sie sauber zu halten. Die <code>__init__.py</code>-Datei erm\u00f6glicht es uns, Funktionen und Variablen in unsere Notebooks oder Skripte zu importieren.</p> <p>config.py: Enth\u00e4lt spezielle Pfade und Variablen, die im gesamten Projekt verwendet werden. Beispielsweise k\u00f6nnten hier Datenbankverbindungen oder Dateipfade festgelegt werden.</p> <p>utils.py: Hier legen wir benutzerdefinierte Funktionen ab, die in verschiedenen Notebooks oder Skripten verwendet werden. Dies f\u00f6rdert die Wiederverwendbarkeit und h\u00e4lt den Code sauber.</p>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/#data","title":"data/","text":"<p>Das <code>data/</code>-Verzeichnis ist in <code>raw/</code>, <code>processed/</code> und <code>cleaned/</code> unterteilt, um den Status der Daten zu kennzeichnen. Ein README in diesem Verzeichnis kann Informationen \u00fcber die Herkunft der Daten und den Zweck der verschiedenen Dateien enthalten.</p>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/#scripts","title":"scripts/","text":"<p>Hier sammeln wir alle Skripte, die nicht Teil der Notebook-Narrative sind. Diese k\u00f6nnen Aufgaben wie die Datenvorverarbeitung oder das Erstellen von Visualisierungen \u00fcbernehmen.</p>"},{"location":"oop_design_patterns_projektstrukturen/projektstrukturen/#setuppy","title":"setup.py","text":"<p>Zum Schluss enth\u00e4lt unser Projekt eine <code>setup.py</code>, die es uns erm\u00f6glicht, das Python-Paket lokal zu installieren. Dies ist besonders n\u00fctzlich, wenn mehrere Personen an dem Projekt arbeiten und eine gemeinsame Codebasis ben\u00f6tigen.</p> <p>Durch die Einhaltung dieser Projektstruktur k\u00f6nnen wir nicht nur die Lesbarkeit und Wartbarkeit unseres Codes verbessern, sondern auch eine klare Trennung zwischen verschiedenen Komponenten des Projekts gew\u00e4hrleisten. Dies erleichtert die Zusammenarbeit und die Skalierung des Projekts erheblich.</p> <p>Dies ist nur ein Beispiel, wie die Projektstruktur aussehen kann. Je nach eingesetztem Tech-Stack und den Anforderungen des Projekts kann die Struktur variieren. Beispielsweise kann ein <code>/tests</code>-Verzeichnis f\u00fcr Unit-Tests oder ein <code>/reports</code>-Verzeichnis f\u00fcr Berichte hinzugef\u00fcgt werden.</p> <p>Um einen Grundlegenden Projektaufbau zu generieren, k\u00f6nnen wir beispielsweise daas Tool Cookiecutter verwenden, das uns erlaubt, Projektvorlagen zu erstellen und zu verwalten.</p>"},{"location":"oop_design_patterns_projektstrukturen/solid/","title":"Solid","text":""},{"location":"oop_design_patterns_projektstrukturen/solid/#solid-prinzipien-in-python","title":"SOLID-Prinzipien in Python","text":"<p>Die SOLID-Prinzipien sind eine Sammlung von Designprinzipien, die darauf abzielen, Software leicht wartbar, erweiterbar und stabil zu machen. Sie sind besonders n\u00fctzlich in gr\u00f6\u00dferen Projekten, bei denen es auf sauberen Code und modulare Architektur ankommt. Im Kontext des Einzelhandels \u2013 zum Beispiel zur Verwaltung von Verkaufsprozessen, Produkten oder Kunden \u2013 helfen sie uns, flexible und erweiterbare Systeme zu bauen.</p> <p>Die SOLID-Prinzipien sind: 1. Single Responsibility Principle (SRP) \u2013 Eine Klasse sollte nur eine Verantwortung haben. 2. Open/Closed Principle (OCP) \u2013 Eine Klasse sollte offen f\u00fcr Erweiterungen, aber geschlossen f\u00fcr Modifikationen sein. 3. Liskov Substitution Principle (LSP) \u2013 Subklassen sollten ihre Basisklassen ohne Ver\u00e4nderung des Verhaltens ersetzen k\u00f6nnen. 4. Interface Segregation Principle (ISP) \u2013 Schnittstellen (Interfaces) sollten klein und spezifisch sein. 5. Dependency Inversion Principle (DIP) \u2013 H\u00f6herwertige Module sollten nicht von niedrigeren Modulen abh\u00e4ngig sein. Beide sollten von Abstraktionen abh\u00e4ngen.</p>"},{"location":"oop_design_patterns_projektstrukturen/solid/#1-single-responsibility-principle-srp","title":"1. Single Responsibility Principle (SRP)","text":"<p>Das SRP besagt, dass jede Klasse nur f\u00fcr eine Aufgabe verantwortlich sein sollte. Dies macht den Code einfacher zu warten und zu erweitern, da \u00c4nderungen in einem Bereich nicht zu Nebeneffekten in einem anderen f\u00fchren.</p> <p>Beispiel:</p> <pre><code>class Produkt:\n    def __init__(self, name, preis):\n        self.name = name\n        self.preis = preis\n\nclass ProduktDatenbank:\n    def speichere_produkt(self, produkt):\n        print(f\"{produkt.name} wurde in der Datenbank gespeichert.\")\n</code></pre> <p>Hier hat die Klasse <code>Produkt</code> nur die Verantwortung, ein Produkt zu beschreiben. Die Verantwortung f\u00fcr das Speichern in der Datenbank liegt bei der Klasse <code>ProduktDatenbank</code>.</p> <p>Aufgabe: \u00c4ndere den folgenden Code so, dass er das SRP beachtet:</p> <pre><code>class BestellSystem:\n    def verarbeite_bestellung(self, produkt, kunde):\n        print(f\"{produkt.name} wurde an {kunde.name} verkauft.\")\n        print(f\"Rechnung f\u00fcr {produkt.preis}\u20ac an {kunde.email} gesendet.\")\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/solid/#2-openclosed-principle-ocp","title":"2. Open/Closed Principle (OCP)","text":"<p>Das OCP besagt, dass Klassen offen f\u00fcr Erweiterungen, aber geschlossen f\u00fcr \u00c4nderungen sein sollten. Das bedeutet, dass wir das Verhalten einer Klasse erweitern k\u00f6nnen, ohne den bestehenden Code zu ver\u00e4ndern.</p> <p>Beispiel:</p> <pre><code>class Rabatt:\n    def berechne_rabatt(self, preis):\n        return preis  # Keine Rabatte standardm\u00e4\u00dfig\n\nclass MitgliederRabatt(Rabatt):\n    def berechne_rabatt(self, preis):\n        return preis * 0.9  # 10% Rabatt f\u00fcr Mitglieder\n</code></pre> <p>Hier k\u00f6nnen wir die Rabattlogik erweitern, indem wir neue Rabattarten hinzuf\u00fcgen, ohne den bestehenden Code zu \u00e4ndern.</p> <p>Aufgabe: Erweitere den folgenden Code, um einen \"SommerRabatt\" zu implementieren, ohne den bestehenden Code zu \u00e4ndern:</p> <pre><code>class Rabatt:\n    def berechne_rabatt(self, preis):\n        return preis\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/solid/#3-liskov-substitution-principle-lsp","title":"3. Liskov Substitution Principle (LSP)","text":"<p>Das LSP besagt, dass Objekte einer Subklasse durch Objekte ihrer Basisklasse ersetzt werden k\u00f6nnen, ohne das Verhalten zu ver\u00e4ndern. Eine Subklasse sollte sich also immer wie ihre Basisklasse verhalten.</p> <p>Beispiel:</p> <pre><code>class Kunde:\n    def zahle(self, betrag):\n        print(f\"Zahle {betrag}\u20ac\")\n\nclass VIPKunde(Kunde):\n    def zahle(self, betrag):\n        print(f\"Zahle {betrag * 0.8}\u20ac (VIP-Rabatt)\")\n</code></pre> <p>Hier kann ein <code>VIPKunde</code> ohne Anpassung der Logik \u00fcberall dort verwendet werden, wo auch ein <code>Kunde</code> verwendet wird.</p> <p>Aufgabe: Schreibe eine Klasse <code>OnlineKunde</code>, die sich wie <code>Kunde</code> verh\u00e4lt, aber zus\u00e4tzlich eine Liefergeb\u00fchr berechnet, ohne das LSP zu verletzen.</p>"},{"location":"oop_design_patterns_projektstrukturen/solid/#4-interface-segregation-principle-isp","title":"4. Interface Segregation Principle (ISP)","text":"<p>Das ISP besagt, dass Schnittstellen (Interfaces) klein und spezifisch sein sollten, damit Klassen nur die Methoden implementieren m\u00fcssen, die sie wirklich ben\u00f6tigen.</p> <p>Beispiel:</p> <pre><code>class LieferbareProdukte:\n    def lieferung_berechnen(self, produkt):\n        pass\n\nclass AbholbareProdukte:\n    def abholung_organisieren(self, produkt):\n        pass\n</code></pre> <p>Hier gibt es separate Schnittstellen f\u00fcr Produkte, die geliefert werden, und solche, die abgeholt werden. Eine Klasse muss also nur die Methoden implementieren, die sie wirklich ben\u00f6tigt.</p> <p>Aufgabe: Passe den folgenden Code an, sodass nicht alle Produkte beide Methoden implementieren m\u00fcssen:</p> <pre><code>class Produkt:\n    def lieferung_berechnen(self):\n        pass\n\n    def abholung_organisieren(self):\n        pass\n</code></pre>"},{"location":"oop_design_patterns_projektstrukturen/solid/#5-dependency-inversion-principle-dip","title":"5. Dependency Inversion Principle (DIP)","text":"<p>Das DIP besagt, dass h\u00f6herwertige Module nicht von spezifischen Implementierungen niedrigerer Module abh\u00e4ngig sein sollten, sondern beide von Abstraktionen abh\u00e4ngen sollten. Dies f\u00f6rdert die Flexibilit\u00e4t und Austauschbarkeit von Komponenten.</p> <p>Beispiel:</p> <pre><code>class Datenbank:\n    def speichere(self, daten):\n        pass\n\nclass ProduktVerwaltung:\n    def __init__(self, datenbank: Datenbank):\n        self.datenbank = datenbank\n\n    def speichere_produkt(self, produkt):\n        self.datenbank.speichere(produkt)\n</code></pre> <p>Hier h\u00e4ngt die <code>ProduktVerwaltung</code> nur von der abstrakten <code>Datenbank</code> ab, sodass die tats\u00e4chliche Implementierung (z.B. SQL-Datenbank, In-Memory-Datenbank) leicht austauschbar ist.</p> <p>Aufgabe: \u00c4ndere den folgenden Code so, dass er das DIP beachtet:</p> <pre><code>class SQLDatenbank:\n    def speichere(self, daten):\n        print(\"Speichern in SQL-Datenbank\")\n\nclass ProduktVerwaltung:\n    def speichere_produkt(self, produkt):\n        datenbank = SQLDatenbank()\n        datenbank.speichere(produkt)\n</code></pre>"},{"location":"pydantic/","title":"Pydantic","text":"<p>Python ist standardm\u00e4\u00dfig eine dynamisch typisierte Sprache, was bedeutet, dass Variablen nicht explizit mit einem Datentyp deklariert werden m\u00fcssen. Dies kann jedoch zu unerwarteten Fehlern f\u00fchren, wenn die Daten nicht den erwarteten Typen entsprechen. Pydantic ist eine Bibliothek, die es erm\u00f6glicht, Datenmodelle zu definieren und zu validieren, um sicherzustellen, dass die Daten den erwarteten Typen entsprechen.</p> <p>In diesem Abschnitt werden wir uns ein Paar grundlegegende Konzepte von Pydantic ansehen und wie wir sie in unseren Projekten verwenden k\u00f6nnen.</p>"},{"location":"pydantic/#models","title":"Models","text":"<p>Ein Modell in Pydantic ist eine Klasse, die Datenattribute definiert und validiert. Ein Modell wird durch eine Klasse definiert, die von der Klasse <code>pydantic.BaseModel</code> erbt. Die Datenattribute werden als Klassenvariablen definiert, die durch Typenannotationen gekennzeichnet sind.</p> <pre><code>from pydantic import BaseModel\n\nclass User(BaseModel):\n    id: int\n    name: str\n    email: str\n</code></pre> <p>In diesem Beispiel definiert das Modell <code>User</code> drei Datenattribute: <code>id</code>, <code>name</code> und <code>email</code>, die die Typen <code>int</code>, <code>str</code> und <code>str</code> haben. Durch die Verwendung von Pydantic k\u00f6nnen wir sicherstellen, dass die Daten, die wir in ein <code>User</code>-Objekt einf\u00fcgen, den erwarteten Typen entsprechen.</p> <pre><code>user = User(id=1, name='Alice', email='alice@im-wunderland.de')\nprint(user)\n# User id=1 name='Alice'\n</code></pre>"},{"location":"pydantic/#validierung","title":"Validierung","text":"<p>Pydantic validiert die Daten automatisch, wenn wir ein Modell instanziieren. Wenn die Daten nicht den erwarteten Typen entsprechen, wird eine <code>ValidationError</code> ausgel\u00f6st.</p> <p>Wie k\u00f6nnen die Validierung theorethisch auch manuell ausl\u00f6sen: 1. <code>model_validate()</code>:    - Validiert Daten in Form eines W\u00f6rterbuchs oder eines Objekts.    - Wirft einen <code>ValidationError</code>, wenn die Eingabe ung\u00fcltig ist oder kein W\u00f6rterbuch/Objekt vom Modelltyp ist.</p> <ol> <li><code>model_validate_json()</code>:</li> <li>Validiert Daten, die als JSON-String oder -Bytes vorliegen.</li> <li> <p>Ist schneller als manuelles Parsen, wenn die Eingabedaten im JSON-Format sind.</p> </li> <li> <p><code>model_validate_strings()</code>:</p> </li> <li>Nimmt ein W\u00f6rterbuch mit Zeichenketten als Schl\u00fcssel und Werte (auch verschachtelt).</li> <li>Zwingt diese Zeichenketten, in die richtigen Datentypen konvertiert zu werden.</li> </ol> <p>Beispiele:</p> <ul> <li> <p><code>model_validate()</code>: Validierung eines W\u00f6rterbuchs.    <pre><code>m = User.model_validate({'id': 123, 'name': 'James'})\nprint(m)  # id=123 name='James' signup_ts=None\n</code></pre>    Bei ung\u00fcltigen Eingabedaten wird ein <code>ValidationError</code> ausgel\u00f6st.</p> </li> <li> <p><code>model_validate_json()</code>: Validierung von JSON-Daten.    <pre><code>m = User.model_validate_json('{\"id\": 123, \"name\": \"James\"}')\nprint(m)  # id=123 name='James' signup_ts=None\n</code></pre></p> </li> <li> <p><code>model_validate_strings()</code>: Konvertiert Zeichenketten in entsprechende Datentypen.    <pre><code>m = User.model_validate_strings({'id': '123', 'name': 'James'})\nprint(m)  # id=123 name='James' signup_ts=None\n</code></pre></p> </li> </ul> <p>Bei fehlerhaften Zeichenketten-Daten wird ein <code>ValidationError</code> ausgel\u00f6st.</p>"},{"location":"pydantic/dataclasses/","title":"Dataclasses","text":""},{"location":"pydantic/dataclasses/#dataclasses-in-pydantic","title":"Dataclasses in Pydantic","text":"<p>Pydantic bietet die M\u00f6glichkeit, Python-Dataclasses um Validierungslogik und zus\u00e4tzliche Features zu erweitern. Normalerweise sind Dataclasses einfache Container f\u00fcr Daten, die keine eingebaute Validierung oder Konvertierung bieten. Pydantic-Dataclasses hingegen f\u00fcgen diesen Funktionen eine starke Datenvalidierung hinzu, \u00e4hnlich wie bei einem <code>BaseModel</code>.</p> <p>Wir k\u00f6nnen die Dataclass von Pydantic als wie eine Erweiterung der built-in Dataclass in Python sehen.</p>"},{"location":"pydantic/dataclasses/#beispiel-pydantic-dataclass","title":"Beispiel: Pydantic-Dataclass","text":"<pre><code>from pydantic import dataclasses, ValidationError\n\n@dataclasses.dataclass\nclass Produkt:\n    id: int\n    name: str\n    preis: float\n\n# Instanziierung eines Produkts\ntry:\n    produkt = Produkt(id=\"123\", name=\"Laptop\", preis=\"999.99\")  # Automatische Konvertierung\n    print(produkt)\nexcept ValidationError as e:\n    print(e)\n</code></pre> <p>In diesem Beispiel wird eine Pydantic-Dataclass verwendet, die eine automatische Typkonvertierung und Validierung durchf\u00fchrt. Hier wird z.B. die <code>id</code> und <code>preis</code> von einem <code>str</code> in den korrekten Typ umgewandelt (<code>int</code> und <code>float</code>).</p>"},{"location":"pydantic/dataclasses/#unterschiede-zwischen-einer-normalen-dataclass-und-einer-pydantic-dataclass","title":"Unterschiede zwischen einer normalen Dataclass und einer Pydantic-Dataclass","text":"<p>Eine normale Python-Dataclass bietet keine Datenvalidierung oder Typkonvertierung. Alle Felder m\u00fcssen beim Instanziieren der Klasse bereits den richtigen Typ haben, da Python-Dataclasses keine eingebaute Pr\u00fcfung durchf\u00fchren.</p>"},{"location":"pydantic/dataclasses/#normale-dataclass","title":"Normale Dataclass","text":"<pre><code>from dataclasses import dataclass\n\n@dataclass\nclass Produkt:\n    id: int\n    name: str\n    preis: float\n\n# Instanziierung mit falschen Typen f\u00fchrt zu keinem Fehler, sondern falschem Verhalten\nprodukt = Produkt(id=\"123\", name=\"Laptop\", preis=\"999.99\")\nprint(produkt)  # Dies wird fehlerhaft ausgef\u00fchrt, weil die Typen nicht konvertiert werden\n</code></pre> <p>Hier wird keine Typkonvertierung durchgef\u00fchrt. Wenn die Felder falsche Typen haben, wie <code>id</code> als <code>str</code> anstatt <code>int</code>, f\u00fchrt dies zu Problemen bei der sp\u00e4teren Verwendung, ohne dass ein Fehler gemeldet wird.</p>"},{"location":"pydantic/dataclasses/#vorteile-der-pydantic-dataclass-gegenuber-der-normalen-dataclass","title":"Vorteile der Pydantic-Dataclass gegen\u00fcber der normalen Dataclass:","text":"<ul> <li>Automatische Typkonvertierung: Pydantic-Dataclasses konvertieren Eingabewerte automatisch in die erwarteten Typen.</li> <li>Eingebaute Validierung: Jede Zuweisung wird validiert. Falsche Typen oder ung\u00fcltige Werte f\u00fchren zu einem <code>ValidationError</code>.</li> <li>Leichte Integration in Pydantic-\u00d6kosystem: Pydantic-Dataclasses unterst\u00fctzen JSON-Schema-Generierung und lassen sich leicht mit anderen Pydantic-Features kombinieren.</li> </ul>"},{"location":"pydantic/dataclasses/#nachteile-der-pydantic-dataclass-gegenuber-einem-basemodel","title":"Nachteile der Pydantic-Dataclass gegen\u00fcber einem <code>BaseModel</code>","text":"<p>W\u00e4hrend Pydantic-Dataclasses viele Vorteile gegen\u00fcber normalen Dataclasses bieten, gibt es einige Einschr\u00e4nkungen im Vergleich zu einem Pydantic <code>BaseModel</code>:</p> <ol> <li> <p>Leistung: Pydantic-Dataclasses sind im Vergleich zu <code>BaseModel</code>-Objekten etwas langsamer, da sie durch Python-Dataclasses eingeschr\u00e4nkt sind und nicht alle Optimierungen von Pydantic \u00fcbernehmen k\u00f6nnen.</p> </li> <li> <p>Fehlende Methoden: Ein <code>BaseModel</code> bietet viele n\u00fctzliche Methoden, wie z.B. <code>.json()</code>, <code>.dict()</code> und <code>.copy()</code>, die f\u00fcr die Serialisierung und Manipulation von Daten sehr praktisch sind. Diese fehlen bei Pydantic-Dataclasses.</p> </li> <li> <p>Mehr Flexibilit\u00e4t in <code>BaseModel</code>: <code>BaseModel</code>-Objekte bieten umfassendere Konfigurationsm\u00f6glichkeiten. Einige Fehldtypen von <code>BaseModel</code> sind in Pydantic <code>dataclasses</code> nicht abbildbar. Die Dokumentation ist an dieser Stelle auch noch nicht vollst\u00e4ndig. Mehr dazu hier</p> </li> </ol>"},{"location":"pydantic/eigene_felder/","title":"Custom Fields &amp; Validators","text":"<p>In pydantic haben wir 2 M\u00f6glichkeiten, um eine eigene Validierung eines Feldes vorzunehmen. Entweder definieren wir ein ganz eigenes Feld oder wir definieren f\u00fcr ein bestehendes Feld einen eigenen Validator.</p>"},{"location":"pydantic/eigene_felder/#eigene-felder","title":"Eigene Felder","text":"<p>Wir k\u00f6nnen in pydantic auch eigene Felder definieren, die spezielle Validierungen oder Konvertierungen durchf\u00fchren. Dies kann beispielsweise sinnvoll sein, wenn wir eine eigene Logik f\u00fcr die Validierung von Daten ben\u00f6tigen, die \u00fcber die Standardfelder von pydantic hinausgeht. </p> <p>Stellen wir uns vor, wir m\u00f6chten eine Klasse Produkt erstellen und haben ein spezielles Feld <code>Price</code>, das den Preis eines Produkts repr\u00e4sentiert. Der Preis soll als Dezimalzahl mit zwei Nachkommastellen gespeichert werden und muss gr\u00f6\u00dfer oder gleich Null sein. Wir k\u00f6nnen ein benutzerdefiniertes Feld <code>PriceField</code> erstellen, das diese Validierung durchf\u00fchrt.</p> <pre><code>from decimal import Decimal\nfrom pydantic import BaseModel, ValidationError, validator\n\nclass PriceField(Decimal):\n    @classmethod\n    def __get_validators__(cls):\n        yield cls.validate\n\n    @classmethod\n    def validate(cls, value, field, **kwargs):\n        if not isinstance(value, Decimal):\n            try:\n                value = Decimal(value)\n            except (ValueError, TypeError):\n                raise ValueError('value is not a valid decimal number')\n        if value &lt; 0:\n            raise ValueError('value must be greater than or equal to 0')\n        if value.as_tuple().exponent != -2:\n            raise ValueError('value must have exactly 2 decimal places')\n        return value\n\nclass Produkt(BaseModel):\n    name: str\n    price: PriceField\n\ntry:\n    produkt = Produkt(name='Laptop', price='999.99')\n    print(produkt)\nexcept ValidationError as e:\n    print(e)\n</code></pre> <p>In diesem Beispiel definieren wir das benutzerdefinierte Feld <code>PriceField</code>, das von der Klasse <code>Decimal</code> erbt und spezielle Validierungen f\u00fcr den Preis eines Produkts durchf\u00fchrt. Die Validierung \u00fcberpr\u00fcft, ob der Preis eine Dezimalzahl ist, gr\u00f6\u00dfer oder gleich Null ist und genau zwei Nachkommastellen hat.</p> <p>Wir verwenden das benutzerdefinierte Feld <code>PriceField</code> in der Klasse <code>Produkt</code>, um den Preis eines Produkts zu validieren. Wenn wir versuchen, ein <code>Produkt</code>-Objekt mit einem ung\u00fcltigen Preis zu erstellen, wird eine <code>ValidationError</code> ausgel\u00f6st.</p> <p>Durch die Definition benutzerdefinierter Felder k\u00f6nnen wir die Validierung und Konvertierung von Daten in pydantic an unsere spezifischen Anforderungen anpassen. Dies erm\u00f6glicht es uns, flexiblere und genauere Datenmodelle zu erstellen, die unseren Anwendungsf\u00e4llen entsprechen. In der Praxis k\u00f6nnen benutzerdefinierte Felder in pydantic verwendet werden, um spezielle Validierungen oder Konvertierungen vorzunehmen, die \u00fcber die Standardfunktionen hinausgehen.</p>"},{"location":"pydantic/eigene_felder/#eigene-validatoren","title":"Eigene Validatoren","text":"<p>Manchmal ben\u00f6tigen wir gar keinen eigenen Datentyp, sondern m\u00f6chten nur eine spezielle Validierung f\u00fcr ein Feld durchf\u00fchren. In solchen F\u00e4llen k\u00f6nnen wir benutzerdefinierte Validatoren verwenden, um die Daten zu \u00fcberpr\u00fcfen und gegebenenfalls Fehler zu melden.</p> <p>Stellen wir uns vor, wir m\u00f6chten ein Feld <code>username</code> erstellen, das nur aus Buchstaben, Zahlen und Unterstrichen bestehen darf. Wir k\u00f6nnen ein benutzerdefiniertes Validierungsmethode <code>validate_username</code> erstellen, das diese \u00dcberpr\u00fcfung durchf\u00fchrt.</p> <pre><code>from pydantic import BaseModel, ValidationError, validator\n\nclass User(BaseModel):\n    username: str\n\n    @validator('username')\n    def validate_username(cls, value):\n        if not value.isalnum():\n            raise ValueError('username must only contain letters and numbers')\n        return value\n\ntry:\n    user = User(username='alice123')\n    print(user)\nexcept ValidationError as e:\n    print(e)\n</code></pre> <p>In diesem Beispiel definieren wir die Klasse <code>User</code> mit einem Feld <code>username</code>, das nur Buchstaben und Zahlen enthalten darf. Wir erstellen ein benutzerdefiniertes Validierungsmethode <code>validate_username</code>, das die \u00dcberpr\u00fcfung durchf\u00fchrt und eine <code>ValueError</code> ausl\u00f6st, wenn das Feld nicht den Anforderungen entspricht.</p> <p>Wir verwenden das benutzerdefinierte Validierungsmethode <code>validate_username</code> mit dem Dekorator <code>@validator</code>, um das Feld <code>username</code> zu validieren. Wenn wir versuchen, ein <code>User</code>-Objekt mit einem ung\u00fcltigen Benutzernamen zu erstellen, wird eine <code>ValidationError</code> ausgel\u00f6st.</p>"},{"location":"pydantic/eigene_felder/#aufgabe-implementierung-eines-eigenen-validators","title":"Aufgabe: Implementierung eines eigenen Validators","text":"<p>Erstelle ein Pydantic-Modell <code>Artikel</code> mit folgenden Anforderungen:</p> <ol> <li> <p>Das Modell soll folgende Felder haben:</p> <ul> <li><code>name</code>: Ein String-Feld f\u00fcr den Namen des Artikels</li> <li><code>artikelnummer</code>: Ein String-Feld f\u00fcr die Artikelnummer</li> <li><code>preis</code>: Ein Float-Feld f\u00fcr den Preis des Artikels</li> <li><code>kategorie</code>: Ein String-Feld f\u00fcr die Kategorie des Artikels</li> </ul> </li> <li> <p>Implementiere einen eigenen Validator f\u00fcr das Feld <code>artikelnummer</code> mit folgenden Regeln:</p> <ul> <li>Die Artikelnummer muss genau 8 Zeichen lang sein</li> <li>Die ersten zwei Zeichen m\u00fcssen Buchstaben sein (Gro\u00dfbuchstaben)</li> <li>Die letzten 6 Zeichen m\u00fcssen Zahlen sein</li> <li>Beispiel f\u00fcr eine g\u00fcltige Artikelnummer: \"AB123456\"</li> </ul> </li> <li> <p>Implementiere einen weiteren Validator f\u00fcr das Feld <code>kategorie</code>, der sicherstellt, dass nur bestimmte Kategorien erlaubt sind. Die erlaubten Kategorien sind:</p> <ul> <li>\"Elektronik\"</li> <li>\"Kleidung\"</li> <li>\"Lebensmittel\"</li> <li>\"Haushalt\"</li> </ul> </li> <li> <p>Teste dein Modell mit verschiedenen Eingaben, sowohl mit g\u00fcltigen als auch mit ung\u00fcltigen Daten.</p> </li> </ol> <p>Hier ist ein Grundger\u00fcst f\u00fcr dein Modell:</p> <pre><code>from pydantic import BaseModel, validator\n\nclass Artikel(BaseModel):\n    name: str\n    artikelnummer: str\n    preis: float\n    kategorie: str\n\n    @validator('artikelnummer')\n    def validate_artikelnummer(cls, v):\n        # Implementiere hier die Validierung f\u00fcr die Artikelnummer\n        pass\n\n    @validator('kategorie')\n    def validate_kategorie(cls, v):\n        # Implementiere hier die Validierung f\u00fcr die Kategorie\n        pass\n\n# Teste dein Modell hier\n</code></pre>"},{"location":"pydantic/fields/","title":"Fields","text":"<p>Die Types in Pydantic sind in der Regel die Python-Standardtypen, aber Pydantic bietet auch spezielle Felder, die zus\u00e4tzliche Validierungen und Konvertierungen erm\u00f6glichen. Einige der verf\u00fcgbaren Felder sind:</p> <ul> <li><code>Field</code>: Ein generisches Feld, das zus\u00e4tzliche Validierungen und Konvertierungen erm\u00f6glicht.</li> <li><code>ConstrainedStr</code>: Ein Feld, das eine Zeichenkette mit zus\u00e4tzlichen Einschr\u00e4nkungen validiert.</li> <li><code>EmailStr</code>: Ein Feld, das eine E-Mail-Adresse validiert.</li> <li><code>SecretStr</code>: Ein Feld, das sensible Daten wie Passw\u00f6rter maskiert.</li> </ul> <p>Mit diesen speziellen Feldern k\u00f6nnen wir die Validierung und Konvertierung von Daten weiter anpassen.</p> <pre><code>from pydantic import EmailStr, Field\n\nclass User(BaseModel):\n    id: int\n    name: str\n    email: EmailStr = Field(..., description='E-Mail-Adresse des Benutzers')\n</code></pre> <p>Wir schauen nachfolgend auf einige der Felder, die Pydantic anbietet und wie sie verwendet werden k\u00f6nnen.</p>"},{"location":"pydantic/fields/#erweiterte-anpassungen-mit-field","title":"Erweiterte Anpassungen mit <code>Field</code>","text":"<p><code>Field</code> erlaubt es uns, zus\u00e4tzliche Metadaten wie <code>title</code>, <code>description</code>, <code>default_factory</code> und <code>alias</code> anzugeben, um sowohl die Validierung als auch die Serialisierung (z. B. bei der JSON-Schema-Generierung) zu beeinflussen.</p> <pre><code>from pydantic import Field, BaseModel\n\nclass Produkt(BaseModel):\n    name: str = Field(..., title=\"Produktname\", description=\"Der Name des Produkts\", min_length=3)\n</code></pre> <p>Hier wird der Name des Produkts mit einer Mindestl\u00e4nge von 3 Zeichen validiert und zus\u00e4tzlich in der JSON-Schema-Darstellung mit einem Titel und einer Beschreibung versehen.</p>"},{"location":"pydantic/fields/#optionale-felder","title":"Optionale Felder","text":"<p>Mit der Verwendung von <code>Optional</code> wird explizit erlaubt, dass ein Feld den Wert <code>None</code> annehmen kann. Au\u00dferdem kannst du festlegen, ob ein Feld weggelassen oder standardm\u00e4\u00dfig mit einem Wert versehen werden soll.</p> <pre><code>from typing import Optional\nfrom pydantic import BaseModel\n\nclass Bestellung(BaseModel):\n    artikel_id: int\n    rabatt_code: Optional[str] = None  # Optionales Feld mit Standardwert\n</code></pre> <p>In diesem Beispiel ist der <code>rabatt_code</code> optional und kann weggelassen oder explizit auf <code>None</code> gesetzt werden.</p>"},{"location":"pydantic/fields/#einschrankende-feldtypen-constrained-types","title":"Einschr\u00e4nkende Feldtypen (<code>Constrained Types</code>)","text":"<p>Pydantic bietet auch spezielle Feldtypen wie <code>ConstrainedInt</code>, <code>ConstrainedStr</code>, <code>PositiveInt</code> und <code>StrictStr</code>, die es erm\u00f6glichen, zus\u00e4tzliche Einschr\u00e4nkungen wie minimale/maximale Werte oder Zeichenl\u00e4ngen zu setzen.</p> <pre><code>from pydantic import conint, constr\n\nclass Kunde(BaseModel):\n    alter: conint(gt=18, lt=65)  # Das Alter muss zwischen 18 und 65 Jahren liegen\n    benutzername: constr(min_length=3, regex=r'^[a-zA-Z0-9_]+$')  # Benutzername mit minimaler L\u00e4nge und Regex-\u00dcberpr\u00fcfung\n</code></pre>"},{"location":"pydantic/fields/#mehrere-typen-fur-ein-feld-mit-union","title":"Mehrere Typen f\u00fcr ein Feld mit <code>Union</code>","text":"<p>Mit <code>Union</code> kannst du festlegen, dass ein Feld mehrere Typen akzeptiert. Pydantic versucht dabei automatisch, den ersten passenden Typ zuzuweisen.</p> <pre><code>from typing import Union\nfrom pydantic import BaseModel, EmailStr\n\nclass Kontakt(BaseModel):\n    kontakt_info: Union[EmailStr, str]  # Akzeptiert entweder eine E-Mail-Adresse oder eine Zeichenkette\n</code></pre> <p>In diesem Fall wird <code>kontakt_info</code> entweder als E-Mail-Adresse oder als einfache Zeichenkette akzeptiert.</p>"},{"location":"pydantic/fields/#aufgaben","title":"Aufgaben","text":"<ol> <li> <p>Produktmodell erstellen:    Erstelle ein Pydantic-Modell <code>Produkt</code> mit folgenden Feldern:</p> <ul> <li><code>name</code>: Ein String-Feld mit einer Mindestl\u00e4nge von 3 Zeichen</li> <li><code>preis</code>: Ein Float-Feld mit einem Mindestwert von 0</li> <li><code>kategorie</code>: Ein String-Feld, das nur bestimmte Werte akzeptiert (z.B. \"Lebensmittel\", \"Elektronik\", \"Kleidung\")</li> <li><code>lagerbestand</code>: Ein optionales Integer-Feld mit einem Standardwert von 0</li> </ul> </li> <li> <p>Benutzermodell mit E-Mail-Validierung:    Erstelle ein Pydantic-Modell <code>Benutzer</code> mit folgenden Feldern:</p> <ul> <li><code>benutzername</code>: Ein String-Feld mit einer Mindestl\u00e4nge von 5 Zeichen</li> <li><code>email</code>: Ein E-Mail-Feld mit Validierung</li> <li><code>alter</code>: Ein Integer-Feld mit einem Mindestwert von 18</li> <li><code>passwort</code>: Ein Feld vom Typ <code>SecretStr</code></li> </ul> </li> <li> <p>Bestellungsmodell mit Validierung:    Erstelle ein Pydantic-Modell <code>Bestellung</code> mit folgenden Feldern:</p> <ul> <li><code>bestellnummer</code>: Ein String-Feld mit einem bestimmten Muster (z.B. \"ORD-\" gefolgt von 6 Ziffern)</li> <li><code>produkte</code>: Eine Liste von <code>Produkt</code>-Objekten (verwende das Modell aus Aufgabe 1)</li> <li><code>gesamtpreis</code>: Ein berechnetes Feld, das die Summe der Produktpreise darstellt</li> <li><code>bestelldatum</code>: Ein Datum-Feld mit dem aktuellen Datum als Standardwert</li> </ul> </li> </ol> <p>Versuche, diese Modelle zu implementieren und teste sie mit verschiedenen Eingaben. Achte besonders darauf, wie Pydantic die Daten validiert und konvertiert.</p>"},{"location":"pydantic/schema/","title":"Schema","text":"<p>\u00c4hnlich wie auch bei <code>@dataclass</code> gibt es in Pydantic die Option, JSON-Schemas aus Objekten zu erstellen. Das Schema-Handling f\u00fcr Modelle und Felder wird automatisch generiert, um JSON-Schemas f\u00fcr die Validierung und Dokumentation bereitzustellen. Dabei k\u00f6nnen zus\u00e4tzliche Metadaten f\u00fcr jedes Feld angegeben werden, wie z.B. Beschreibungen, Titel oder Beispiele, die im generierten Schema verwendet werden.</p>"},{"location":"pydantic/schema/#schema-fur-modelle-und-felder","title":"Schema f\u00fcr Modelle und Felder","text":"<p>Mit der Funktion <code>Field</code> k\u00f6nnen wir zus\u00e4tzliche Informationen wie <code>title</code>, <code>description</code> und <code>examples</code> festlegen, die im generierten JSON-Schema verwendet werden. Dies ist besonders n\u00fctzlich f\u00fcr die API-Dokumentation.</p> <p>Beispiel: <pre><code>from pydantic import BaseModel, Field\n\nclass Produkt(BaseModel):\n    id: int = Field(..., title=\"Produkt-ID\", description=\"Die eindeutige Kennung des Produkts\", example=123)\n    name: str = Field(..., title=\"Produktname\", description=\"Der Name des Produkts\", example=\"Laptop\")\n    preis: float = Field(..., title=\"Preis\", description=\"Der Preis des Produkts in EUR\", example=999.99)\n</code></pre></p>"},{"location":"pydantic/schema/#json-schema-generierung","title":"JSON-Schema-Generierung","text":"<p>Pydantic bietet die M\u00f6glichkeit, ein Modell als JSON-Schema zu exportieren. Das ist hilfreich f\u00fcr die Integration in API-Dokumentationen wie OpenAPI.</p> <pre><code>produkt_schema = Produkt.model_json_schema()\nprint(produkt_schema)\n</code></pre> <p>Das resultierende Schema sieht dann in etwa so aus: <pre><code>{\n  \"title\": \"Produkt\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"id\": {\n      \"title\": \"Produkt-ID\",\n      \"type\": \"integer\",\n      \"description\": \"Die eindeutige Kennung des Produkts\",\n      \"example\": 123\n    },\n    \"name\": {\n      \"title\": \"Produktname\",\n      \"type\": \"string\",\n      \"description\": \"Der Name des Produkts\",\n      \"example\": \"Laptop\"\n    },\n    \"preis\": {\n      \"title\": \"Preis\",\n      \"type\": \"number\",\n      \"description\": \"Der Preis des Produkts in EUR\",\n      \"example\": 999.99\n    }\n  },\n  \"required\": [\"id\", \"name\", \"preis\"]\n}\n</code></pre></p>"},{"location":"pydantic/schema/#anpassung-des-schemas","title":"Anpassung des Schemas","text":"<p>Durch die Verwendung von <code>Field</code>-Parametern k\u00f6nnen wir detaillierte Metadaten f\u00fcr jedes Feld hinzuf\u00fcgen: - <code>title</code>: Gibt dem Feld einen Titel im Schema. - <code>description</code>: Beschreibt das Feld detailliert. - <code>example</code>: Definiert ein Beispiel, das im Schema angezeigt wird.</p> <p>Mit diesen Informationen k\u00f6nnen wir sicherstellen, dass das Schema sowohl f\u00fcr die Validierung als auch f\u00fcr die API-Dokumentation aussagekr\u00e4ftig ist.</p>"},{"location":"pytest/","title":"Pytest: Einf\u00fchrung und Aufbau von Tests","text":"<p>Tests sind ein integraler Bestandteil der Softwareentwicklung, da sie sicherstellen, dass unser Code wie erwartet funktioniert und korrektes Verhalten in verschiedenen Szenarien zeigt. In PyTest, einem der beliebtesten Test-Frameworks f\u00fcr Python, haben wir ein m\u00e4chtiges Werkzeug, um einfache Unit-Tests sowie komplexere Testszenarien effizient umzusetzen.</p> <p>Ein guter Test stellt sicher, dass das Verhalten eines Systems oder einer Funktion, auf die wir uns verlassen, stabil und vorhersehbar bleibt. Dies ist besonders wichtig in gro\u00dfen Projekten, in denen kleine \u00c4nderungen an einem Teil des Codes unvorhergesehene Auswirkungen auf andere Bereiche haben k\u00f6nnten.</p>"},{"location":"pytest/#aufbau-von-tests","title":"Aufbau von Tests","text":"<p>Ein Test soll das Ergebnis eines bestimmten Verhaltens \u00fcberpr\u00fcfen und sicherstellen, dass dieses Ergebnis den Erwartungen entspricht. \u201eVerhalten\u201c beschreibt, wie ein System auf eine bestimmte Situation oder Reize reagiert. Dabei ist weniger wichtig, wie oder warum etwas geschieht, sondern was genau passiert. Das Ziel eines Tests ist es, das System unter verschiedenen Bedingungen zu beobachten und zu \u00fcberpr\u00fcfen, ob es korrekt reagiert.</p> <p>Ein Test l\u00e4sst sich typischerweise in vier Schritte unterteilen:</p> <ul> <li>Vorbereitung (Arrange)</li> <li>Aktion (Act)</li> <li>\u00dcberpr\u00fcfung (Assert)</li> <li>Aufr\u00e4umen (Cleanup)</li> </ul>"},{"location":"pytest/#1-vorbereitung-arrange","title":"1. Vorbereitung (Arrange)","text":"<p>In der Vorbereitungsphase schaffen wir die Voraussetzungen, damit der eigentliche Test durchgef\u00fchrt werden kann. Dies umfasst das Einrichten von Objekten, das Laden von Testdaten, das Starten von Diensten oder das Initialisieren von Variablen. In vielen F\u00e4llen kann dies auch das Einf\u00fcgen von Testdatens\u00e4tzen in eine Datenbank oder das Setzen eines erwarteten Zustands in einer API-Anfrage sein. Die Vorbereitung stellt sicher, dass der Kontext des Tests vollst\u00e4ndig ist, bevor die eigentliche Aktion ausgel\u00f6st wird.</p> <p>Beispiele f\u00fcr Vorbereitung: - Das Erstellen eines neuen Benutzers f\u00fcr einen Login-Test. - Das Einrichten einer Netzwerkverbindung f\u00fcr eine API-Abfrage. - Das Initialisieren einer Klasse mit bestimmten Startwerten.</p>"},{"location":"pytest/#2-aktion-act","title":"2. Aktion (Act)","text":"<p>Dies ist der zentrale Teil des Tests, in dem eine Aktion ausgef\u00fchrt wird, die das zu testende Verhalten des Systems (SUT \u2013 System under Test) ausl\u00f6st. Typischerweise handelt es sich dabei um einen Methoden- oder Funktionsaufruf. Die Aktion sollte genau eine \u00c4nderung am Zustand des Systems hervorrufen. Diese Zustands\u00e4nderung k\u00f6nnte z. B. eine Berechnung, eine API-Anfrage oder das Speichern eines Datensatzes sein.</p> <p>Beispiele f\u00fcr Aktionen: - Ein Funktionsaufruf, der den aktuellen Bestand in einem Lager zur\u00fcckgibt. - Das Absenden eines Formulars \u00fcber eine API. - Das Hinzuf\u00fcgen eines neuen Artikels zu einem Warenkorb.</p>"},{"location":"pytest/#3-uberprufung-assert","title":"3. \u00dcberpr\u00fcfung (Assert)","text":"<p>Nach der Aktion wird das Verhalten \u00fcberpr\u00fcft, um festzustellen, ob das Ergebnis den Erwartungen entspricht. Hier wird gepr\u00fcft, ob der resultierende Zustand korrekt ist. Dies geschieht durch Asserts. Ein Assert vergleicht das tats\u00e4chliche Ergebnis mit dem erwarteten Ergebnis und sorgt daf\u00fcr, dass der Test nur dann erfolgreich ist, wenn beide \u00fcbereinstimmen.</p> <p>Beispiele f\u00fcr Asserts: - \u00dcberpr\u00fcfung, ob ein Artikel erfolgreich in den Warenkorb hinzugef\u00fcgt wurde. - Sicherstellen, dass die API eine korrekte Erfolgsmeldung zur\u00fcckgibt. - \u00dcberpr\u00fcfen, dass ein Rabatt korrekt auf einen Produktpreis angewendet wurde.</p> <pre><code>assert actual_value == expected_value\n</code></pre> <p>Wenn diese \u00dcberpr\u00fcfung fehlschl\u00e4gt, zeigt PyTest den Test als fehlgeschlagen an und gibt das erwartete und tats\u00e4chliche Ergebnis aus, was das Debugging erleichtert.</p>"},{"location":"pytest/#4-aufraumen-cleanup","title":"4. Aufr\u00e4umen (Cleanup)","text":"<p>Nicht jeder Test ben\u00f6tigt explizite Aufr\u00e4umarbeiten, aber in vielen F\u00e4llen ist es sinnvoll, Ressourcen wie Datenbanken, Dateien oder Netzwerkverbindungen nach einem Test zu schlie\u00dfen. PyTest bietet verschiedene Mechanismen wie Fixtures, um dies automatisch zu handhaben, insbesondere wenn Aufr\u00e4umarbeiten immer nach einem Test durchgef\u00fchrt werden sollen.</p> <p>Beispiele f\u00fcr Cleanup: - Schlie\u00dfen einer Datenbankverbindung nach dem Test. - L\u00f6schen tempor\u00e4rer Dateien oder Verzeichnisse. - Zur\u00fccksetzen von Testdaten oder Entfernen von Testbenutzern.</p>"},{"location":"pytest/#der-arrange-act-assert-cycle","title":"Der ARRANGE-ACT-ASSERT-CYCLE","text":"<p>Im Wesentlichen besteht jeder Test aus den Schritten Aktion und \u00dcberpr\u00fcfung, wobei die Vorbereitung den Kontext f\u00fcr die Aktion liefert. Die Aktion ver\u00e4ndert den Zustand des Systems, und die \u00dcberpr\u00fcfung stellt sicher, dass das Verhalten den Erwartungen entspricht. </p> <p>Das folgende Beispiel zeigt, wie diese Schritte in einem simplen Unit-Test umgesetzt werden:</p> <p>Beispiel:</p> <pre><code>import pytest\n\ndef my_function(x):\n    return x + 1\n\ndef test_my_function():\n    x = 3  # Arrange: Vorbereitung des Testfalls\n    result = my_function(x)  # Act: Ausf\u00fchrung der zu testenden Aktion\n    assert result == 4  # Assert: \u00dcberpr\u00fcfung, ob das Ergebnis korrekt ist\n</code></pre> <p>In diesem einfachen Beispiel testen wir eine Funktion <code>my_function</code>, die eine Zahl um 1 erh\u00f6ht. Zuerst bereiten wir den Test vor, indem wir den Wert <code>x</code> auf 3 setzen. Dann rufen wir die Funktion auf (Aktion) und \u00fcberpr\u00fcfen schlie\u00dflich, ob das Ergebnis korrekt ist (\u00dcberpr\u00fcfung).</p>"},{"location":"pytest/#strukturierter-aufbau-von-testfallen","title":"Strukturierter Aufbau von Testf\u00e4llen","text":"<p>Gute Tests folgen einem konsistenten Muster, das f\u00fcr alle Tests gleich bleibt. Dies erleichtert das Schreiben, Warten und Lesen von Tests, insbesondere wenn diese zahlreicher und komplexer werden. In diesem Beispiel haben wir gesehen, wie die Schritte Arrange-Act-Assert auf einfache Weise implementiert werden k\u00f6nnen.</p>"},{"location":"pytest/#beispiel-fur-einen-vollstandigen-test","title":"Beispiel f\u00fcr einen vollst\u00e4ndigen Test:","text":"<p>Nehmen wir ein komplexeres Szenario aus dem Einzelhandel. Wir haben eine Funktion, die basierend auf einem gegebenen Artikelpreis und einem Rabatt den endg\u00fcltigen Preis berechnet. Wir m\u00f6chten sicherstellen, dass unsere Rabattberechnungen korrekt funktionieren:</p> <pre><code>import pytest\n\ndef calculate_discounted_price(price, discount):\n    return price * (1 - discount)\n\ndef test_calculate_discounted_price():\n    # Arrange\n    price = 100.0\n    discount = 0.2  # 20% Rabatt\n    expected_price = 80.0\n\n    # Act\n    final_price = calculate_discounted_price(price, discount)\n\n    # Assert\n    assert final_price == expected_price\n</code></pre> <p>In diesem Beispiel verwenden wir den Arrange-Act-Assert-Zyklus, um die Preisberechnung zu testen. Wir bereiten den Artikelpreis und den Rabatt vor, f\u00fchren die Preisberechnung durch und \u00fcberpr\u00fcfen, ob das Endergebnis korrekt ist.</p>"},{"location":"pytest/#aufgaben","title":"Aufgaben:","text":"<ol> <li>Erstelle einen Test f\u00fcr eine Funktion, die den Lagerbestand eines Artikels in einem Discounter aktualisiert.</li> <li> <p>Verwende den Arrange-Act-Assert-Zyklus, um sicherzustellen, dass der Lagerbestand korrekt erh\u00f6ht wird, wenn eine Lieferung eintrifft.</p> </li> <li> <p>Schreibe einen Test f\u00fcr eine Funktion, die basierend auf dem Artikelpreis und der Menge den Gesamtpreis berechnet.</p> </li> <li> <p>Implementiere eine Aktion, die eine Menge von Artikeln an einen Warenkorb hinzuf\u00fcgt, und \u00fcberpr\u00fcfe, ob der Gesamtpreis korrekt berechnet wird.</p> </li> <li> <p>Implementiere einen Test f\u00fcr eine Funktion, die pr\u00fcft, ob ein Benutzer erfolgreich eingeloggt werden kann.</p> </li> <li>Parametrisiere den Test, um verschiedene Benutzeranmeldeinformationen zu testen.</li> </ol>"},{"location":"pytest/best_practices/","title":"Best Practices","text":""},{"location":"pytest/best_practices/#test-organization","title":"Test Organization","text":"<p>F\u00fcr pytest gibt es 2 allgemeine Methoden, um Tests zu organisieren:</p> <ol> <li>Im Anwendungscode integrierte Tests: Tests werden in den gleichen Ordner wie der Anwendungscode geschrieben. Dies kann beispielsweise in einem <code>tests/</code>-Ordner innerhalb des Projekts erfolgen.</li> </ol> <pre><code>[src/]my_package/\n    __init__.py\n    app.py\n    view.py\n    tests/\n        __init__.py\n        test_app.py\n        test_view.py\n        ...\n</code></pre> <p>Wollen wir die Tests ausf\u00fchren, k\u00f6nnen wir folgenden Befehl verwenden:</p> <pre><code>pytest --pyargs tests/\n</code></pre> <ol> <li>Separater Testordner: Tests werden in einem separaten Ordner geschrieben, z.B. <code>tests/</code>. Dies ist n\u00fctzlich, wenn die Tests unabh\u00e4ngig von der Anwendungsstruktur sein sollen.</li> </ol> <pre><code>src/\n    my_package/\n        __init__.py\n        app.py\n        view.py\ntests/\n    test_app.py\n    test_view.py\n    ...\n</code></pre> <p>Wollen wir die Tests ausf\u00fchren, k\u00f6nnen wir folgenden Befehl verwenden:</p> <pre><code>python -m pytest\n</code></pre> <p>Falls wir mehrere Tests mit dem gleichen Namen haben, k\u00f6nnen wir uns \u00fcber weitere Subfolder behelfen:</p> <pre><code>tests/\n    __init__.py\n    test_app/\n        test_app.py\n    test_view/\n        test_view.py\n    ...\n</code></pre>"},{"location":"pytest/fixtures/","title":"Fixtures","text":"<p>In diesem Abschnitt besch\u00e4ftigen wir uns mit einem der wichtigsten Konzepte in PyTest: den Fixtures. Fixtures sind eine M\u00f6glichkeit, Testdaten oder Testumgebungen bereitzustellen, die wir in unseren Tests wiederverwenden k\u00f6nnen. Dadurch wird nicht nur der Code aufger\u00e4umter, sondern wir vermeiden auch unn\u00f6tige Wiederholungen. </p>"},{"location":"pytest/fixtures/#was-sind-fixtures","title":"Was sind Fixtures?","text":"<p>Fixtures sind Funktionen, die vor unseren Tests aufgerufen werden, um bestimmte Vorbedingungen oder Ressourcen bereitzustellen. Das k\u00f6nnen Datenbankverbindungen, Dateien, Netzwerkressourcen oder einfach nur Daten sein, die in mehreren Tests ben\u00f6tigt werden. Eine der gr\u00f6\u00dften St\u00e4rken von Fixtures liegt darin, dass sie sich nicht nur um die Vorbereitung, sondern auch um die Aufr\u00e4umarbeiten k\u00fcmmern k\u00f6nnen, falls n\u00f6tig.</p> <p>Stellen wir uns vor, wir testen eine Anwendung, die auf eine Datenbank zugreift. In jedem Test ben\u00f6tigen wir eine frische, vorbereitete Datenbank. Mit Fixtures k\u00f6nnen wir das Setup und das Teardown dieser Datenbank in einer zentralen Funktion unterbringen und diese dann in unseren Tests nutzen. Das bedeutet: Wir m\u00fcssen die Initialisierung nicht in jedem Test wiederholen.</p>"},{"location":"pytest/fixtures/#wie-definieren-wir-eine-fixture","title":"Wie definieren wir eine Fixture?","text":"<p>Fixtures werden in PyTest mithilfe des <code>@pytest.fixture</code>-Dekorators definiert. Lassen Sie uns gemeinsam ein einfaches Beispiel durchgehen. Angenommen, wir haben eine Funktion, die eine Berechnung auf einer Liste von Zahlen durchf\u00fchrt. Wir m\u00f6chten sicherstellen, dass in unseren Tests immer eine bestimmte Liste von Zahlen verwendet wird.</p> <pre><code>import pytest\n\n@pytest.fixture\ndef sample_list():\n    return [1, 2, 3, 4, 5]\n</code></pre> <p>In diesem Fall ist <code>sample_list</code> unsere Fixture. Sie liefert eine Liste von Zahlen, die wir in mehreren Tests wiederverwenden k\u00f6nnen.</p>"},{"location":"pytest/fixtures/#verwendung-einer-fixture-in-tests","title":"Verwendung einer Fixture in Tests","text":"<p>Um diese Fixture in einem Test zu verwenden, \u00fcbergeben wir einfach den Namen der Fixture als Parameter an die Testfunktion:</p> <pre><code>def test_sum(sample_list):\n    assert sum(sample_list) == 15\n</code></pre> <p>Hier ruft PyTest die Fixture <code>sample_list</code> auf und injiziert deren R\u00fcckgabewert in den Test. Der Test selbst bleibt \u00fcbersichtlich und fokussiert, da wir uns nicht um die Erstellung der Liste k\u00fcmmern m\u00fcssen.</p>"},{"location":"pytest/fixtures/#fixture-scopes","title":"Fixture-Scopes","text":"<p>Oft ben\u00f6tigen wir mehr Kontrolle dar\u00fcber, wie oft eine Fixture erstellt wird. Standardm\u00e4\u00dfig wird eine Fixture f\u00fcr jeden Test neu ausgef\u00fchrt, aber manchmal m\u00f6chten wir, dass eine Fixture \u00fcber mehrere Tests hinweg besteht. PyTest bietet daf\u00fcr verschiedene Scopes, wie:</p> <ul> <li><code>function</code>: Die Fixture wird vor jedem Test aufgerufen (Standard).</li> <li><code>module</code>: Die Fixture wird einmal pro Modul aufgerufen.</li> <li><code>class</code>: Die Fixture wird einmal pro Klasse aufgerufen.</li> <li><code>session</code>: Die Fixture wird einmal pro Test-Session aufgerufen.</li> </ul> <p>Schauen wir uns ein Beispiel an, in dem wir eine Datenbankverbindung nur einmal pro Modul erstellen wollen:</p> <pre><code>@pytest.fixture(scope=\"module\")\ndef db_connection():\n    conn = setup_database()\n    yield conn\n    conn.close()\n</code></pre> <p>Hier verwenden wir den <code>yield</code>-Befehl, um die Verbindung nach dem Testen zu schlie\u00dfen. Mit <code>yield</code> geben wir die Ressource zur\u00fcck, aber die Funktion kann auch nach dem Test weiterlaufen, um Aufr\u00e4umarbeiten durchzuf\u00fchren.</p>"},{"location":"pytest/fixtures/#aufgaben","title":"Aufgaben","text":"<p>Aufgabe 1: Definiere eine Fixture, die eine Datei \u00f6ffnet, diese nach dem Testen aber automatisch schlie\u00dft. Nutze daf\u00fcr <code>yield</code> und \u00fcberlege, welche Aufr\u00e4umarbeiten notwendig sind.</p> <p>Aufgabe 2: Erstelle eine Fixture mit einem <code>class</code>-Scope, die eine komplexe Datenstruktur (z.B. einen gro\u00dfen JSON-Datensatz) erstellt und in mehreren Tests einer Klasse verwendet wird.</p>"},{"location":"pytest/fixtures/#parametrisierte-fixtures","title":"Parametrisierte Fixtures","text":"<p>Manchmal wollen wir unsere Tests mit unterschiedlichen Daten ausf\u00fchren. Hier kommen parametrisierte Fixtures ins Spiel. Damit k\u00f6nnen wir eine Fixture mit verschiedenen Werten bereitstellen, ohne den Code zu duplizieren.</p> <p>Ein Beispiel:</p> <pre><code>@pytest.fixture(params=[(1, 2, 3), (4, 5, 9), (10, 20, 30)])\ndef numbers(request):\n    return request.param\n</code></pre> <p>Die Fixture <code>numbers</code> liefert in jedem Testlauf ein anderes Zahlenpaar. In unseren Tests sieht das so aus:</p> <pre><code>def test_addition(numbers):\n    a, b, result = numbers\n    assert a + b == result\n</code></pre> <p>PyTest f\u00fchrt diesen Test dreimal aus, jedes Mal mit einem anderen Tupel von Werten. Parametrisierte Fixtures helfen uns dabei, umfangreiche Tests mit unterschiedlichen Eingabedaten zu schreiben, ohne den Code zu vervielfachen.</p>"},{"location":"pytest/fixtures/#fixture-komposition","title":"Fixture-Komposition","text":"<p>In realen Projekten kommt es h\u00e4ufig vor, dass wir mehrere Fixtures kombinieren m\u00fcssen. Gl\u00fccklicherweise unterst\u00fctzt PyTest die Abh\u00e4ngigkeit von Fixtures, das hei\u00dft, eine Fixture kann eine andere Fixture verwenden. Dies erm\u00f6glicht uns eine elegante Komposition von Funktionen.</p> <p>Schauen wir uns folgendes Beispiel an:</p> <pre><code>@pytest.fixture\ndef user_data():\n    return {\"name\": \"Max\", \"age\": 28}\n\n@pytest.fixture\ndef user_profile(user_data):\n    return {\"profile\": f\"{user_data['name']} is {user_data['age']} years old.\"}\n\ndef test_profile(user_profile):\n    assert user_profile == \"Max is 28 years old.\"\n</code></pre> <p>Hier verwendet die <code>user_profile</code>-Fixture die <code>user_data</code>-Fixture, um ein zusammengesetztes Ergebnis zu erzeugen. Dies ist eine sehr n\u00fctzliche Technik, wenn unsere Testkonfigurationen komplexer werden und wir bestimmte Teile in separaten Fixtures kapseln wollen.</p>"},{"location":"pytest/fixtures/#aufgaben_1","title":"Aufgaben","text":"<p>Aufgabe 3: Erstelle zwei Fixtures, bei denen die eine auf der anderen basiert. Die erste Fixture sollte eine Liste mit Zahlen liefern, die zweite Fixture soll den Durchschnitt dieser Liste berechnen.</p> <p>Aufgabe 4: Verwende parametrisierte Fixtures, um einen Test zu erstellen, der verschiedene Benutzereingaben testet (z.B. eine Liste von Benutzernamen und Passw\u00f6rtern) und pr\u00fcft, ob die Anmeldung erfolgreich ist.</p>"},{"location":"pytest/parametrisierte_tests/","title":"Parametrisierung von Tests","text":"<p>In diesem Abschnitt widmen wir uns der Parametrisierung von Tests. Dies ist besonders n\u00fctzlich, wenn wir unsere Tests mit verschiedenen Eingabewerten wiederholt ausf\u00fchren m\u00f6chten, ohne daf\u00fcr mehrfach den gleichen Code schreiben zu m\u00fcssen. Insbesondere in Projekten, die umfangreiche Datenverarbeitung beinhalten, wie es im Einzelhandel oft der Fall ist, erm\u00f6glicht uns die Parametrisierung, effizient und flexibel zu testen.</p>"},{"location":"pytest/parametrisierte_tests/#was-ist-parametrisierung","title":"Was ist Parametrisierung?","text":"<p>Mit der Parametrisierung k\u00f6nnen wir eine Testfunktion mit verschiedenen Eingabewerten mehrfach ausf\u00fchren. Stellen wir uns vor, wir entwickeln ein Kassensystem f\u00fcr einen Discounter und m\u00f6chten die Berechnung von Rabatten f\u00fcr verschiedene Produkttypen testen. Anstatt f\u00fcr jeden Produkttyp eine eigene Testfunktion zu schreiben, k\u00f6nnen wir dieselbe Testfunktion mit verschiedenen Rabatts\u00e4tzen und Preisen aufrufen.</p> <p>Dies erm\u00f6glicht es uns, die Testf\u00e4lle sauber und wiederverwendbar zu halten, ohne unn\u00f6tigen doppelten Code.</p>"},{"location":"pytest/parametrisierte_tests/#parametrisierung-mit-pytestmarkparametrize","title":"Parametrisierung mit <code>@pytest.mark.parametrize</code>","text":"<p>In PyTest verwenden wir den Dekorator <code>@pytest.mark.parametrize</code>, um eine Funktion zu parametrisieren. Nehmen wir an, wir haben eine Funktion, die f\u00fcr ein Kassensystem den Endpreis eines Produkts berechnet, nachdem ein Rabatt abgezogen wurde. Wir m\u00f6chten diese Funktion mit verschiedenen Rabatten testen.</p> <p>Zun\u00e4chst ein einfaches Beispiel:</p> <pre><code>import pytest\n\n@pytest.mark.parametrize(\"price, discount, expected\", [\n    (100, 0.10, 90),\n    (200, 0.15, 170),\n    (50, 0.20, 40)\n])\ndef test_discount(price, discount, expected):\n    assert price * (1 - discount) == expected\n</code></pre> <p>Hier haben wir die Funktion <code>test_discount</code> mit drei verschiedenen Satzpaaren von Preis und Rabattwerten parametrisiert. PyTest wird diesen Test dreimal ausf\u00fchren \u2013 einmal f\u00fcr jedes Tupel von Werten (Preis, Rabatt, erwarteter Endpreis).</p>"},{"location":"pytest/parametrisierte_tests/#mehrere-parameter","title":"Mehrere Parameter","text":"<p>Manchmal m\u00fcssen wir mehr als nur einen Parameter kombinieren. Nehmen wir an, wir testen in einem Discounter-Szenario nicht nur den Rabatt, sondern auch, ob der Preis brutto oder netto vorliegt. Dazu k\u00f6nnen wir mehrere Parameter in einer Parametrisierung kombinieren:</p> <pre><code>@pytest.mark.parametrize(\"price, discount, is_gross, expected\", [\n    (100, 0.10, True, 90), \n    (200, 0.15, False, 170),\n    (50, 0.20, True, 40)\n])\ndef test_discount(price, discount, is_gross, expected):\n    if is_gross:\n        net_price = price * 0.9  # Vereinfachte Beispielsteuer\n    else:\n        net_price = price\n    assert net_price * (1 - discount) == expected\n</code></pre> <p>In diesem Beispiel haben wir den zus\u00e4tzlichen Parameter <code>is_gross</code> eingef\u00fchrt, der anzeigt, ob der angegebene Preis bereits die Mehrwertsteuer enth\u00e4lt oder nicht. Je nach Eingabeparameter wird der Preis unterschiedlich berechnet.</p>"},{"location":"pytest/parametrisierte_tests/#aufgaben","title":"Aufgaben","text":"<p>Aufgabe 1: Parametrisiere einen Test, der verschiedene Rabatte und Preise f\u00fcr Lebensmittelprodukte testet. Denke dabei daran, dass Lebensmittel in Deutschland eine andere Mehrwertsteuer (7 %) haben als andere Produkte (19 %).</p> <p>Aufgabe 2: Schreibe eine Testfunktion, die die korrekte Berechnung von Mengenrabatten f\u00fcr verschiedene Produktmengen und Rabattstaffeln testet. Verwende die Parametrisierung, um unterschiedliche Rabattstufen f\u00fcr unterschiedliche Mengen zu testen.</p>"},{"location":"pytest/parametrisierte_tests/#verwendung-von-fixtures-mit-parametrisierung","title":"Verwendung von Fixtures mit Parametrisierung","text":"<p>Wie bereits im vorherigen Abschnitt erl\u00e4utert, sind Fixtures in PyTest extrem n\u00fctzlich. Wir k\u00f6nnen sie auch zusammen mit der Parametrisierung verwenden, um komplexere Szenarien abzubilden. Nehmen wir an, wir haben eine Fixture, die eine Liste von Artikeln in einem Warenkorb zur\u00fcckgibt. Diese Liste k\u00f6nnte f\u00fcr verschiedene Kundengruppen parametrisiert werden, z.B. f\u00fcr Privatkunden und Gro\u00dfkunden.</p> <pre><code>@pytest.fixture\ndef customer_type():\n    return {\"type\": \"retail\", \"discount\": 0.10}\n\n@pytest.mark.parametrize(\"price, expected\", [\n    (100, 90),\n    (200, 180),\n])\ndef test_customer_discount(price, expected, customer_type):\n    discount = customer_type['discount']\n    assert price * (1 - discount) == expected\n</code></pre> <p>Hier verwenden wir eine Fixture, um den Kundentyp zu simulieren. In diesem Fall gibt die Fixture an, dass es sich um einen Einzelkunden handelt, der einen festen Rabatt erh\u00e4lt. Die Parametrisierung sorgt daf\u00fcr, dass wir die Testlogik mit verschiedenen Preisen durchlaufen k\u00f6nnen.</p>"},{"location":"pytest/parametrisierte_tests/#parametrisierung-komplexer-objekte","title":"Parametrisierung komplexer Objekte","text":"<p>In manchen F\u00e4llen m\u00f6chten wir komplexe Datenstrukturen an unsere Tests \u00fcbergeben, wie zum Beispiel Objekte oder W\u00f6rterb\u00fccher. Dies ist besonders im Einzelhandel relevant, wenn wir z.B. mit Produktinformationen arbeiten.</p> <p>Stellen wir uns vor, wir haben ein W\u00f6rterbuch, das verschiedene Eigenschaften eines Produkts speichert, und wir m\u00f6chten die Preiskalkulation auf Basis dieser Daten testen:</p> <pre><code>@pytest.mark.parametrize(\"product, expected_price\", [\n    ({\"name\": \"Apple\", \"price\": 1.00, \"discount\": 0.05}, 0.95),\n    ({\"name\": \"Banana\", \"price\": 0.50, \"discount\": 0.10}, 0.45),\n    ({\"name\": \"Laptop\", \"price\": 1000, \"discount\": 0.20}, 800)\n])\ndef test_product_discount(product, expected_price):\n    final_price = product[\"price\"] * (1 - product[\"discount\"])\n    assert final_price == expected_price\n</code></pre> <p>In diesem Beispiel verwenden wir W\u00f6rterb\u00fccher, die die Eigenschaften der Produkte enthalten, und parametrisieren den Test, um verschiedene Produkte und ihre Rabatte zu \u00fcberpr\u00fcfen. Dies ist besonders n\u00fctzlich, wenn wir Tests schreiben, die mit realistischen Daten arbeiten sollen.</p>"},{"location":"pytest/parametrisierte_tests/#aufgaben_1","title":"Aufgaben","text":"<p>Aufgabe 3: Erstelle eine Parametrisierung, bei der du verschiedene Kundentypen (z.B. Privatkunde, Gro\u00dfkunde, Mitarbeiter) testest und sicherstellst, dass jeweils der richtige Rabatt angewendet wird.</p> <p>Aufgabe 4: Schreibe einen Test, der unterschiedliche Produkte testet, bei denen neben dem Preis auch noch andere Eigenschaften wie Mindesthaltbarkeitsdatum oder St\u00fcckzahl ber\u00fccksichtigt werden. Parametrisiere die Tests, um sicherzustellen, dass f\u00fcr verderbliche Waren spezielle Regeln gelten (z.B. zus\u00e4tzliche Rabatte kurz vor Ablaufdatum).</p>"},{"location":"pytest/parametrisierte_tests/#parametrisierung-und-fehlererwartungen","title":"Parametrisierung und Fehlererwartungen","text":"<p>In manchen F\u00e4llen m\u00f6chten wir nicht nur testen, ob eine Funktion korrekt arbeitet, sondern auch, ob sie bei falschen Eingabewerten erwartungsgem\u00e4\u00df Fehler ausl\u00f6st. Dies l\u00e4sst sich ebenfalls mit der Parametrisierung kombinieren. Nehmen wir an, wir m\u00f6chten sicherstellen, dass unser Kassensystem bei einem negativen Preis eine Ausnahme wirft:</p> <pre><code>@pytest.mark.parametrize(\"price, discount\", [\n    (-10, 0.10),\n    (100, -0.15),\n    (-50, -0.20)\n])\ndef test_invalid_discount(price, discount):\n    with pytest.raises(ValueError):\n        if price &lt; 0 or discount &lt; 0:\n            raise ValueError(\"Preis oder Rabatt d\u00fcrfen nicht negativ sein\")\n</code></pre> <p>In diesem Fall parametrisieren wir den Test mit fehlerhaften Eingabewerten und erwarten, dass eine <code>ValueError</code>-Exception geworfen wird, wenn der Preis oder der Rabatt negativ ist. Dies ist n\u00fctzlich, um sicherzustellen, dass unser System robust gegen\u00fcber falschen Eingaben ist.</p>"},{"location":"pytest/parametrisierte_tests/#aufgaben_2","title":"Aufgaben","text":"<p>Aufgabe 5: Parametrisiere einen Test, der sicherstellt, dass das Kassensystem bei ung\u00fcltigen Eingaben (z.B. negativen Preisen oder ung\u00fcltigen Rabattwerten) korrekt Fehler ausl\u00f6st.</p>"},{"location":"python_dash/","title":"Python Dash","text":"<p>Python Dash ist eine Open-Source-Bibliothek, die es erm\u00f6glicht, interaktive Webanwendungen mit Python zu erstellen. Es basiert auf Flask, Plotly.js und React.js und eignet sich besonders gut f\u00fcr Data-Science-Projekte.</p> <p>Zu unterschieden ist zwischen der Dash-Bibliothek und der Dash Enterprise-Plattform. Die Dash-Bibliothek ist kostenlos und Open-Source, w\u00e4hrend die Dash Enterprise-Plattform kostenpflichtig ist und zus\u00e4tzliche Funktionen, wie beispielsweise eine erweiterte Authentication bietet.</p> <p>Streamlit</p> <p>Eine Alternative zu Dash ist Streamlit. Streamlit ist ebenfalls eine Open-Source-Bibliothek, die es erm\u00f6glicht, interaktive Webanwendungen mit Python zu erstellen. </p> <p>Ein Vorteil von Streamlit ist, dass die Erstellung von kleinen Dashboards sehr einfach ist.</p> <p>Streamlit ist jedoch weniger flexibel als Dash, da es weniger Anpassungsm\u00f6glichkeiten bietet.</p>"},{"location":"python_dash/callbacks/","title":"Callbacks","text":"<p>Bisher haben unsere Dashboards nur statische Inhalte angezeigt. Um die Interaktivit\u00e4t zu erzeugen, k\u00f6nnen wir Callbacks verwenden. Callbacks sind Funktionen, die aufgerufen werden, wenn ein bestimmtes Ereignis eintritt. Beispielsweise kann eine Callback-Funktion aufgerufen werden, wenn ein Button gedr\u00fcckt wird.</p> <p>In Dash erm\u00f6glichen Callbacks, die Anwendung dynamisch zu aktualisieren, basierend auf Benutzereingaben oder anderen Ereignissen.</p> <p>Ein Callback in Dash besteht aus drei Teilen:</p> <ul> <li>Input: Das Ereignis, auf das reagiert werden soll. Dies kann beispielsweise ein Klick auf einen Button oder eine \u00c4nderung in einem Eingabefeld sein.</li> <li>Output: Die Komponente, die aktualisiert werden soll. Dies kann beispielsweise ein Textfeld oder ein Diagramm sein.</li> <li>Callback-Funktion: Die Funktion, die aufgerufen wird, wenn das Ereignis eintritt. Diese Funktion nimmt die Eingabewerte entgegen, verarbeitet sie und gibt die aktualisierten Werte zur\u00fcck.</li> </ul> <p>Um Callbacks in Dash zu definieren, verwenden wir das <code>@app.callback</code>-Dekorator. Das Dekorator wird \u00fcber der Callback-Funktion platziert und nimmt die Input- und Output-Komponenten als Argumente. Hier ist ein einfaches Beispiel f\u00fcr die Verwendung von Callbacks in Dash:</p> <pre><code>import dash\nfrom dash import html, dcc, Input, Output\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div([\n    html.Button('Click Me', id='button'),\n    html.Div(id='output')\n])\n\n@app.callback(\n    Output('output', 'children'),\n    Input('button', 'n_clicks')\n)\ndef update_output(n_clicks):\n    if n_clicks is None:\n        return 'No clicks yet'\n    else:\n        return f'Button clicked {n_clicks} times'\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>In diesem Beispiel wird eine einfache Dash-Anwendung erstellt, die einen Button und ein Textfeld enth\u00e4lt. Der Text im Textfeld wird aktualisiert, wenn der Button geklickt wird. Die Callback-Funktion <code>update_output</code> wird aufgerufen, wenn der Button geklickt wird, und aktualisiert den Text basierend auf der Anzahl der Klicks.</p>"},{"location":"python_dash/callbacks/#inhaltsverzeichnis","title":"Inhaltsverzeichnis","text":"<ul> <li>Callbacks</li> <li>Inhaltsverzeichnis</li> <li>Inputs und Outputs<ul> <li>Callbacks mit mehreren Inputs/ Outputs</li> </ul> </li> <li>State</li> <li>Speichereffizienz in Dash<ul> <li>Aufrufen des Callbacks bei Initialisierung</li> <li>Verwendung von <code>prevent_initial_call</code></li> <li>Aufgabe:</li> </ul> </li> </ul>"},{"location":"python_dash/callbacks/#inputs-und-outputs","title":"Inputs und Outputs","text":"<p>Inputs und Outputs in Dash sind die Komponenten, die in der Callback-Funktion verwendet werden. Inputs sind die Ereignisse, auf die reagiert werden soll, w\u00e4hrend Outputs die Komponenten sind, die aktualisiert werden sollen.</p> <p>Inputs und Outputs in Dash werden als Listen von <code>dash.dependencies.Input</code> und <code>dash.dependencies.Output</code>-Objekten definiert. Diese Objekte nehmen die ID und den Attributnamen der Komponenten als Argumente.</p> <p>Ein Beispiel f\u00fcr die Definition von Inputs und Outputs:</p> <pre><code>import dash\nfrom dash import html, dcc, Input, Output\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div([\n    dcc.Input(id='input', value='initial value', type='text'),\n    html.Div(id='output')\n])\n\n@app.callback(\n    Output('output', 'children'),\n    Input('input', 'value')\n)\ndef update_output(value):\n    return f'Input value: {value}'\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>In diesem Beispiel wird ein Eingabefeld (<code>dcc.Input</code>) und ein Textfeld (<code>html.Div</code>) erstellt. Der Text im Textfeld wird aktualisiert, wenn der Wert im Eingabefeld ge\u00e4ndert wird. Die Callback-Funktion <code>update_output</code> wird aufgerufen, wenn der Wert im Eingabefeld ge\u00e4ndert wird, und aktualisiert den Text basierend auf dem neuen Wert.</p>"},{"location":"python_dash/callbacks/#callbacks-mit-mehreren-inputs-outputs","title":"Callbacks mit mehreren Inputs/ Outputs","text":"<p>Dash erm\u00f6glicht es auch, mehrere Inputs und Outputs in einer Callback-Funktion zu verwenden. Dies erm\u00f6glicht es, die Anwendung basierend auf mehreren Ereignissen zu aktualisieren.</p> <pre><code>import dash\nfrom dash import html, dcc, Input, Output\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div([\n    dcc.Input(id='input1', value='initial value', type='text'),\n    dcc.Input(id='input2', value='initial value', type='text'),\n    html.Div(id='output')\n])\n\n@app.callback(\n    Output('output', 'children'),\n    [Input('input1', 'value'), Input('input2', 'value')]\n)\ndef update_output(value1, value2):\n    return f'Input value 1: {value1}, Input value 2: {value2}'\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>In diesem Beispiel werden zwei Eingabefelder (<code>dcc.Input</code>) und ein Textfeld (<code>html.Div</code>) erstellt. Der Text im Textfeld wird aktualisiert, wenn der Wert in einem der Eingabefelder ge\u00e4ndert wird. Die Callback-Funktion <code>update_output</code> nimmt die Werte der beiden Eingabefelder entgegen und aktualisiert den Text basierend auf den neuen Werten.</p> <p>Gleicherma\u00dfen k\u00f6nnen auch mehrere Outputs in einer Callback-Funktion verwendet werden:</p> <pre><code>import dash\nfrom dash import html, dcc, Input, Output\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div([\n    dcc.Input(id='input', value='initial value', type='text'),\n    html.Div(id='output1'),\n    html.Div(id='output2')\n])\n\n@app.callback(\n    [Output('output1', 'children'), Output('output2', 'children')],\n    Input('input', 'value')\n)\ndef update_output(value):\n    return f'Output 1: {value}', f'Output 2: {value}'\n</code></pre> <p>In diesem Beispiel wird ein Eingabefeld (<code>dcc.Input</code>) und zwei Textfelder (<code>html.Div</code>) erstellt. Die Textfelder werden aktualisiert, wenn der Wert im Eingabefeld ge\u00e4ndert wird. Die Callback-Funktion <code>update_output</code> nimmt den Wert des Eingabefelds entgegen und aktualisiert beide Textfelder basierend auf dem neuen Wert.</p> <p>Oftmals m\u00f6chten wir zwar mehrere Eingaben verwenden, jedoch nicht bei jedem Input die Callback-Funktion ausf\u00fchren. In diesem Fall k\u00f6nnen wir die <code>State</code>-Komponente verwenden.</p>"},{"location":"python_dash/callbacks/#state","title":"State","text":"<p>State in Dash ist ein Konzept, das verwendet wird, um den internen Zustand der Anwendung zu speichern. State kann verwendet werden, um Informationen zwischen Callbacks zu \u00fcbertragen oder um den Zustand einer Komponente zu speichern.</p> <p>In Dash wird State als Liste von <code>dash.dependencies.State</code>-Objekten definiert. Diese Objekte nehmen die ID und den Attributnamen der Komponenten als Argumente.</p> <p>Ein Beispiel f\u00fcr die Verwendung von State:</p> <pre><code>import dash\nfrom dash import html, dcc, Input, Output, State\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div([\n    dcc.Input(id='input', value='initial value', type='text'),\n    html.Button('Submit', id='button'),\n    html.Div(id='output')\n])\n\n@app.callback(\n    Output('output', 'children'),\n    Input('button', 'n_clicks'),\n    State('input', 'value')\n)\ndef update_output(n_clicks, value):\n    if n_clicks is None:\n        return 'No clicks yet'\n    else:\n        return f'Button clicked {n_clicks} times, Input value: {value}'\n</code></pre> <p>In diesem Beispiel wird ein Eingabefeld (<code>dcc.Input</code>), ein Button (<code>html.Button</code>) und ein Textfeld (<code>html.Div</code>) erstellt. Der Text im Textfeld wird aktualisiert, wenn der Button geklickt wird. Die Callback-Funktion <code>update_output</code> wird aufgerufen, wenn der Button geklickt wird, und aktualisiert den Text basierend auf der Anzahl der Klicks und dem Wert im Eingabefeld.</p>"},{"location":"python_dash/callbacks/#speichereffizienz-in-dash","title":"Speichereffizienz in Dash","text":"<p>Normalerweise werden Callback-Funktionen in Dash serverseitig aufgerufen, wenn ein Ereignis eintritt. Dies kann bei vielen Aufrufen und gro\u00dfen Datenmengen zu einer Verz\u00f6gerung f\u00fchren, die wir vermeiden m\u00f6chten. Wir werden uns nun einige M\u00f6glichkeiten ansehen, um Ressourcen zu schonen und die Effizienz von Dash-Anwendungen zu verbessern.</p>"},{"location":"python_dash/callbacks/#aufrufen-des-callbacks-bei-initialisierung","title":"Aufrufen des Callbacks bei Initialisierung","text":"<p>Eine M\u00f6glichkeit um Ressourcen zu schonen ist es, die Callback-Funktion clientseitig aufzurufen.</p> <p>Manchmal m\u00f6chten wir, dass ein Callback-Funktion bei der Initialisierung der Anwendung aufgerufen wird. Dies kann beispielsweise n\u00fctzlich sein, um den Anfangszustand der Anwendung zu setzen.</p> <p>In Dash k\u00f6nnen wir das <code>app.clientside_callback</code>-Dekorator verwenden, um eine Callback-Funktion bei der Initialisierung der Anwendung aufzurufen.</p> <pre><code>import dash\nfrom dash import html, dcc, Input, Output, State\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div([\n    dcc.Input(id='input', value='initial value', type='text'),\n    html.Div(id='output')\n])\n\n@app.clientside_callback(\n    Output('output', 'children'),\n    Input('input', 'value')\n)\ndef update_output(value):\n    return f'Input value: {value}'\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>In diesem Beispiel wird ein Eingabefeld (<code>dcc.Input</code>) und ein Textfeld (<code>html.Div</code>) erstellt. Der Text im Textfeld wird aktualisiert, wenn der Wert im Eingabefeld ge\u00e4ndert wird. Die Callback-Funktion <code>update_output</code> wird bei der Initialisierung der Anwendung aufgerufen und setzt den Text basierend auf dem Anfangswert des Eingabefelds.</p>"},{"location":"python_dash/callbacks/#verwendung-von-prevent_initial_call","title":"Verwendung von <code>prevent_initial_call</code>","text":"<p>Manchmal m\u00f6chten wir verhindern, dass eine Callback-Funktion bei der Initialisierung der Anwendung aufgerufen wird. Dies kann n\u00fctzlich sein, wenn die Callback-Funktion teure Berechnungen durchf\u00fchrt oder auf externe Ressourcen zugreift.</p> <p>In Dash k\u00f6nnen wir das Argument <code>prevent_initial_call=True</code> verwenden, um zu verhindern, dass eine Callback-Funktion bei der Initialisierung der Anwendung aufgerufen wird.</p> <pre><code>import dash\nfrom dash import html, dcc, Input, Output, State\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div([\n    dcc.Input(id='input', value='initial value', type='text'),\n    html.Div(id='output')\n])\n\n@app.callback(\n    Output('output', 'children'),\n    Input('input', 'value'),\n    prevent_initial_call=True\n)\ndef update_output(value):\n    return f'Input value: {value}'\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>In diesem Beispiel wird ein Eingabefeld (<code>dcc.Input</code>) und ein Textfeld (<code>html.Div</code>) erstellt. Der Text im Textfeld wird aktualisiert, wenn der Wert im Eingabefeld ge\u00e4ndert wird. Die Callback-Funktion <code>update_output</code> wird nur aufgerufen, wenn der Wert im Eingabefeld ge\u00e4ndert wird, nicht bei der Initialisierung der Anwendung.</p>"},{"location":"python_dash/callbacks/#aufgabe","title":"Aufgabe:","text":"<p>Erstellen Sie ein Dashboard mit folgenden Komponenten und Funktionen:</p> <ol> <li>Zwei Eingabefelder (<code>dcc.Input</code>) f\u00fcr numerische Werte.</li> <li>Ein Dropdown-Men\u00fc (<code>dcc.Dropdown</code>) mit verschiedenen mathematischen Operationen (Addition, Subtraktion, Multiplikation, Division).</li> <li>Ein Button zum Ausf\u00fchren der Berechnung.</li> <li>Zwei Ausgabefelder (<code>html.Div</code>):<ul> <li>Ein Feld, das das Ergebnis der Berechnung anzeigt.</li> <li>Ein Feld, das die Anzahl der Berechnungen anzeigt.</li> </ul> </li> </ol> <p>Verwenden Sie einen Callback mit mehreren Inputs (die beiden Eingabefelder und das Dropdown-Men\u00fc) und mehreren Outputs (die beiden Ausgabefelder). Nutzen Sie den <code>State</code> f\u00fcr die Eingabefelder und das Dropdown-Men\u00fc, sodass die Berechnung erst bei Knopfdruck ausgef\u00fchrt wird. Verwenden Sie <code>prevent_initial_call=True</code>, um zu verhindern, dass der Callback bei der Initialisierung aufgerufen wird. Implementieren Sie eine einfache Caching-Strategie f\u00fcr die Berechnungsfunktion.</p>"},{"location":"python_dash/dcc_store/","title":"Daten zwischen Dash-Komponenten teilen","text":"<p>Wie auch bei anderen Anwendungen wollen wir in Dash globale Variablen vermeiden. Insbesondere, da Dash serverseitig arbeitet, k\u00f6nnen globale Variablen zu unerwartetem Verhalten f\u00fchren. Stattdessen k\u00f6nnen Daten zwischen verschiedenen Dash-Komponenten geteilt werden, indem wir ein <code>Store</code> Objekt verwenden. Das Store Objekt kann Daten sogar \u00fcber einen l\u00e4ngeren Zeitraum speichern und selbst nach einem Neustart der Anwendung wieder aufrufen.</p>"},{"location":"python_dash/dcc_store/#dccstore","title":"dcc.Store","text":"<p>Das <code>dcc.Store</code>-Komponente wird verwendet, um Daten tempor\u00e4r zu speichern. Die Daten werden im Browser des Benutzers gespeichert und gehen nicht verloren, wenn die Seite neu geladen wird.</p> <pre><code>import dash\nfrom dash import html\nfrom dash import dcc\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div([\n    dcc.Input(id='input', type='text', value=''),\n    dcc.Store(id='store'),\n    html.Div(id='output'),\n    html.Button('Clear Data', id='clear-button')\n])\n\n@app.callback(\n    dash.dependencies.Output('store', 'data'),\n    [dash.dependencies.Input('input', 'value')]\n)\ndef update_store(input_value):\n    return input_value\n\n@app.callback(\n    dash.dependencies.Output('output', 'children'),\n    [dash.dependencies.Input('store', 'data')]\n)\ndef update_output(data):\n    return f'Input: {data}'\n\n@app.callback(\n    dash.dependencies.Output('store', 'data'),\n    [dash.dependencies.Input('clear-button', 'n_clicks')]\n)\ndef clear_data(n_clicks):\n    if n_clicks:\n        return None\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>Dadurch, dass die Daten in einer eigenen Component liegen, k\u00f6nnen Sie als State zwischen den Components geteilt werden. In dem Objekt liegen die Daten im Json Format vor.</p>"},{"location":"python_dash/erste_schritte/","title":"Erste Schritte mit Dash","text":"<p>Um eine einfache Dash-Anwendung zu starten, muss eine Instanz der <code>dash.Dash</code>-Klasse erstellt werden. Diese Instanz dient als Container f\u00fcr die Anwendung. Anschlie\u00dfend k\u00f6nnen Layout und Callbacks definiert werden.</p> <p>\u00dcber das Layout wird festgelegt, wie die Anwendung aussieht. Das Layout wird beispielsweise durch HTML-Elemente wie \u00dcberschriften, Textfelder oder Schaltfl\u00e4chen definiert. Diese Komponenten sind gro\u00dfteils in den Modulen <code>dash.html</code> und <code>dash.core_components</code> enthalten.</p> <p>Callbacks sind Funktionen, die aufgerufen werden, wenn ein bestimmtes Ereignis eintritt. Beispielsweise kann eine Callback-Funktion aufgerufen werden, wenn ein Button gedr\u00fcckt wird. Callbacks werden in Dash verwendet, um die Interaktivit\u00e4t der Anwendung zu steuern.</p> <pre><code>import dash\nfrom dash import html\n\napp = dash.Dash(__name__)\n\napp.layout = html.H1('Hello World')\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>Um die Anwendung zu starten, kann das Skript ausgef\u00fchrt werden. Anschlie\u00dfend kann die Anwendung im Browser unter <code>localhost:8000</code> aufgerufen werden.</p> <p>Wir werden uns als n\u00e4chstes das Layout und in dem Zusammenhang die verschiedenen Komponenten und M\u00f6glichkeiten f\u00fcr das Styling von Dash-Anwendungen ansehen.</p>"},{"location":"python_dash/layout/","title":"Erstellung von Layouts","text":"<p>Die visuelle Gestaltung von Dash-Anwendungen erfolgt \u00fcber das Layout. Im Layout werden die Komponenten festgelegt, die in der Anwendung angezeigt werden. Die Komponenten k\u00f6nnen beispielsweise Textfelder, Schaltfl\u00e4chen oder Diagramme sein.</p> <p>Dash bietet verschiedene Module, die die Erstellung von Layouts erleichtern. Die wichtigsten Module sind:</p> <ul> <li><code>dash.html</code>: Enth\u00e4lt HTML-Elemente wie \u00dcberschriften, Textfelder oder Schaltfl\u00e4chen.</li> <li><code>dash.core_components</code>: Enth\u00e4lt interaktive Komponenten wie Diagramme, Dropdown-Men\u00fcs oder Schieberegler.</li> <li><code>dash.dcc</code>: Enth\u00e4lt alle Komponenten aus <code>dash.core_components</code> und <code>dash.html</code>.</li> </ul> <p>In diesem Kapitel werden wir uns die verschiedenen Komponenten und M\u00f6glichkeiten f\u00fcr das Styling von Dash-Anwendungen ansehen.</p>"},{"location":"python_dash/layout/#inhaltsverzeichnis","title":"Inhaltsverzeichnis","text":"<ul> <li>Erstellung von Layouts</li> <li>Inhaltsverzeichnis</li> <li>HTML-Elemente</li> <li>Interaktive Komponenten</li> </ul>"},{"location":"python_dash/layout/#html-elemente","title":"HTML-Elemente","text":"<p>Das Modul <code>dash.html</code> enth\u00e4lt verschiedene HTML-Elemente, die in Dash-Anwendungen verwendet werden k\u00f6nnen. Die Elemente k\u00f6nnen beispielsweise \u00dcberschriften, Textfelder oder Schaltfl\u00e4chen sein.</p> <p>Einige Beispiele f\u00fcr HTML-Elemente sind:</p> <ul> <li><code>html.H1</code>: Erstellt eine \u00dcberschrift der Gr\u00f6\u00dfe 1.</li> <li><code>html.P</code>: Erstellt einen Absatz.</li> <li><code>html.Button</code>: Erstellt eine Schaltfl\u00e4che.</li> </ul> <pre><code>import dash\nfrom dash import html\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div([\n    html.H1('Hello World'),\n    html.P('This is a paragraph.'),\n    html.Button('Click Me', id='button')\n])\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>In diesem Beispiel wird eine einfache Dash-Anwendung erstellt, die eine \u00dcberschrift, einen Absatz und eine Schaltfl\u00e4che enth\u00e4lt.</p>"},{"location":"python_dash/layout/#interaktive-komponenten","title":"Interaktive Komponenten","text":"<p>Das Modul <code>dash.core_components</code> enth\u00e4lt interaktive Komponenten, die in Dash-Anwendungen verwendet werden k\u00f6nnen. Die Komponenten k\u00f6nnen beispielweise Diagramme, Dropdown-Men\u00fcs oder Schieberegler sein. Das Modul <code>dash.dcc</code> enth\u00e4lt alle Komponenten aus <code>dash.core_components</code> und <code>dash.html</code>. Wir verwenden in diesem Kapitel <code>dash.dcc</code>.</p> <p>Einige Beispiele f\u00fcr interaktive Komponenten sind:</p> <ul> <li><code>dcc.Graph</code>: Erstellt ein Diagramm.</li> <li><code>dcc.Dropdown</code>: Erstellt ein Dropdown-Men\u00fc.</li> <li><code>dcc.Slider</code>: Erstellt einen Schieberegler.</li> </ul> <pre><code>import dash\nfrom dash import html\nfrom dash import dcc\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div([\n    dcc.Graph(\n        figure={\n            'data': [\n                {'x': [1, 2, 3], 'y': [4, 1, 2], 'type': 'bar', 'name': 'Berlin'},\n                {'x': [1, 2, 3], 'y': [2, 4, 5], 'type': 'bar', 'name': 'M\u00fcnchen'},\n            ],\n            'layout': {\n                'title': 'Dash Data Visualization'\n            }\n        }\n    ),\n    dcc.Dropdown(\n        options=[\n            {'label': 'Berlin', 'value': 'Berlin'},\n            {'label': 'M\u00fcnchen', 'value': 'M\u00fcnchen'}\n        ],\n        value='Berlin'\n    ),\n    dcc.Slider(\n        min=0,\n        max=9,\n        marks={i: str(i) for i in range(10)},\n        value=5\n    )\n])\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>In diesem Beispiel wird eine Dash-Anwendung erstellt, die ein Diagramm, ein Dropdown-Men\u00fc und einen Schieberegler enth\u00e4lt. Das Diagramm zeigt zwei Balkendiagramme f\u00fcr die St\u00e4dte Berlin und M\u00fcnchen.</p>"},{"location":"python_dash/layout/#aufgabe","title":"Aufgabe:","text":"<p>Erstelle eine Dash-Anwendung f\u00fcr einen Discounter, die folgende Elemente enth\u00e4lt:</p> <ol> <li>Eine \u00dcberschrift (H1) mit dem Namen des Discounters.</li> <li>Ein Dropdown-Men\u00fc zur Auswahl verschiedener Produktkategorien (z.B. Obst, Gem\u00fcse, Milchprodukte).</li> <li>Ein Balkendiagramm, das die Verkaufszahlen f\u00fcr die Top 5 Produkte der ausgew\u00e4hlten Kategorie anzeigt.</li> <li>Einen Schieberegler, mit dem der Benutzer einen Preisbereich ausw\u00e4hlen kann.</li> </ol> <p>Verwende dazu die passenden Komponenten aus <code>dash.html</code> und <code>dash.dcc</code>.</p>"},{"location":"python_dash/multipage_apps/","title":"Multipage Apps","text":"<p>Seit dash 2.5. gibt es die M\u00f6glichkeit, in Dash Apps mit mehreren Seiten durch eine Ordnerstruktur, \u00e4hnlich zu NextJS zu erstellen. </p> <pre><code>app.py\npages/\n    __init__.py\n    home.py\n    archive.py\n</code></pre> <p>Die einzelnen Seiten werden \u00fcber das keyword argument <code>use_pages=True</code> in der app initialisierung aktiviert. </p> <pre><code>import dash\nfrom dash import Dash, html, dcc\n\napp = Dash(__name__, use_pages=True)\n\napp.layout = html.Div([\n    html.H1('Multi-page app with Dash Pages'),\n    html.Div([\n        html.Div(\n            dcc.Link(f\"{page['name']} - {page['path']}\", href=page[\"relative_path\"])\n        ) for page in dash.page_registry.values()\n    ]),\n    dash.page_container\n])\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre> <p>Die einzelnen Seiten werden in den <code>page</code>-Dateien definiert. </p> <p>Seite <code>home.py</code> <pre><code>import dash\nfrom dash import html\n\ndash.register_page(__name__, path='/')\n\nlayout = html.Div([\n    html.H1('This is our Home page'),\n    html.Div('This is our Home page content.'),\n])\n</code></pre></p> <p>Seite <code>archive.py</code> <pre><code>import dash\nfrom dash import html\n\ndash.register_page(__name__)\n\nlayout = html.Div([\n    html.H1('This is our Archive page'),\n    html.Div('This is our Archive page content.'),\n])\n</code></pre></p>"},{"location":"python_dash/multipage_apps/#aufgabe","title":"Aufgabe:","text":"<p>F\u00fcge eine weitere Seite hinzu und stelle diese in der Navigationsleiste dar.</p>"},{"location":"python_dash/styles/","title":"Styles","text":"<p>\u00c4hnlich, wie wir in html und css Styles verwenden k\u00f6nnen, um das Aussehen einer Webseite zu ver\u00e4ndern, k\u00f6nnen wir auch in Dash-Anwendungen Styles verwenden, um das Aussehen der Anwendung zu ver\u00e4ndern. In Dash k\u00f6nnen Styles entweder inline oder \u00fcber externe Stylesheets definiert werden. </p> <p>Neben den Standard-HTML- und CSS-Styles k\u00f6nnen in Dash auch Third-Party-Styles verwendet werden. Zu den Dash-Styles geh\u00f6ren beispielsweise die Bootstrap-Styles, die in Dash integriert sind und verwendet werden k\u00f6nnen, um das Aussehen der Anwendung zu ver\u00e4ndern.</p>"},{"location":"python_dash/styles/#inhaltsverzeichnis","title":"Inhaltsverzeichnis","text":"<ul> <li>Styles</li> <li>Inhaltsverzeichnis</li> <li>Inline Styles</li> <li>Externe Stylesheets</li> <li>Dash Bootstrap</li> </ul>"},{"location":"python_dash/styles/#inline-styles","title":"Inline Styles","text":"<p>Inline Styles sind Styles, die direkt in den Komponenten definiert werden. Sie werden als Python-Dictionary \u00fcbergeben und k\u00f6nnen beispielsweise die Farbe, Schriftgr\u00f6\u00dfe oder den Abstand eines Elements festlegen.</p> <p>Ein Beispiel f\u00fcr die Verwendung von Inline Styles ist:</p> <pre><code>import dash\nfrom dash import html\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div(\n    children='Hello World',\n    style={\n        'color': 'red',\n        'fontSize': 24,\n        'margin': 20\n    }\n)\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>In diesem Beispiel wird ein <code>html.Div</code>-Element erstellt, das den Text 'Hello World' enth\u00e4lt. Das Element hat die Farbe Rot, eine Schriftgr\u00f6\u00dfe von 24 und einen Abstand von 20 Pixeln.</p>"},{"location":"python_dash/styles/#externe-stylesheets","title":"Externe Stylesheets","text":"<p>Externe Stylesheets sind Styles, die in einer separaten CSS-Datei definiert werden. Diese Stylesheets k\u00f6nnen dann in der Dash-Anwendung eingebunden werden, um das Aussehen der Anwendung zu ver\u00e4ndern.</p> <p>Ein Beispiel f\u00fcr die Verwendung von externen Stylesheets ist:</p> <pre><code>import dash\nfrom dash import html\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div(\n    children='Hello World',\n    className='my-class'\n)\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>In diesem Beispiel wird ein <code>html.Div</code>-Element erstellt, das den Text 'Hello World' enth\u00e4lt. Das Element verwendet die Klasse <code>my-class</code>, die in einem externen Stylesheet definiert ist. Das Stylesheet k\u00f6nnte beispielsweise folgenden Inhalt haben:</p> <pre><code>.my-class {\n    color: red;\n    font-size: 24px;\n    margin: 20px;\n}\n</code></pre> <p>Um dieses Stylesheet in der Dash-Anwendung zu verwenden, muss es im gleichen Verzeichnis wie das Skript gespeichert werden und den Namen <code>styles.css</code> haben. Anschlie\u00dfend kann es in der Dash-Anwendung eingebunden werden, indem der Parameter <code>external_stylesheets</code> an die <code>dash.Dash</code>-Instanz \u00fcbergeben wird:</p> <pre><code>import dash\nfrom dash import html\n\napp = dash.Dash(__name__, external_stylesheets=['styles.css'])\n\napp.layout = html.Div(\n    children='Hello World',\n    className='my-class'\n)\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre>"},{"location":"python_dash/styles/#aufgabe","title":"Aufgabe:","text":"<p>Aufgabe 1: Kombiniere Inline-Styles und externe Stylesheets in einer Dash-Anwendung. Erstelle eine Tabelle, bei der die Tabellen\u00fcberschriften durch Inline-Styles formatiert sind, w\u00e4hrend die Tabellenzeilen eine Klasse aus einem externen Stylesheet verwenden.</p>"},{"location":"python_dash/styles/#dash-bootstrap","title":"Dash Bootstrap","text":"<p>Ein einfacher Weg, um in kurzer Zeit zu optisch ansprechenden Komponenten zu kommen, ist die Verwendung von Dash Bootstrap. Dash Bootstrap ist eine Sammlung von vorgefertigten Komponenten und Layouts, die auf der Bootstrap-Bibliothek basieren.</p> <p>Um Dash Bootstrap zu verwenden, muss das <code>dash_bootstrap_components</code>-Modul installiert und in der Dash-Anwendung eingebunden werden. Anschlie\u00dfend k\u00f6nnen die vorgefertigten Komponenten und Layouts verwendet werden, um das Aussehen der Anwendung zu ver\u00e4ndern.</p> <pre><code>import dash\nimport dash_bootstrap_components as dbc\n\napp = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n\napp.layout = dbc.Container(\n    dbc.Alert('Hello World', color='primary'),\n    className='my-class'\n)\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre> <p>In diesem Beispiel wird ein <code>dbc.Alert</code>-Element erstellt, das den Text 'Hello World' enth\u00e4lt. Das Element verwendet das Bootstrap-Theme <code>BOOTSTRAP</code>, das in der Dash-Anwendung eingebunden wird. Durch die Verwendung von Dash Bootstrap k\u00f6nnen schnell und einfach ansprechende Dash-Anwendungen erstellt werden.</p>"},{"location":"python_polars/","title":"Polars in Python","text":"<p>Lange Zeit war Pandas die erste Wahl f\u00fcr die Datenverarbeitung in Python. Zwar ist Pandas deutlich schneller als beispielsweise Excel, doch f\u00fcr gro\u00dfe Datens\u00e4tze reicht die Performance teilweise nicht mehr aus. Hier kommt Polars ins Spiel. Polars ist eine moderne Datenverarbeitungsbibliothek, die speziell f\u00fcr die Verarbeitung gro\u00dfer Datens\u00e4tze entwickelt wurde. In diesem Kapitel werden wir uns ansehen, wie Polars in Python verwendet werden kann.</p>"},{"location":"python_polars/#warum-ist-polars-schneller-als-pandas","title":"Warum ist Polars schneller als Pandas?","text":"<p>Polars ist deutlich schneller als pandas, was auf eine Reihe technischer und architektonischer Unterschiede zur\u00fcckzuf\u00fchren ist:</p>"},{"location":"python_polars/#1-speicherlayout-und-hardware-nutzung","title":"1. Speicherlayout und Hardware-Nutzung","text":"<ul> <li>Spaltenorientiertes Speicherlayout: Polars speichert Daten in einem spaltenorientierten Format, \u00e4hnlich wie Apache Arrow. Das bedeutet, dass alle Daten einer Spalte im Speicher direkt hintereinander liegen. Das erm\u00f6glicht es modernen CPUs, diese Daten schneller zu verarbeiten, da sie optimierte Speicherzugriffe und Caching besser nutzen k\u00f6nnen.</li> <li>Vektorisiertes Rechnen: Polars nutzt sogenannte SIMD-Instruktionen (Single Instruction, Multiple Data). Das bedeutet, es kann mehrere Werte mit einem einzigen CPU-Befehl verarbeiten, was die Geschwindigkeit der Berechnungen erheblich erh\u00f6ht.</li> <li>Multithreading und Parallelisierung: Polars verteilt Rechenoperationen automatisch auf mehrere CPU-Kerne. Da pandas im Wesentlichen Single-threaded ist, profitiert Polars stark von Multi-Core-Prozessoren.</li> </ul>"},{"location":"python_polars/#2-programmiersprache-rust","title":"2. Programmiersprache Rust","text":"<ul> <li>Polars wurde in Rust entwickelt, einer Hochleistungssprache, die sowohl sehr schnell als auch speichereffizient ist. Rust bietet zudem strenge Speichersicherheitsmechanismen, die verhindern, dass typische Fehler wie Speicherlecks oder Puffer\u00fcberl\u00e4ufe entstehen, ohne dass dabei die Performance leidet.</li> <li>Pandas hingegen ist in Python geschrieben, einer interpretieren Sprache, die im Vergleich langsamer ist. Zwar sind viele Funktionen von pandas in C oder Cython implementiert, aber Python selbst bleibt oft der Flaschenhals.</li> </ul>"},{"location":"python_polars/#3-lazy-evaluation","title":"3. Lazy Evaluation","text":"<ul> <li>Polars nutzt Lazy Evaluation, d. h. Berechnungen werden nicht sofort ausgef\u00fchrt. Stattdessen erstellt Polars einen optimierten Ausf\u00fchrungsplan, bevor es die Daten verarbeitet. Das erm\u00f6glicht eine deutliche Effizienzsteigerung, da unn\u00f6tige Berechnungen vermieden werden.</li> <li>Im Gegensatz dazu f\u00fchrt pandas Operationen direkt aus, was h\u00e4ufig zu einer weniger optimalen Nutzung von Rechenressourcen f\u00fchrt.</li> </ul>"},{"location":"python_polars/#4-effiziente-speicherverwaltung","title":"4. Effiziente Speicherverwaltung","text":"<ul> <li>Polars bietet eine sehr optimierte Speicherverwaltung. Rust kommt ohne Garbage Collection aus, was bedeutet, dass Polars den Speicher effizient und kontrolliert nutzen kann. Dies minimiert unn\u00f6tige Speicherbewegungen und maximiert die Rechenleistung.</li> <li>Pandas hingegen verwendet Python's Garbage Collector, was zu unn\u00f6tigem Overhead f\u00fchren kann und sich negativ auf die Performance auswirkt.</li> </ul>"},{"location":"python_polars/#5-optimiertes-handling-von-null-werten","title":"5. Optimiertes Handling von Null-Werten","text":"<ul> <li>Polars verwendet optimierte Datenstrukturen, um fehlende Werte effizient zu handhaben. Pandas hingegen nutzt h\u00e4ufig NaN-Werte, was in numerischen Berechnungen zus\u00e4tzlichen Overhead verursachen kann.</li> </ul>"},{"location":"python_polars/#6-schnellere-ein-ausgabe-io","title":"6. Schnellere Ein-/Ausgabe (I/O)","text":"<ul> <li>Polars ist f\u00fcr effiziente I/O-Operationen optimiert. Es kann Daten aus Formaten wie Parquet oder Arrow direkt von der Festplatte lesen, ohne sie vollst\u00e4ndig in den Arbeitsspeicher zu laden. Dies reduziert sowohl die Verarbeitungszeit als auch den Speicherverbrauch erheblich.</li> </ul> <p>Einen ausf\u00fchrlichen Vergleich zum Einlese von Daten in pandas und polars k\u00f6nnen wir hier finden: Polars vs Pandas</p> <p>Neben Polars bietet auch Spark eine performante Alternative zu Pandas. Wir werden uns in diesem Fall auf Polars beschr\u00e4nken, da es in lokalen Umgebungen in der Regel performanter ist. Spark hingegen ist f\u00fcr verteilte Systeme und Big Data-Anwendungen optimiert.</p> <p>Einen weiteren Vergleich f\u00fcr die Frage, wann pandas, polars oder spark verwendet werden sollte, finden wir hier: Polars vs Pandas vs Spark. Zusammenfassend wird aus der Quelle folgendes empfohlen:</p> Anwendungsfall Empfehlung Begr\u00fcndung Kleinere Datens\u00e4tze Polars Gute Standardwahl f\u00fcr kleinere Datenmengen Kleinere Datens\u00e4tze mit begrenzter CPU-Auslastung Pandas Optimiert f\u00fcr niedrige CPU-Auslastung Gro\u00dfe DataFrames mit verteiltem Rechnen Spark Schnellste Ausf\u00fchrungszeit, jedoch hohe Spitzen bei Speicher- und CPU-Auslastung Vorhersehbare Speicher- und CPU-Nutzung bei kleinen und gro\u00dfen DataFrames Polars Stabile, vorhersehbare Nutzung von Speicher und CPU, auch bei gr\u00f6\u00dferen Datens\u00e4tzen, l\u00e4ngere Ausf\u00fchrungszeit als Spark <p>Aktuell wird f\u00fcr lokale Entwicklungsumgebungen die Verwendung von Polars empfohlen.</p>"},{"location":"python_polars/best_practices/","title":"Best Practices f\u00fcr die Arbeit mit Polars","text":""},{"location":"python_polars/best_practices/#1-nutze-lazy-execution","title":"1. Nutze Lazy Execution","text":"<ul> <li>Do: Verwende <code>LazyFrames</code>, um deine Abfragen zu optimieren. Lass Polars die gesamte Abfrage analysieren und optimieren, bevor du die Ausf\u00fchrung anforderst.</li> </ul> <pre><code>lazy_df = df.lazy().filter(pl.col(\"age\") &gt; 30).groupby(\"city\").agg(pl.col(\"salary\").mean())\nresult = lazy_df.collect()\n</code></pre> <ul> <li>Don't: Vermeide es, <code>EagerFrames</code> ohne Grund zu verwenden, da dies zu ineffizienten Berechnungen f\u00fchren kann, die Ressourcen verschwenden.</li> </ul> <pre><code>result = df.filter(pl.col(\"age\") &gt; 30).groupby(\"city\").agg(pl.col(\"salary\").mean())  # ineffizient\n</code></pre>"},{"location":"python_polars/best_practices/#2-optimierung-durch-expression-api","title":"2. Optimierung durch Expression API","text":"<ul> <li>Do: Nutze die Expression API, um klare und lesbare Abfragen zu erstellen, die Polars helfen, deine Absichten zu verstehen.</li> </ul> <pre><code>result = df.select([\n    pl.col(\"salary\").mean().alias(\"avg_salary\"),\n    pl.col(\"age\").min().alias(\"min_age\")\n])\n</code></pre> <ul> <li>Don't: Vermeide es, mehrere Schritte in einer einzelnen Pipeline ohne Verwendung der Expression API zu kombinieren, da dies die Lesbarkeit und Wartbarkeit deines Codes beeintr\u00e4chtigen kann.</li> </ul> <pre><code>result = df.with_column(pl.col(\"salary\") * 1.1).select(\"salary\", \"age\")  # nicht optimal\n</code></pre>"},{"location":"python_polars/best_practices/#3-datenformate-und-io-optimierung","title":"3. Datenformate und I/O-Optimierung","text":"<ul> <li>Do: W\u00e4hle effiziente Datenformate wie Parquet oder Arrow f\u00fcr den Import und Export, um die Leistung zu steigern.</li> </ul> <pre><code>df.write_parquet(\"data.parquet\")\n</code></pre> <ul> <li>Don't: Verwende keine textbasierten Formate wie CSV f\u00fcr gro\u00dfe Datenmengen, da dies die Ladezeiten und die Effizienz negativ beeinflussen kann.</li> </ul> <pre><code>df.to_csv(\"data.csv\")  # ineffizient f\u00fcr gro\u00dfe Datenmengen\n</code></pre>"},{"location":"python_polars/best_practices/#4-nutze-die-vorteile-von-multithreading","title":"4. Nutze die Vorteile von Multithreading","text":"<ul> <li>Do: Lass Polars die Vorteile der Multithreading-Verarbeitung nutzen, indem du Operationen auf gro\u00dfen DataFrames durchf\u00fchrst, die parallelisiert werden k\u00f6nnen.</li> </ul> <pre><code>result = df.filter(pl.col(\"age\") &gt; 30).groupby(\"city\").agg(pl.col(\"salary\").mean())\n</code></pre> <ul> <li>Don't: Vermeide es, manuell Threads zu erstellen oder Daten selbst zu partitionieren. Polars k\u00fcmmert sich automatisch um die Parallelisierung.</li> </ul> <pre><code># Manuelles Multithreading ist nicht notwendig\n</code></pre>"},{"location":"python_polars/best_practices/#5-speicher-und-typmanagement","title":"5. Speicher- und Typmanagement","text":"<ul> <li>Do: Verwende die richtigen Datentypen f\u00fcr deine Spalten (z.B. <code>Int32</code> statt <code>Int64</code>), um den Speicherverbrauch zu optimieren.</li> </ul> <pre><code>df = df.with_columns(pl.col(\"id\").cast(pl.Int32))  # Speichereffizient\n</code></pre> <ul> <li>Don't: Vermeide es, unn\u00f6tige Datentypen zu verwenden, die mehr Speicherplatz als n\u00f6tig beanspruchen.</li> </ul> <pre><code>df = df.with_columns(pl.col(\"id\").cast(pl.Int64))  # nicht optimal, wenn Int32 ausreichend ist\n</code></pre>"},{"location":"python_polars/best_practices/#6-effiziente-filterung-und-aggregation","title":"6. Effiziente Filterung und Aggregation","text":"<ul> <li>Do: Wende Filteroperationen so fr\u00fch wie m\u00f6glich an, um die Anzahl der verarbeiteten Zeilen zu reduzieren.</li> </ul> <pre><code>df.filter(pl.col(\"age\") &gt; 30).groupby(\"city\").agg(pl.col(\"salary\").mean())\n</code></pre> <ul> <li>Don't: Vermeide es, zuerst Aggregationen durchzuf\u00fchren, bevor du die Daten filterst, da dies die Verarbeitung unn\u00f6tig aufbl\u00e4hen kann.</li> </ul> <pre><code>df.groupby(\"city\").agg(pl.col(\"salary\").mean()).filter(pl.col(\"age\") &gt; 30)  # ineffizient\n</code></pre>"},{"location":"python_polars/best_practices/#7-profiling-und-debugging","title":"7. Profiling und Debugging","text":"<ul> <li>Do: Nutze die Funktionen <code>describe_plan()</code> und <code>describe_optimized_plan()</code>, um den Query Plan zu analysieren und Leistungsengp\u00e4sse zu identifizieren.</li> </ul> <pre><code>lazy_df.describe_plan()\n</code></pre> <ul> <li>Don't: Ignoriere die M\u00f6glichkeit zur Profilierung und f\u00fchre nicht optimierte Abfragen aus, ohne deren Leistung zu pr\u00fcfen.</li> </ul> <pre><code># Keine Profilierung macht die Performance schwer zu bewerten\n</code></pre>"},{"location":"python_polars/best_practices/#8-fallstricke-vermeiden","title":"8. Fallstricke vermeiden","text":"<ul> <li>Do: Speichere Zwischenergebnisse in Variablen, um redundante Berechnungen zu vermeiden.</li> </ul> <pre><code>filtered_df = df.filter(pl.col(\"age\") &gt; 30)\nresult = filtered_df.groupby(\"city\").agg(pl.col(\"salary\").mean())\n</code></pre> <ul> <li>Don't: F\u00fchre gleiche Berechnungen mehrfach durch, da dies unn\u00f6tige Ressourcen verbraucht.</li> </ul> <pre><code>result = df.filter(pl.col(\"age\") &gt; 30).groupby(\"city\").agg(pl.col(\"salary\").mean())\nresult2 = df.filter(pl.col(\"age\") &gt; 30).groupby(\"city\").agg(pl.col(\"salary\").sum())  # redundant\n</code></pre>"},{"location":"python_polars/best_practices/#9-datenvalidierung-und-bereinigung","title":"9. Datenvalidierung und -bereinigung","text":"<ul> <li>Do: Behandle fehlende Werte und andere Datenprobleme, um die Integrit\u00e4t deiner Analysen sicherzustellen.</li> </ul> <pre><code>df.fill_null(0)  # Fehlende Werte mit 0 ersetzen\n</code></pre> <ul> <li>Don't: Ignoriere fehlende oder ung\u00fcltige Daten, da dies zu fehlerhaften Ergebnissen f\u00fchren kann.</li> </ul> <pre><code># Fehlende Werte werden nicht behandelt, was die Analyse beeintr\u00e4chtigen kann\n</code></pre>"},{"location":"python_polars/best_practices/#10-dokumentation-und-community","title":"10. Dokumentation und Community","text":"<ul> <li>Do: Nutze die offizielle Polars-Dokumentation, um dich \u00fcber Funktionen und Best Practices zu informieren.</li> </ul> <pre><code># Lese die Dokumentation auf der offiziellen Polars-Website\n</code></pre> <ul> <li>Don't: Verlasse dich nicht ausschlie\u00dflich auf Tutorials oder externe Quellen ohne Verweis auf die offizielle Dokumentation, da diese veraltet oder ungenau sein k\u00f6nnen.</li> </ul> <pre><code># Vermeide das Vertrauen auf potenziell ungenaue Informationen\n</code></pre> <p>Mit diesen Do's and Don'ts erh\u00e4ltst du klare Anleitungen, wie du Polars effektiv nutzen kannst, um die Effizienz und Leistung deiner Datenanalysen zu maximieren.</p>"},{"location":"python_polars/erste_schritte/","title":"Erste Schritte mit Polars","text":"<p>Polars \u00e4hnelt sich in der Syntax zu Pandas. So k\u00f6nnen wir auch hier mit <code>DataFrame</code>-Objekten arbeiten. </p> <pre><code>import polars as pl\n\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [24, 25, 26, 27],\n    'city': ['Berlin', 'Hamburg', 'Munich', 'Cologne']\n}\n\ndf = pl.DataFrame(data)\nprint(df)\n</code></pre> <pre><code>shape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name    \u2506 age \u2506 city    \u2502\n\u2502 str     \u2506 i64 \u2506 str     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Alice   \u2506 24  \u2506 Berlin  \u2502\n\u2502 Bob     \u2506 25  \u2506 Hamburg \u2502\n\u2502 Charlie \u2506 26  \u2506 Munich  \u2502\n\u2502 David   \u2506 27  \u2506 Cologne \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Wir k\u00f6nnen auch die Daten filtern, sortieren und gruppieren. </p> <pre><code>filtered = df.filter(pl.col('age') &gt; 25)\nprint(filtered)\n</code></pre> <pre><code>shape: (2, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name    \u2506 age \u2506 city    \u2502\n\u2502 str     \u2506 i64 \u2506 str     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Charlie \u2506 26  \u2506 Munich  \u2502\n\u2502 David   \u2506 27  \u2506 Cologne \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Anders als bei Pandas m\u00fcssen wir hier die Spaltennamen als <code>pl.col('name')</code> angeben.</p> <pre><code>sorted_df = df.sort('age', reverse=True)\nprint(sorted_df)\n</code></pre> <pre><code>shape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name    \u2506 age \u2506 city    \u2502\n\u2502 str     \u2506 i64 \u2506 str     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 David   \u2506 27  \u2506 Cologne \u2502\n\u2502 Charlie \u2506 26  \u2506 Munich  \u2502\n\u2502 Bob     \u2506 25  \u2506 Hamburg \u2502\n\u2502 Alice   \u2506 24  \u2506 Berlin  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"python_polars/erste_schritte/#daten-lesen-und-filtern","title":"Daten lesen und filtern","text":"<p>Einen \u00fcberblick zu den Einlesefunktion von Polars finden wir in der Dokumentation. Hier finden wir Funktionen f\u00fcr die g\u00e4ngigen Datenformate, wie CSV, Parquet, JSON, aber auch f\u00fcr Datenbanken. Im Folgenden werden wir das Einlesen und Filtern auf Basis von CSV-Dateien zeigen. Daf\u00fcr verwenden wir nachfolgend den Datensatz FoodData_Central_csv_2024-04-18 (Full Download of All Data Types).</p> <pre><code>df = pl.read_csv('../datasets/FoodData_Central_csv_2024-04-18/food_nutrient.csv')\nprint(df)\n</code></pre> <p>Note</p> <p>Das Einlesen der Datei food_nutrient.csv (Gr\u00f6\u00dfe 1,83 GB) ben\u00f6tigt auf einem MacBook Pro mit 16 GB RAM unter Verwendung von Polars ca. 2 Sekunden. Pandas ben\u00f6tigt f\u00fcr die gleiche Datei ca. 15 Sekunden.</p> <p>Wir k\u00f6nnen die Performance unseres Einlesens noch weiter verbessern, indem wir auf die Lazy API von Polars zur\u00fcckgreifen. Hierbei wird die Datei nicht sofort eingelesen, sondern erst, wenn wir die Daten wirklich ben\u00f6tigen. </p> <p><pre><code>q = pl.pl.scan_csv('../datasets/FoodData_Central_csv_2024-04-18/food_nutrient.csv')\ndf = q.collect()\nprint(df)\n</code></pre> Dies kann insbesondere dann n\u00fctzlich sein, wenn wir die Daten fr\u00fcher oder sp\u00e4ter filtern oder manupulieren m\u00f6chten. Mehr dazu sp\u00e4ter.</p> <p>Haben wir die Datei, k\u00f6nnen wir das DataFrame filtern und manupulieren. Zu unterschieden ist hierbei zwischen den Funktionen <code>filter</code> und <code>select</code>. <code>filter</code> wird verwendet, um Zeilen zu filtern, w\u00e4hrend <code>select</code> verwendet wird, um Spalten zu filtern.</p> <p>Mit select k\u00f6nnen wir aus unserem DataFrame beispielweise die Spalten <code>nutrient_id</code>, <code>amount</code> und <code>percent_daily_value</code> ausw\u00e4hlen. <pre><code>selected = df.select(\n    pl.col('nutrient_id'),\n    pl.col('amount'),\n    pl.col('percent_daily_value')\n)\nprint(selected)\n</code></pre></p> <p>Mit filter k\u00f6nnen wir die Zeilen filtern, die beispielsweise einen <code>percent_daily_value</code> von mehr als 10 haben. <pre><code>filtered = df.filter(pl.col('amount') &gt; 10)\nprint(filtered)\n</code></pre></p> <p>Wir k\u00f6nnen auch Spalten ein Alias vergeben, um die Spaltennamen zu verdeutlichen.  <pre><code>renamed = df.select(\n    pl.col('nutrient_id').alias('ID'),\n    pl.col('amount').alias('Amount'),\n    pl.col('percent_daily_value').alias('Percent Daily Value')\n)\nprint(renamed)\n</code></pre></p>"},{"location":"python_polars/erste_schritte/#manupulation-von-spalten","title":"Manupulation von Spalten","text":"<p>Polars bietet auch die M\u00f6glichkeit, Spalten zu manupulieren. So k\u00f6nnen wir beispielsweise eine neue Spalte hinzuf\u00fcgen, die die Spalten <code>amount</code>und <code>unit</code> zusammenf\u00fcgt und als <code>amount_unit</code> speichert. </p> <pre><code>df.with_columns(\n    (pl.col('amount').cast(str) + ' ' + pl.col('unit_name')).alias('amount_with_unit')\n)\nprint(df)\n</code></pre> <p>Ein \u00e4hnliches Resultat k\u00f6nnen wir \u00fcber ein <code>select</code> erreichen. In diesem Fall erhalten wir jedoch nur die gew\u00e4hlten Spalten, w\u00e4hrend wir bei <code>with_columns</code> das gesamte DataFrame erhalten.</p> <pre><code>df.select(\n    (pl.col('amount').cast(str) + ' ' + pl.col('unit_name')).alias('amount')\n)\nprint(df)\n</code></pre>"},{"location":"python_polars/erste_schritte/#join-und-merge","title":"Join und Merge","text":"<p>Polars bietet auch die M\u00f6glichkeit, DataFrames zu joinen und zu mergen. Um beispielsweise die Namen der Nutrients zu den Nutrient IDs hinzuzuf\u00fcgen, k\u00f6nnen wir die DataFrames <code>food_nutrient.csv</code> und <code>nutrient.csv</code> joinen.</p> <pre><code>df1 = pl.read_csv('../datasets/FoodData_Central_csv_2024-04-18/food_nutrient.csv')\ndf2 = pl.read_csv('../datasets/FoodData_Central_csv_2024-04-18/nutrient.csv')\n\njoined = df1.join(df2, 'nutrient_id', left_on='nutrient_id', right_on='id')\nprint(joined)\n</code></pre> <p>Note</p> <p>Sp\u00e4testens beim Joinen weiterer Tabellen wird Pandas langsam aber sicher zu einem Bottleneck bei der Analyse der Daten.</p>"},{"location":"python_polars/erste_schritte/#aufgaben","title":"Aufgaben","text":"<ol> <li> <p>Daten einlesen und filtern:    Lade die Datei \"food_nutrient.csv\" aus dem FoodData Central Datensatz herunter. Verwende die Lazy API von Polars, um die Datei einzulesen. Filtere dann alle Eintr\u00e4ge, bei denen der N\u00e4hrwert (amount) gr\u00f6\u00dfer als 10 ist.</p> </li> <li> <p>Spalten ausw\u00e4hlen und umbenennen:    W\u00e4hle aus dem DataFrame die Spalten 'fdc_id', 'nutrient_id' und 'amount' aus. Gib der Spalte 'amount' den Alias 'nutrient_amount'.</p> </li> <li> <p>Gruppierung und Aggregation:    Gruppiere die Daten nach 'nutrient_id' und berechne den Durchschnittswert und den Maximalwert f\u00fcr 'amount' pro N\u00e4hrstoff.</p> </li> <li> <p>Daten zusammenf\u00fchren:    Lade zus\u00e4tzlich die Datei \"nutrient.csv\" herunter. F\u00fchre einen Join zwischen dem 'food_nutrient' DataFrame und dem 'nutrient' DataFrame durch, um den Namen des N\u00e4hrstoffs (name) zu den N\u00e4hrwertdaten hinzuzuf\u00fcgen.</p> </li> <li> <p>Analyse:    Finde die Top 10 Lebensmittel (fdc_id) mit dem h\u00f6chsten Gehalt an Vitamin C (verwende die entsprechende nutrient_id f\u00fcr Vitamin C).</p> </li> </ol> <p>Versuche, diese Aufgaben mit den in diesem Dokument vorgestellten Polars-Funktionen zu l\u00f6sen. Die Aufgaben basieren auf realen Daten und geben einen Einblick in typische Datenverarbeitungsaufgaben im Bereich der Ern\u00e4hrungswissenschaften. Viel Erfolg!</p>"},{"location":"python_polars/lazy_vs_eager/","title":"Lazy vs. Eager API","text":"<p>Polars bietet zwei APIs, die wir in unseren Analysen verwenden k\u00f6nnen: die Lazy API und die Eager API. Die Lazy API ist ein wesentlicher Bestandteil von Polars und erm\u00f6glicht es uns, Berechnungen zu verz\u00f6gern, bis wir die Daten tats\u00e4chlich ben\u00f6tigen. Dies kann insbesondere bei der Verarbeitung gro\u00dfer Datens\u00e4tze von Vorteil sein, da unn\u00f6tige Berechnungen vermieden werden. Die Eager API hingegen f\u00fchrt Berechnungen sofort aus und gibt das Ergebnis zur\u00fcck.</p> <p></p>"},{"location":"python_polars/lazy_vs_eager/#lazy-api","title":"Lazy API","text":"<p>In der Lazy API werden Berechnungen nicht sofort ausgef\u00fchrt, sondern erst, wenn wir die Daten wirklich ben\u00f6tigen. Die Lazy API erstellt zun\u00e4chst einen optimierten Ausf\u00fchrungsplan, bevor sie die Daten verarbeitet. Dies erm\u00f6glicht eine deutliche Effizienzsteigerung, da unn\u00f6tige Berechnungen vermieden werden. </p> <p>Ein Beispiel f\u00fcr die Verwendung der Lazy API ist das Einlesen einer CSV-Datei mit <code>pl.scan_csv()</code>:</p> <pre><code>q = pl.scan_csv('data.csv')\ndf = q.collect()\nprint(df)\n</code></pre> <p>In diesem Beispiel wird die CSV-Datei nicht sofort eingelesen, sondern erst, wenn wir die Daten tats\u00e4chlich ben\u00f6tigen. Dies kann insbesondere dann n\u00fctzlich sein, wenn wir die Daten filtern oder manipulieren m\u00f6chten.</p> <p>Wir k\u00f6nnen in <code>q</code> auch eine komplexere Query speichern, die wir sp\u00e4ter ausf\u00fchren m\u00f6chten:</p> <pre><code># Variante 1\nq = pl.scan_csv('data.csv')\nq = q.filter(pl.col('amount') &gt; 10)\nq = q.select(pl.col('amount'), pl.col('unit'))\ndf = q.collect()\nprint(df)\n\n# Variante 2\nq = (\n    pl.scan_csv('data.csv')\n    .filter(pl.col('amount') &gt; 10)\n    .select(pl.col('amount'), pl.col('unit'))\n)\ndf = q.collect()\n</code></pre> <p>Polars wird bei Lazy Operationen die Query optimieren und nur die ben\u00f6tigten Daten verarbeiten. Dies kann die Performance erheblich verbessern, insbesondere bei gro\u00dfen Datens\u00e4tzen. Wir k\u00f6nnen uns dies am beisoiel des Query-Plans anzeigen lassen:</p> <pre><code>...\nq.show_plan()\n</code></pre> <p></p> <p>Wenn wir die Optimierung ausschalten m\u00f6chten, k\u00f6nnen wir das \u00fcber das Keyword Argument <code>optimized=False</code></p> <pre><code>...\nq.show_plan(optimized=False)\n</code></pre> <p></p> <p>Der Query Plan ist von Unten nach Oben zu lesen. Das \\(\\sigma\\) zeigt an, dass es sich um eine Filter Operation handelt Konkret weist es in diesem Fall darauf hin, dass wir nur Zeilen w\u00e4hlen. bei denen <code>nutrient_id == 2047</code> gilt. Mit dem \\(\\pi\\) wird eine Projektion durchgef\u00fchrt (also in diesem Fall das W\u00e4hlen eines Subsets). Die Zahhl hinter dem \\(\\pi\\) gibt an, wie viele Spalten wir ausw\u00e4hlen.</p> <p>Wir k\u00f6nnen uns den Query Plan auch in einer SQL \u00e4hnlichen Syntax anzeigen lassen:</p> <pre><code>...\nprint(q.explain(optimized=False))\n</code></pre> <p>Dies f\u00fchrt zu der nachfolgenden Ausgabe:</p> <pre><code>FILTER [(col(\"nutrient_id\")) == (2047)] FROM\n  Csv SCAN [../datasets/FoodData_Central_csv_2024-04-18/food_nutrient.csv]\n  PROJECT */13 COLUMNS\n</code></pre>"},{"location":"python_polars/lazy_vs_eager/#eager-api","title":"Eager API","text":"<p>Im Gegensatz zur Lazy API f\u00fchrt die Eager API Berechnungen sofort aus und gibt das Ergebnis zur\u00fcck. Die Eager API eignet sich gut f\u00fcr kleinere Datens\u00e4tze, bei denen die Verz\u00f6gerung durch die Lazy API nicht erforderlich ist.</p> <p>Ein Beispiel f\u00fcr die Verwendung der Eager API ist die direkte Filterung von Daten mit <code>pl.col()</code>:</p> <pre><code>df = pl.scan_csv('data.csv')\nfiltered = df.filter(pl.col('amount') &gt; 10)\nprint(filtered)\n</code></pre> <p>In diesem Beispiel wird die Filterung der Daten sofort ausgef\u00fchrt, ohne dass ein Ausf\u00fchrungsplan erstellt wird. Die Eager API eignet sich gut f\u00fcr kleinere Datens\u00e4tze, bei denen die Verz\u00f6gerung durch die Lazy API nicht erforderlich ist. </p> <p>Im Hintergrund greift die Eager API aus Performance Gr\u00fcnden teilweise auf die Lazy API zur\u00fcck, um die Berechnungen durchzuf\u00fchren. Die Eager API ist daher eine bequeme M\u00f6glichkeit, um schnell und einfach Daten zu filtern und zu manipulieren.</p>"}]}